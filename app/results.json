[
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "TIR: AI/ML Platform | E2E Cloud Skip to main content On this page TIR: AI/ML Platform TIR is built on top of Jupyter Notebook, an advanced web-based interactive development environment offered by E2E Cloud. It provides users with the latest features and functionalities, including JupyterLab, a cutting-edge interface for working with notebooks, code, and data. JupyterLab empowers users to effortlessly customize and streamline their workflows across diverse domains like data science, scientific computing, computational journalism, and machine learning. Components of TIR Platform ​ TIR Dashboard Nodes, Datasets, Inference, Pipeline, VectorDB, Data Syncer, GenAI API Python SDK TIR SDK Work with TIR objects from the comfort of a python shell or jupyter notebooks (hosted or local) CLI Bring the power of E2E GPU cloud on your local desktop using E2E CLI Why AI Model Development So Hard ? ​ Building and deploying AI models can be overwhelming, but it doesn’t have to be. From the complexity of the tech stack to scaling and production hurdles, model development presents challenges at every stage. That’s why TIR , the AI/ML platform built for modern workflows, is here to help you overcome these obstacles effortlessly. 1. Software Stack Complexity Moving models from development to production requires juggling multiple tools, environments, and processes. It’s not just about training a model but also managing: Data loading and preprocessing Advanced training frameworks like PyTorch and TensorFlow GPU drivers and software optimizations for high-performance computing Fault tolerance and error handling Efficient deployment and orchestration across environments 2. Scaling: The Hidden Cost of AI As your AI/ML models grow in size and complexity, so do your infrastructure demands. Managing resources efficiently can become a costly nightmare. You need: Access to high-performance GPUs when training large models Scalability to handle fluctuating compute demands and optimize costs 3. Breaking Down Silos in AI AI development isn’t a solo journey. Teams need to work together seamlessly to build, train, and fine-tune models. However, traditional tools often lead to siloed work environments where communication breaks down. This makes it harder to: Reproduce results across teams Collaborate in real-time on model improvements 4. Deploying Models to Production: Simplified Deploying AI models shouldn’t require a PhD in software engineering. Yet, many teams struggle to move models into production environments efficiently. The process often requires: Specialized knowledge in DevOps Manual intervention for deployment and scaling Constant monitoring to avoid downtime But Why Choose Only TIR? ​ TIR is the AI/ML platform built for modern data scientists and machine learning engineers. We simplify the complexities of model development, collaboration, and deployment, so you can: 1️⃣ Accelerate your time to market 2️⃣ Collaborate seamlessly 3️⃣ Scale effortlessly 4️⃣ Reduce costs Ready to take your AI models from development to production—without the headaches? TIR has you covered. With TIR , you can easily scale your resources up, down, or even to zero, ensuring you only pay for what you need—when you need it. Our intelligent resource management lets you focus on innovation without worrying about overspending. Components of TIR Platform Why AI Model Development So Hard ? But Why Choose Only TIR?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/e2e_cli/cli_intro.html",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes E2E Networks Documentation India's Top Provider of Advanced Cloud GPUs ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs , making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Why us ? 100% Human Support Unlike other cloud providers, our support team is always reachable. 99.99% Uptime SLA Uptime SLAs such that you worry less and do more. High Reliability Cloud platform powered by robust engineering to ensure high-reliability. Ready to Scale? Let's Talk? Our sales team will get in touch with you within 24-48 hours. Promise! Let's talk",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/private_cluster/",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "Private Cluster | E2E Cloud Skip to main content On this page Private Cluster Private Cluster enables the creation of a dedicated environment with a predefined allocation of GPU resources. The pricing for the Private Cluster is fixed, unaffected by the actual usage percentage of the allocated resources. Additionally, deploying Nodes, Inference engines, or Vector Databases within the Private Cluster incurs no extra charges. Create Private Cluster ​ To create a new Private Cluster , click the Create Private Cluster button. Select the desired Cluster Configuration by choosing the appropriate machine type with the required GPU and an available plan. Additionally, you can apply filters to the available resources based on CPU , RAM , or GPU Card specifications. On this page, you can view the details of the selected plan. Depending on whether you choose an Hourly-Billed Plan or a Committed Plan , the summary section will display the corresponding details and associated costs. Private Cluster Hourly plan ​ You can select an Hourly-Based Plan based on your requirements, view the estimated cost, and then click Next to proceed. Private Cluster Committed plan ​ In a Private Cluster with a committed plan, users can choose one of the following post-expiry actions: auto-renew the committed plan, auto-start hourly billing, or automatically delete the cluster after expiry. Manage Private Cluster ​ Overview ​ You can view the details of the selected Private Cluster , including the Cluster Name , Number of Nodes , Plan Name , and the Cluster Node Configuration , which displays the count of GPUs , CPUs , and RAM allocated within the cluster. Monitoring ​ You can view the Disk Usage and Memory Usage for the selected Node within the Private Cluster . Additionally, the following metrics are also available: GPU Utilization , GPU Temperature , CPU Utilization , Memory Utilization , Disk Total Read Bytes , and Disk Total Write Bytes . Services ​ You can view the list of Services that have been launched on the cluster. Actions ​ In the Actions section, you can perform two operation which is Update cluster in which you can increase the Node count and Delete cluster . Update Private Cluster ​ In Actions section, click on Update Cluster . To update the node count, click on the Additional Node Count (+) button and increase the nodes as per your requirements. Delete Private Cluster ​ In Actions section, click on Delete Cluster and confirm. Create Private Cluster Manage Private Cluster Overview Monitoring Services Actions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/RAG/",
    "site_type": "Cloud-based AI/ML Platform",
    "content": "RAG (Retrieval-Augmented Generation) | E2E Cloud Skip to main content On this page RAG (Retrieval-Augmented Generation) Introduction ​ Retrieval-Augmented Generation (RAG) enhances the performance of large language models (LLMs) by enabling them to access a specific knowledge base, rather than relying solely on their general training data. LLMs, which are trained on extensive datasets and contain billions of parameters, excel at generating responses for tasks like Q&A, translation, and text completion. RAG further refines this capability by allowing LLMs to retrieve information from a trusted external knowledge source—such as an organization’s internal data—before generating responses. This approach enables accurate, context-specific, and up-to-date answers without requiring model retraining, making it an efficient and cost-effective way to tailor LLM responses for specialized domains. Retrieval ​ This refers to the process of fetching or retrieving information from an external source, usually a database, knowledge base, or document repository. In the context of RAG, retrieval is the process of searching for relevant data (such as text or documents) based on a query or input provided by the user or system. Augmented ​ Augmentation refers to the enhancement or improvement of something. In the case of RAG, it means enhancing the generation process of a model by supplementing it with additional, relevant information retrieved during the retrieval step. Rather than relying solely on the model's internal knowledge (which can be limited), the model is \"augmented\" with external data, making it more accurate and context-aware. Generation ​ Generation refers to the process of creating or producing content, such as text, based on an input or prompt. In the context of RAG, it refers to the generation of text or responses by the large language model (LLM). After retrieving relevant data, the LLM generates an output, typically by using both the retrieved information and its own internal knowledge. Use Case which RAG Supports ​ RAG (Retrieval-Augmented Generation) supports a range of specific use cases, making it a powerful framework for applications that require the synthesis of contextually relevant information. Here are some notable use cases: 1. Creating Chat Assistants ​ Customer Support Bots : RAG enables the development of chatbot that can answer customer inquiries using a company's internal knowledge base or FAQ repository, providing detailed, context-aware responses. Virtual Assistants : Personal assistants powered by RAG can access external knowledge bases to provide informative responses that go beyond their training data, making them capable of more personalized interactions. Technical Support Assistants : Assistants designed for IT or technical domains can retrieve documentation, troubleshooting guides, or step-by-step instructions from a relevant database to help users with complex queries. 2. Handling FAQs and Knowledge Management ​ FAQ Automation : RAG can be used to create intelligent FAQ systems that retrieve specific answers from company documentation, ensuring that responses are always current and accurate. Dynamic Knowledge Base Queries : Organizations can leverage RAG to allow employees or users to search and receive comprehensive, generated responses from extensive knowledge bases that span different topics or departments. Internal Document Search Tools : Tools powered by RAG can facilitate document search within an enterprise, where users input queries and receive synthesized answers extracted from various internal documents or policies. 3. Content Generation ​ Article Summarization : RAG can pull relevant information from multiple sources and generate cohesive summaries or articles. Report Compilation : It can compile data from various reports and generate a consolidated document or response. Educational Tools : RAG can help create interactive learning tools that provide informative and precise responses from educational databases or textbooks. 4. Research and Analysis ​ Data-Driven Research Assistants : Researchers can use RAG to query large academic databases or datasets, retrieving relevant studies and generating summaries or insights. Legal and Compliance Analysis : In legal or regulatory fields, RAG-powered tools can search through large collections of legal documents, case studies, and compliance requirements, delivering detailed, contextually enriched responses. 5. Personalized Recommendations ​ Content Curation : RAG can tailor recommendations for articles, videos, or other resources based on a user's queries and preferences by pulling related content from knowledge bases. Product Support : Assistants powered by RAG can offer troubleshooting or how-to recommendations specific to the user's products or issues. RAG (Retrieval-Augmented Generation) enhances standard LLMs by integrating a retrieval mechanism that accesses external, up-to-date data sources. This approach improves the accuracy, relevance, and contextuality of responses, addressing limitations such as outdated knowledge and hallucination. RAG allows models to provide domain-specific and real-time information without needing retraining, making it ideal for applications requiring precise and current data. Introduction Retrieval Augmented Generation Use Case which RAG Supports 1. Creating Chat Assistants 2. Handling FAQs and Knowledge Management 3. Content Generation 4. Research and Analysis 5. Personalized Recommendations",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams-Team_Id--projects/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Project ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/{Team_Id}/projects/ Request Security: API Key & Bearer Auth Path Parameters Team_Id integer required Team ID >= 0 Responses 200 Successful response with project details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 project_id integer Example: 124 project_name string Example: default-project description string or null Example: null created_by object created_at string<date-time> Example: 2023-03-22T05:27:47.892853Z updated_at string<date-time> Example: 2023-03-22T05:27:47.945762Z errors object Example: {} message string Example: Success Auth apikey : Token : Parameters Team_Id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/{Team_Id}/projects/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"project_id\" : 124 , 7 \"project_name\" : \"default-project\" , 8 \"description\" : null , 9 \"created_by\" : { 10 \"id\" : 19 , 11 \"name\" : \"shubham Chaturvedi\" , 12 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 13 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 14 } , 15 \"created_at\" : \"2023-03-22T05:27:47.892853Z\" , 16 \"updated_at\" : \"2023-03-22T05:27:47.945762Z\" 17 } 18 ] , 19 \"errors\" : { } , 20 \"message\" : \"Success\" 21 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/users-iam-accounts/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight IAM Accounts get https://api.e2enetworks.com/myaccount/api/v1/gpu /users/iam-accounts/ Request Security: API Key & Bearer Auth Responses 200 Successful response with user details and roles Body application/json application/json code integer Example: 200 data array[object] id integer Example: 2421 owner object role string Example: Owner Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/users/iam-accounts/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"id\" : 2421 , 6 \"owner\" : { 7 \"id\" : 3573 , 8 \"name\" : \"Nipun\" , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"username\" : \"nipun.arora@e2enetworks.com\" , 11 \"phone\" : null , 12 \"is_primary_contact\" : true , 13 \"primary_email\" : \"nipun.arora@e2enetworks.com\" , 14 \"currency\" : \"INR\" , 15 \"is_suspended\" : true 16 } , 17 \"role\" : \"Owner\" 18 } 19 ] 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation TIR: AI/ML Platform Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler TIR, a cutting-edge AI development platform designed to streamline the training, fine-tuning, and serving of large AI models. With optimized GPU containers, pre-configured environments (PyTorch, TensorFlow, Triton), and automated API generation, TIR offers a seamless and end-to-end solution for the AI/ML lifecycle. From model fine-tuning and scalable pipelines to team collaboration and managed inference, TIR is built to unlock the full potential of AI. With integrations like Hugging Face, Weights & Biases, and cloud storage integration options (S3, Azure Blob, Google Drive), TIR empowers teams to innovate efficiently and effectively. Start building the future of AI with TIR today! Getting Started Products & Services Developer's Guide IAM Identity and access managements. Projects Creating Projects on TIR-AI Platform Billing GPU and cpu plans billing. Security API tokens and SSH keys. BenchMarking Performance comparison tool. FAQ Frequently Asked Questions Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/",
    "site_type": "Cloud Computing Platform",
    "content": "TIR: AI/ML Platform | E2E Cloud Skip to main content On this page TIR: AI/ML Platform TIR is built on top of Jupyter Notebook, an advanced web-based interactive development environment offered by E2E Cloud. It provides users with the latest features and functionalities, including JupyterLab, a cutting-edge interface for working with notebooks, code, and data. JupyterLab empowers users to effortlessly customize and streamline their workflows across diverse domains like data science, scientific computing, computational journalism, and machine learning. Components of TIR Platform ​ TIR Dashboard Nodes, Datasets, Inference, Pipeline, VectorDB, Data Syncer, GenAI API Python SDK TIR SDK Work with TIR objects from the comfort of a python shell or jupyter notebooks (hosted or local) CLI Bring the power of E2E GPU cloud on your local desktop using E2E CLI Why AI Model Development So Hard ? ​ Building and deploying AI models can be overwhelming, but it doesn’t have to be. From the complexity of the tech stack to scaling and production hurdles, model development presents challenges at every stage. That’s why TIR , the AI/ML platform built for modern workflows, is here to help you overcome these obstacles effortlessly. 1. Software Stack Complexity Moving models from development to production requires juggling multiple tools, environments, and processes. It’s not just about training a model but also managing: Data loading and preprocessing Advanced training frameworks like PyTorch and TensorFlow GPU drivers and software optimizations for high-performance computing Fault tolerance and error handling Efficient deployment and orchestration across environments 2. Scaling: The Hidden Cost of AI As your AI/ML models grow in size and complexity, so do your infrastructure demands. Managing resources efficiently can become a costly nightmare. You need: Access to high-performance GPUs when training large models Scalability to handle fluctuating compute demands and optimize costs 3. Breaking Down Silos in AI AI development isn’t a solo journey. Teams need to work together seamlessly to build, train, and fine-tune models. However, traditional tools often lead to siloed work environments where communication breaks down. This makes it harder to: Reproduce results across teams Collaborate in real-time on model improvements 4. Deploying Models to Production: Simplified Deploying AI models shouldn’t require a PhD in software engineering. Yet, many teams struggle to move models into production environments efficiently. The process often requires: Specialized knowledge in DevOps Manual intervention for deployment and scaling Constant monitoring to avoid downtime But Why Choose Only TIR? ​ TIR is the AI/ML platform built for modern data scientists and machine learning engineers. We simplify the complexities of model development, collaboration, and deployment, so you can: 1️⃣ Accelerate your time to market 2️⃣ Collaborate seamlessly 3️⃣ Scale effortlessly 4️⃣ Reduce costs Ready to take your AI models from development to production—without the headaches? TIR has you covered. With TIR , you can easily scale your resources up, down, or even to zero, ensuring you only pay for what you need—when you need it. Our intelligent resource management lets you focus on innovation without worrying about overspending. Components of TIR Platform Why AI Model Development So Hard ? But Why Choose Only TIR?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faq/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs General FAQs 1 . What are TIR Nodes? 2 . How do I create a Chat Assistant? 3 . What is the Fine-Tune SDK? 4 . What is TIR Data Syncer? 5 . What is a Private Cluster in TIR? 6 . What is a vector database, and how is it different from traditional databases? Billing FAQs 1 . What types of plans are available for GPU H100 Notebooks? 2 . What is the difference between Committed and Hourly Billed Inference? 3 . What are the plan options available for inference services? 4 . How is usage calculated for billing purposes? 5 . Can I specify custom intervals for checking usage? 6 . What are the costs associated with the Private Cluster? Node High-performance virtual machines optimized for AI/ML workloads RAG Context-aware responses using real time data retrieval and understanding Dataset Efficient storage and handling system designed for large-scale AI/ML datasets Inference Optimized inference for quick, scalable AI model execution. Foundation Studio & GenAI Platform for building, deploying, and managing AI applications seamlessly. Vector Database Database optimized for storing and retrieving high-dimensional vector data. Data Syncer Platform for seamless synchronization of data across systems efficiently. Private Cluster Dedicated, secure cluster for private cloud infrastructure management.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/",
    "site_type": "Cloud Computing Platform",
    "content": "Security | E2E Cloud Skip to main content Security TIR AI platform security ensures that access to sensitive systems and data is tightly controlled through robust authentication methods. It leverages two key security components: API tokens and SSH keys. API tokens are used for authenticating and securing communication between services or applications, ensuring that only authorized entities can interact with the platform. Meanwhile, SSH keys provide secure, encrypted access to remote systems, facilitating safe server management and data transfer. Together, these security measures safeguard the platform from unauthorized access and ensure data integrity across the entire AI lifecycle. API Tokens Learn how to create API Tokens. SSH Keys Set up SSH-based security.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Customer Account Management/Portal",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Customer Account Management/Portal",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Customer Account Management/Portal",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Customer Account Management/Portal",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/#sign-up-with-foreign-customer-as-organization",
    "site_type": "Customer Account Management/Portal",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Customer Account Management/Portal",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-indian-customers",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes E2E Networks Documentation India's Top Provider of Advanced Cloud GPUs ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs , making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Why us ? 100% Human Support Unlike other cloud providers, our support team is always reachable. 99.99% Uptime SLA Uptime SLAs such that you worry less and do more. High Reliability Cloud platform powered by robust engineering to ensure high-reliability. Ready to Scale? Let's Talk? Our sales team will get in touch with you within 24-48 hours. Promise! Let's talk",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation TIR: AI/ML Platform Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler TIR, a cutting-edge AI development platform designed to streamline the training, fine-tuning, and serving of large AI models. With optimized GPU containers, pre-configured environments (PyTorch, TensorFlow, Triton), and automated API generation, TIR offers a seamless and end-to-end solution for the AI/ML lifecycle. From model fine-tuning and scalable pipelines to team collaboration and managed inference, TIR is built to unlock the full potential of AI. With integrations like Hugging Face, Weights & Biases, and cloud storage integration options (S3, Azure Blob, Google Drive), TIR empowers teams to innovate efficiently and effectively. Start building the future of AI with TIR today! Getting Started Products & Services Developer's Guide IAM Identity and access managements. Projects Creating Projects on TIR-AI Platform Billing GPU and cpu plans billing. Security API tokens and SSH keys. BenchMarking Performance comparison tool. FAQ Frequently Asked Questions Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/auto_scale_encryption/",
    "site_type": "Cloud Computing Provider",
    "content": "Autoscale Encryption | E2E Cloud Skip to main content On this page Autoscale Encryption E2E Networks Autoscale Encryption ensures the confidentiality and integrity of dynamically provisioned resources by encrypting virtual machine instances that are automatically created within an autoscaling group. This encryption mechanism protects sensitive workloads that scale in response to traffic or performance demands, safeguarding them from unauthorized access—even during rapid infrastructure changes or unexpected scaling events. E2E Networks implements strong encryption protocols and centralized key management to secure both user and system data across all autoscaled nodes. The encryption process is fully automated and seamless, maintaining high performance and operational efficiency. By securing autoscaled infrastructure, organizations can confidently meet compliance requirements, enforce consistent security policies across fluctuating environments, and ensure end-to-end data protection in cloud-native architectures. How E2E Networks Autoscaling Encryption Works ​ You can enable encryption for Autoscale Group Nodes on E2E Networks. When setting up an Autoscale Group, users can choose to enable encryption by selecting the “Enable Encryption” option. An optional passphrase may also be provided, offering an added layer of protection for sensitive workloads that scale dynamically. E2E Networks implements full disk encryption using LUKS (Linux Unified Key Setup) across autoscaled instances. This ensures data at rest is encrypted at the block level, delivering strong protection even during high-scale, high-speed deployments. The default cipher used is aes-xts-plain64 with a 512-bit key, aligning with industry best practices for secure, performant encryption. By integrating LUKS-based encryption with the flexibility of Autoscaling, E2E Networks ensures that organizations can scale their applications securely and meet compliance goals effortlessly. Encryption settings are easily managed through the MyAccount portal, offering a user-friendly yet secure cloud experience tailored for dynamic and mission-critical workloads. With LUKS encryption and intuitive configuration through the MyAccount portal, E2E Networks helps organizations maintain data confidentiality, ensure compliance with security standards, and confidently deploy applications in a highly secure cloud environment. If you wish to create a new encrypted Node from this unencrypted Image, the process involves the following steps: • Create an Node • Once the Node will come in Running state then click on Save Image button in Actions section of Node. • Click on Save Images • Once the Image come in Ready state then use this image to launch a new Encrypted Autoscale Group . • During the creation of the new Autoscale Group, you will have the option to enable encryption by selecting the \"Enable Encryption\" checkbox and, optionally, providing a passphrase . Encrypted-Autoscale Steps to Create Encrypted Autoscale How E2E Networks Autoscaling Encryption Works",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes E2E Networks Documentation India's Top Provider of Advanced Cloud GPUs ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs , making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Why us ? 100% Human Support Unlike other cloud providers, our support team is always reachable. 99.99% Uptime SLA Uptime SLAs such that you worry less and do more. High Reliability Cloud platform powered by robust engineering to ensure high-reliability. Ready to Scale? Let's Talk? Our sales team will get in touch with you within 24-48 hours. Promise! Let's talk",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/gpu_service-sku/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight SKU List get https://api.e2enetworks.com/myaccount/api/v1/gpu /gpu_service/sku/ Request Security: API Key & Bearer Auth Query Parameters framework string Required for Inference Allowed values: Phi-3-mini-128k-instruct starcoder2-7b llma llama-3-8b-instruct gemma-2b-it gemma-7b-it codellama mistral-7b-instruct mixtral-8x7b-instruct stable_diffusion stable_diffusion_xl mpt image_version_id integer Required for Notebook service service string required Allowed values: notebook vector_db pipeline inference_service private_cloud data_syncer active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with available plans Body application/json application/json responses / 200 code integer Example: 200 data object CPU array[object] GPU array[object] SPOT_INSTANCE array[object] Auth apikey : Token : Parameters service* : notebook vector_db pipeline inference_service private_cloud data_syncer notebook active_iam : framework : Not Set Phi-3-mini-128k-instruct starcoder2-7b llma llama-3-8b-instruct gemma-2b-it gemma-7b-it codellama mistral-7b-instruct mixtral-8x7b-instruct stable_diffusion stable_diffusion_xl mpt select an option image_version_id : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/gpu_service/sku/?service=notebook&apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"CPU\" : [ 5 { 6 \"sku_id\" : 35 , 7 \"name\" : \"C3.8GB_Free\" , 8 \"series\" : \"CPU\" , 9 \"cpu\" : \"4\" , 10 \"gpu\" : null , 11 \"memory\" : \"8GB\" , 12 \"sku_type\" : \"C3-250GB\" , 13 \"is_free\" : true , 14 \"is_active\" : true , 15 \"plans\" : [ 16 { 17 \"sku_item_price_id\" : 86 , 18 \"sku_type\" : \"hourly\" , 19 \"committed_days\" : 0 , 20 \"unit_price\" : 0 , 21 \"currency\" : \"INR\" , 22 \"is_active\" : true , 23 \"description\" : \"Free-Tier Plan\" 24 } 25 ] , 26 \"gpu_switch_type\" : null , 27 \"gpu_card_type\" : null , 28 \"local_storage_in_gb\" : 0 , 29 \"available_inventory_count\" : 102 , 30 \"is_inventory_available\" : true 31 } 32 ] , 33 \"GPU\" : [ 34 { 35 \"sku_id\" : 76 , 36 \"name\" : \"GDC.A100-16.115GB_Free\" , 37 \"series\" : \"GPU\" , 38 \"cpu\" : \"16\" , 39 \"gpu\" : \"1\" , 40 \"memory\" : \"115GB\" , 41 \"sku_type\" : \"GDC.A10040\" , 42 \"is_free\" : true , 43 \"is_active\" : true , 44 \"plans\" : [ 45 { 46 \"sku_item_price_id\" : 193 , 47 \"sku_type\" : \"hourly\" , 48 \"committed_days\" : 0 , 49 \"unit_price\" : 0 , 50 \"currency\" : \"INR\" , 51 \"is_active\" : true , 52 \"description\" : \"Free-Tier Plan\" 53 } 54 ] , 55 \"gpu_switch_type\" : null , 56 \"gpu_card_type\" : \"A100\" , 57 \"local_storage_in_gb\" : 0 , 58 \"available_inventory_count\" : 0 , 59 \"is_inventory_available\" : false 60 } 61 ] , 62 \"SPOT_INSTANCE\" : [ 63 { 64 \"sku_id\" : 180 , 65 \"name\" : \"Spot_GDC.1xH10080-26.250GB_SXM\" , 66 \"series\" : \"SPOT_INSTANCE\" , 67 \"cpu\" : \"26\" , 68 \"gpu\" : \"1\" , 69 \"memory\" : \"250GB\" , 70 \"sku_type\" : \"SPOT-GDC-4xH10080\" , 71 \"is_free\" : false , 72 \"is_active\" : true , 73 \"plans\" : [ 74 { 75 \"sku_item_price_id\" : 987 , 76 \"sku_type\" : \"hourly\" , 77 \"committed_days\" : 0 , 78 \"unit_price\" : 175 , 79 \"currency\" : \"INR\" , 80 \"is_active\" : true , 81 \"description\" : \"Hourly Compute Instance notebook\" 82 } 83 ] , 84 \"gpu_switch_type\" : null , 85 \"gpu_card_type\" : \"H100\" , 86 \"local_storage_in_gb\" : 0 , 87 \"available_inventory_count\" : 4 , 88 \"is_inventory_available\" : true 89 } 90 ] 91 } 92 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/gpu_service-sku/get#Responses",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight SKU List get https://api.e2enetworks.com/myaccount/api/v1/gpu /gpu_service/sku/ Request Security: API Key & Bearer Auth Query Parameters framework string Required for Inference Allowed values: Phi-3-mini-128k-instruct starcoder2-7b llma llama-3-8b-instruct gemma-2b-it gemma-7b-it codellama mistral-7b-instruct mixtral-8x7b-instruct stable_diffusion stable_diffusion_xl mpt image_version_id integer Required for Notebook service service string required Allowed values: notebook vector_db pipeline inference_service private_cloud data_syncer active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with available plans Body application/json application/json responses / 200 code integer Example: 200 data object CPU array[object] GPU array[object] SPOT_INSTANCE array[object] Auth apikey : Token : Parameters service* : notebook vector_db pipeline inference_service private_cloud data_syncer notebook active_iam : framework : Not Set Phi-3-mini-128k-instruct starcoder2-7b llma llama-3-8b-instruct gemma-2b-it gemma-7b-it codellama mistral-7b-instruct mixtral-8x7b-instruct stable_diffusion stable_diffusion_xl mpt select an option image_version_id : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/gpu_service/sku/?service=notebook&apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"CPU\" : [ 5 { 6 \"sku_id\" : 35 , 7 \"name\" : \"C3.8GB_Free\" , 8 \"series\" : \"CPU\" , 9 \"cpu\" : \"4\" , 10 \"gpu\" : null , 11 \"memory\" : \"8GB\" , 12 \"sku_type\" : \"C3-250GB\" , 13 \"is_free\" : true , 14 \"is_active\" : true , 15 \"plans\" : [ 16 { 17 \"sku_item_price_id\" : 86 , 18 \"sku_type\" : \"hourly\" , 19 \"committed_days\" : 0 , 20 \"unit_price\" : 0 , 21 \"currency\" : \"INR\" , 22 \"is_active\" : true , 23 \"description\" : \"Free-Tier Plan\" 24 } 25 ] , 26 \"gpu_switch_type\" : null , 27 \"gpu_card_type\" : null , 28 \"local_storage_in_gb\" : 0 , 29 \"available_inventory_count\" : 102 , 30 \"is_inventory_available\" : true 31 } 32 ] , 33 \"GPU\" : [ 34 { 35 \"sku_id\" : 76 , 36 \"name\" : \"GDC.A100-16.115GB_Free\" , 37 \"series\" : \"GPU\" , 38 \"cpu\" : \"16\" , 39 \"gpu\" : \"1\" , 40 \"memory\" : \"115GB\" , 41 \"sku_type\" : \"GDC.A10040\" , 42 \"is_free\" : true , 43 \"is_active\" : true , 44 \"plans\" : [ 45 { 46 \"sku_item_price_id\" : 193 , 47 \"sku_type\" : \"hourly\" , 48 \"committed_days\" : 0 , 49 \"unit_price\" : 0 , 50 \"currency\" : \"INR\" , 51 \"is_active\" : true , 52 \"description\" : \"Free-Tier Plan\" 53 } 54 ] , 55 \"gpu_switch_type\" : null , 56 \"gpu_card_type\" : \"A100\" , 57 \"local_storage_in_gb\" : 0 , 58 \"available_inventory_count\" : 0 , 59 \"is_inventory_available\" : false 60 } 61 ] , 62 \"SPOT_INSTANCE\" : [ 63 { 64 \"sku_id\" : 180 , 65 \"name\" : \"Spot_GDC.1xH10080-26.250GB_SXM\" , 66 \"series\" : \"SPOT_INSTANCE\" , 67 \"cpu\" : \"26\" , 68 \"gpu\" : \"1\" , 69 \"memory\" : \"250GB\" , 70 \"sku_type\" : \"SPOT-GDC-4xH10080\" , 71 \"is_free\" : false , 72 \"is_active\" : true , 73 \"plans\" : [ 74 { 75 \"sku_item_price_id\" : 987 , 76 \"sku_type\" : \"hourly\" , 77 \"committed_days\" : 0 , 78 \"unit_price\" : 175 , 79 \"currency\" : \"INR\" , 80 \"is_active\" : true , 81 \"description\" : \"Hourly Compute Instance notebook\" 82 } 83 ] , 84 \"gpu_switch_type\" : null , 85 \"gpu_card_type\" : \"H100\" , 86 \"local_storage_in_gb\" : 0 , 87 \"available_inventory_count\" : 4 , 88 \"is_inventory_available\" : true 89 } 90 ] 91 } 92 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams-Team_Id--projects/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Project ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/{Team_Id}/projects/ Request Security: API Key & Bearer Auth Path Parameters Team_Id integer required Team ID >= 0 Responses 200 Successful response with project details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 project_id integer Example: 124 project_name string Example: default-project description string or null Example: null created_by object created_at string<date-time> Example: 2023-03-22T05:27:47.892853Z updated_at string<date-time> Example: 2023-03-22T05:27:47.945762Z errors object Example: {} message string Example: Success Auth apikey : Token : Parameters Team_Id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/{Team_Id}/projects/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"project_id\" : 124 , 7 \"project_name\" : \"default-project\" , 8 \"description\" : null , 9 \"created_by\" : { 10 \"id\" : 19 , 11 \"name\" : \"shubham Chaturvedi\" , 12 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 13 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 14 } , 15 \"created_at\" : \"2023-03-22T05:27:47.892853Z\" , 16 \"updated_at\" : \"2023-03-22T05:27:47.945762Z\" 17 } 18 ] , 19 \"errors\" : { } , 20 \"message\" : \"Success\" 21 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/NodeEncryption/",
    "site_type": "Cloud Computing Service Provider",
    "content": "Node Encryption | E2E Cloud Skip to main content On this page Node Encryption E2E Networks Encryption ensures the security and confidentiality of data by encrypting virtual machine instances at rest. This process protects sensitive information stored within Nodes from unauthorized access, even in the event of a data breach or hardware compromise. E2E Networks leverages robust encryption standards and integrates key management to safeguard both system and user data. Encryption is applied transparently, with minimal impact on performance, allowing applications to operate securely and efficiently. By enabling Node encryption, organizations can meet compliance requirements, strengthen data protection strategies, and maintain the integrity of their cloud-based environments. How E2E Networks Node encryption works ​ You can enable encryption for Nodes on E2E Networks. When creating a Node, users can enable encryption by selecting the \"Enable Encryption\" checkbox. Additionally, an optional passphrase can be provided to further enhance the security of the encrypted volumes. E2E Networks utilizes LUKS (Linux Unified Key Setup) to provide robust full disk encryption for its Nodes. This encryption operates at the block level, ensuring secure protection of data at the storage layer. The default cipher used is aes-xts-plain64, paired with a strong 512-bit key size to deliver high levels of security. Both the root and data volumes are fully encrypted, ensuring that all critical parts of the system are protected by default. At E2E Networks, storage security is silently enforced at the infrastructure level. Logical Volume Management (LVM) volumes are encrypted in the backend as part of our broader disk protection strategy. This encryption is entirely invisible to users—requiring no manual setup and leaving no trace in the user-facing environment—while ensuring that all data remains fully protected behind the scenes. Snapshots taken from encrypted Nodes continue to retain their encryption, ensuring end-to-end data security across your entire Node lifecycle—from the initial creation and configuration to backup, restoration, and beyond. This guarantees that any snapshot, whether taken manually or on a schedule, is securely encrypted, preserving the confidentiality and integrity of your data throughout its lifecycle. With LUKS encryption and intuitive configuration through the MyAccount portal, E2E Networks helps organizations maintain data confidentiality, ensure compliance with security standards, and confidently deploy applications in a highly secure cloud environment. Note Currently, the Save Encrypted Image functionality does not support encrypted Nodes. Whether a Node is encrypted or unencrypted, attempting to create a saved image will always result in an unencrypted image. This limitation is under review, and potential enhancements are being considered for future updates. How Encryption Works for Snapshots which is created from Encrypted Nodes ​ Snapshots taken from an encrypted Node are automatically encrypted. The encryption is handled using LUKS at the disk level, ensuring that data remains protected both at rest and during restoration. Whether the snapshot is taken manually or via a scheduled task, encryption is preserved without requiring additional steps. Once the user creates a snapshot, it first generates a saved image. The user can then choose whether to enable encryption for the Node created from that image. When a snapshot is taken from an encrypted Node, and an image is created from that snapshot, the new Node created from that image will not inherit encryption by default. To ensure data security, encryption must be manually enabled during the Node creation process. How E2E Networks Handles Snapshots from Unencrypted Nodes ​ When a snapshot is taken from an unencrypted Node on E2E Networks, the snapshot itself remains unencrypted. This means that no encryption is automatically applied during the snapshot creation process. When a user takes a snapshot, it must first be converted into a saved image. A new Node can then be created from that image. During the Node creation process, the user must explicitly choose whether to enable encryption for the new Node, as encryption is not automatically inherited. Encryption cannot be retroactively applied to an unencrypted snapshot. Users must create a new encrypted Node and migrate data manually if encryption is required. If you wish to create a new encrypted Node from this unencrypted snapshot, the process involves the following steps: • Create an Image from the unencrypted snapshot. • Use this image to launch a new Node . • During the creation of the new Node, you will have the option to enable encryption by selecting the \"Enable Encryption\" checkbox and, optionally,providing a passphrase . Encrypted-Node Steps to Create Encrypted Nodes How E2E Networks Node encryption works How Encryption Works for Snapshots which is created from Encrypted Nodes How E2E Networks Handles Snapshots from Unencrypted Nodes",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Computing Service Provider",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/NodeEncryption/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Service Provider",
    "content": "Node Encryption | E2E Cloud Skip to main content On this page Node Encryption E2E Networks Encryption ensures the security and confidentiality of data by encrypting virtual machine instances at rest. This process protects sensitive information stored within Nodes from unauthorized access, even in the event of a data breach or hardware compromise. E2E Networks leverages robust encryption standards and integrates key management to safeguard both system and user data. Encryption is applied transparently, with minimal impact on performance, allowing applications to operate securely and efficiently. By enabling Node encryption, organizations can meet compliance requirements, strengthen data protection strategies, and maintain the integrity of their cloud-based environments. How E2E Networks Node encryption works ​ You can enable encryption for Nodes on E2E Networks. When creating a Node, users can enable encryption by selecting the \"Enable Encryption\" checkbox. Additionally, an optional passphrase can be provided to further enhance the security of the encrypted volumes. E2E Networks utilizes LUKS (Linux Unified Key Setup) to provide robust full disk encryption for its Nodes. This encryption operates at the block level, ensuring secure protection of data at the storage layer. The default cipher used is aes-xts-plain64, paired with a strong 512-bit key size to deliver high levels of security. Both the root and data volumes are fully encrypted, ensuring that all critical parts of the system are protected by default. At E2E Networks, storage security is silently enforced at the infrastructure level. Logical Volume Management (LVM) volumes are encrypted in the backend as part of our broader disk protection strategy. This encryption is entirely invisible to users—requiring no manual setup and leaving no trace in the user-facing environment—while ensuring that all data remains fully protected behind the scenes. Snapshots taken from encrypted Nodes continue to retain their encryption, ensuring end-to-end data security across your entire Node lifecycle—from the initial creation and configuration to backup, restoration, and beyond. This guarantees that any snapshot, whether taken manually or on a schedule, is securely encrypted, preserving the confidentiality and integrity of your data throughout its lifecycle. With LUKS encryption and intuitive configuration through the MyAccount portal, E2E Networks helps organizations maintain data confidentiality, ensure compliance with security standards, and confidently deploy applications in a highly secure cloud environment. Note Currently, the Save Encrypted Image functionality does not support encrypted Nodes. Whether a Node is encrypted or unencrypted, attempting to create a saved image will always result in an unencrypted image. This limitation is under review, and potential enhancements are being considered for future updates. How Encryption Works for Snapshots which is created from Encrypted Nodes ​ Snapshots taken from an encrypted Node are automatically encrypted. The encryption is handled using LUKS at the disk level, ensuring that data remains protected both at rest and during restoration. Whether the snapshot is taken manually or via a scheduled task, encryption is preserved without requiring additional steps. Once the user creates a snapshot, it first generates a saved image. The user can then choose whether to enable encryption for the Node created from that image. When a snapshot is taken from an encrypted Node, and an image is created from that snapshot, the new Node created from that image will not inherit encryption by default. To ensure data security, encryption must be manually enabled during the Node creation process. How E2E Networks Handles Snapshots from Unencrypted Nodes ​ When a snapshot is taken from an unencrypted Node on E2E Networks, the snapshot itself remains unencrypted. This means that no encryption is automatically applied during the snapshot creation process. When a user takes a snapshot, it must first be converted into a saved image. A new Node can then be created from that image. During the Node creation process, the user must explicitly choose whether to enable encryption for the new Node, as encryption is not automatically inherited. Encryption cannot be retroactively applied to an unencrypted snapshot. Users must create a new encrypted Node and migrate data manually if encryption is required. If you wish to create a new encrypted Node from this unencrypted snapshot, the process involves the following steps: • Create an Image from the unencrypted snapshot. • Use this image to launch a new Node . • During the creation of the new Node, you will have the option to enable encryption by selecting the \"Enable Encryption\" checkbox and, optionally,providing a passphrase . Encrypted-Node Steps to Create Encrypted Nodes How E2E Networks Node encryption works How Encryption Works for Snapshots which is created from Encrypted Nodes How E2E Networks Handles Snapshots from Unencrypted Nodes",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/guide/apt-get_update_ubuntu/",
    "site_type": "Cloud Computing Service Provider",
    "content": "Apt-get update issue | E2E Cloud Skip to main content On this page Fix slow apt-get update issue on Ubuntu/Debian Server While updating or installing new packages in Ubuntu/Debian servers, slow download speeds may occur even when the network connection is running smoothly. If you run the command # apt-get update , and experience slow download speeds for packages, it likely means you’re connected to a busy Source Mirror server. Some users report no updates happening, updates stuck at the header, or other issues. Slow speed on Ubuntu/Debian server updates & upgrades can be due to: Mirror issues Name server issues Repository issues Other unknown issues In order to fix apt-get update , check the following: ​ Verify if the correct source repositories are in your /etc/apt/sources.list file. Remove unwanted or unsupported source repositories. Clean the apt-get cache. Choose a fast DNS server. Method 1: Fixing Name Server Issues ​ Clear apt-get cache: apt-get clean Choose a proper DNS server** Edit resolv.conf file: vi /etc/resolv.conf Enter Google/CloudFlare DNS nameservers The following two are Google DNS, admittedly, if Google is broken, we all think the Internet is broken. Hence the reason of using Google DNS. You can choose other DNS servers like CloudFlare if you want that are fast and reliable. nameserver 8.8.8.8 nameserver 8.8.4.4 Or CloudFlare Name Server nameserver 1.1.1.1 nameserver 1.0.0.1 Now save and close the file. Test your changes** Let's put our changes to the test. Do an apt-get update apt-get update Do and upgrade apt-get upgrade Finally, do a distribution upgrade apt-get dist-upgrade Your download speed should be much greater than what you were getting earlier. Method 2 ​ 1. Change HTTP to repo in sources.list file You can check and go with the official LaunchPad mirror <https://launchpad.net/ubuntu/+archivemirrors> _ listing or use the country-code method. But we have a much more scientific method. First, you will need to install a tool called netselect , which automatically pulls the Ubuntu/Debian source mirror list and benchmark them based on their latency to your Server location. This package is not shipped with Ubuntu/Debian by default, so you have to install it manually: wget http://ftp.au.debian.org/debian/pool/main/n/netselect/netselect_0.3.ds1-28+b1_amd64.deb dpkg -i netselect_0.3.ds1-28+b1_amd64.deb The following command will call netselect to benchmark the top 20 source hosts from the source mirror list: netselect -s 20 -t 40 $(wget -qO - http://mirrors.ubuntu.com/mirrors.txt) For example, we have established that in our location, repo.extreme-ix.org is going to be fastest mirror server for apt. We are going to use this information to update the mirror list: vi /etc/apt/sources.list Next, search for the existing server domain (e.g. us.archive.ubuntu.com ) and then replace it with repo.extreme-ix.org . At the prompt, perform this replacement for all entries. Save the sources.list file and run command # apt update && apt upgrade -y to update repo source and server packages. Method 3 ​ Transport HTTP mirrors to HTTPS mirrors in sources.list file 1. Transport source to https. Transport source from http to https. Open the terminal and run the following command to install apt-transport-https package. apt install apt-transport-https 2. Edit resources Just change HTTP to HTTPS and Save the sources.list file and run command # apt update && apt upgrade -y to update repo source and server packages. In order to fix apt-get update , check the following: Method 1: Fixing Name Server Issues Method 2 Method 3",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Computing Service Provider",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Computing Service Provider",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/abuse/",
    "site_type": "Support/Help Documentation",
    "content": "Abuse | E2E Cloud Skip to main content Abuse E2E Networks platform team works around the clock to address complaints of abuse on our network. We receive these complaints via feedback loops from security updates providers, spam blacklisting services, various industry contacts and mailing lists as well as from our clients. Some of the types of abuses and the steps that can be taken to resolve the same are documented in the articles below The following process is followed when we detect an abuse complaint regarding any server/service you have taken from us We send out a warning email to the authorized contact as soon as we discover and ascertain the abuse issue. The email contains the nature of the abuse and requests to check the issue at your end. If there are any identifiable security vulnerabilities, we will include the remedial measures as well. We would ask you to respond to us with the corrective measures you have taken to address the issue For Abuse Complaints, Since the outbound attack originates from your server, In order to protect the network from attack, We will suspend the Public and Private connectivity of your server as soon as the issue is reported For Phishing and Other Complaints, If we do not get a response from your side in 2 hours and the issue is still persisting we would call the authorized contact on their given phone numbers to intimate the issue In lack of response for our phone call for another 2 hours, It would be required by us to suspend the public/Private network of your machines to prevent malicious activities on our server You need to take action on the abuse complaint yourself by login to the server via console, we would require written confirmation on the steps you have taken to stop the reported actions Please keep your authorized contact details updated to avoid any miscommunications by sending an email to cloud-platform@e2enetworks.com , whenever there is a change or an anomaly is discovered in contact details. We understand getting an abuse ticket is a hassle, but please remember that we’re doing our best to protect our network, the Internet community and you. Switching off your server is a last resort for us, and we want to make sure everyone is on the same page to prevent us from getting to that last resort. In case any of your server at E2E Networks is compromised, Please note that during the entire process, we request you to communicate and kindly take immediate action to fix the issue as the lack of response or resolution of the issue would be a contravention of IT Act 2000 and would lead to disabling of the public network.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Support/Help Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/abuse/#__docusaurus_skipToContent_fallback",
    "site_type": "Support/Help Documentation",
    "content": "Abuse | E2E Cloud Skip to main content Abuse E2E Networks platform team works around the clock to address complaints of abuse on our network. We receive these complaints via feedback loops from security updates providers, spam blacklisting services, various industry contacts and mailing lists as well as from our clients. Some of the types of abuses and the steps that can be taken to resolve the same are documented in the articles below The following process is followed when we detect an abuse complaint regarding any server/service you have taken from us We send out a warning email to the authorized contact as soon as we discover and ascertain the abuse issue. The email contains the nature of the abuse and requests to check the issue at your end. If there are any identifiable security vulnerabilities, we will include the remedial measures as well. We would ask you to respond to us with the corrective measures you have taken to address the issue For Abuse Complaints, Since the outbound attack originates from your server, In order to protect the network from attack, We will suspend the Public and Private connectivity of your server as soon as the issue is reported For Phishing and Other Complaints, If we do not get a response from your side in 2 hours and the issue is still persisting we would call the authorized contact on their given phone numbers to intimate the issue In lack of response for our phone call for another 2 hours, It would be required by us to suspend the public/Private network of your machines to prevent malicious activities on our server You need to take action on the abuse complaint yourself by login to the server via console, we would require written confirmation on the steps you have taken to stop the reported actions Please keep your authorized contact details updated to avoid any miscommunications by sending an email to cloud-platform@e2enetworks.com , whenever there is a change or an anomaly is discovered in contact details. We understand getting an abuse ticket is a hassle, but please remember that we’re doing our best to protect our network, the Internet community and you. Switching off your server is a last resort for us, and we want to make sure everyone is on the same page to prevent us from getting to that last resort. In case any of your server at E2E Networks is compromised, Please note that during the entire process, we request you to communicate and kindly take immediate action to fix the issue as the lack of response or resolution of the issue would be a contravention of IT Act 2000 and would lead to disabling of the public network.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Support/Help Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/abuse/logs/",
    "site_type": "Support/Help Documentation",
    "content": "Abuse Logs | E2E Cloud Skip to main content Abuse Logs Login to MyAccount at \"https://myaccount.e2enetworks.com/accounts/login\" via your registered E2E Customer login Credentials. You will be directed to the ‘Dashboard’ page. Click on the ‘Settings’ menu from the left panel menu. Click on the ‘Abuse Logs’ sub-menu. You will be directed to the ‘Abuse Logs’ page. Click on the ‘Download’ button to download and view the abuse logs status. Please contact us at cloud-platform@e2enetworks.com if you have any queries.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Support/Help Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/virt_comp_node/",
    "site_type": "documentation",
    "content": "Virtual Compute Node Documentation | E2E Cloud Skip to main content On this page Virtual Compute Node Documentation Create and Login to your Node ​ Getting Started Learn how to create Nodes. Log in to your Node Learn how to log in to your virtual compute node. Log in to your Windows Node Learn how to log in to your windows node. Node Management and Operations ​ Manage your Nodes Learn how to manage your nodes. Create a Node Image Learn how to create image of your node. Node Snapshot Learn how to take snapshots of your node. Import your own custom Image Guide for importing a custom image to MyAccount. Tutorials ​ Transfer Images Across Regions Tutorial for image transfer across regions. Migrate AWS Image to E2E Guide to Export AWS Image and Import to E2E Committed Node Convert an hourly Node to Committed Node Node in Recovery mode How to access node in recovery mode Change Hostname Change the hostname of your node Help & Troubleshooting Guide ​ Node Accessibility Issues Troubleshooting Steps When your Nodes is not accessible High processor Load Troubleshooting High Processor Load on your server Site down Troubleshooting Steps when your Site is down. Running out of disk space Node Running Out Of DiskSpace Monitor Server Load On Windows Node Reboot Survival Practices to minimize downtime Apt-get update issue Fix slow apt-get update issue on Ubuntu/Debian Server Create and Login to your Node Node Management and Operations Tutorials Help & Troubleshooting Guide",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/virt_comp_node/help/node_access_issue/",
    "site_type": "documentation",
    "content": "Node not accessible | E2E Cloud Skip to main content On this page Steps When Your Node is Not Accessible Sometimes we may run into troubles when our Virtual Nodes are not accessible. We should be able to identify the problem that is likely causing the issues and fix it ourselves. In this article, we’ll share a few troubleshooting steps that are commonly taken by administrators when a node is not accessible. You can refer to these steps and fix the issue to get your server up and accessible. Verifying the Server Status ​ Before proceeding with any of the steps, we need to first verify the server status by pinging and SSH/rdesktop into your server. If you are able to access your server using ping and SSH, and only your site is not accessible, then it's mostly an issue at the service level. We recommend you refer to this article . What is ping? ​ Ping is a computer network administration software utility used to test the reachability of a host on an Internet Protocol network. You can verify this with the below command: ping xx.xx.xx.xx Note Replace xx.xx.xx.xx with your server IP in the above command. If you are able to reach the network, You will get similar output to as below e2e-Vostro-3546:~$ ping 164.52.200.65 PING 164.52.200.65 (164.52.200.65) 56(84) bytes of data. 64 bytes from 164.52.200.65: icmp_seq=1 ttl=52 time=313 ms 64 bytes from 164.52.200.65: icmp_seq=2 ttl=52 time=98.2 ms 64 bytes from 164.52.200.65: icmp_seq=3 ttl=52 time=76.9 ms ^C --- 164.52.200.65 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms The above output represents that your server is up and the packet is being transmitted. When you are unable to reach your network, You will get an output as below where the packet is being not transmitted e2e-Vostro-3546:~$ ping 164.52.200.65 PING 164.52.200.65 (164.52.200.65) 56(84) bytes of data. ^C --- 164.52.200.65 ping statistics --- 7 packets transmitted, 0 received, 100% packet loss, time 6144ms e2e-Vostro-3546:~$ rtt min/avg/max/mdev = 76.963/162.942/313.633/106.908 ms From the above command, you can see that there is a packet loss of 100% which indicates that your server is not reachable to the network at all. Note If you have disabled ping ICMP on your server, Then you will not be able ping the server even though the server might be up and accessible. What is SSH ​ The SSH protocol (also referred to as Secure Shell) is a method for secure remote login from one computer to another. If you are using a Linux server, You can SSH to your server and verify whether you are able to access your server. Please refer below command ssh username@xx.xx.xx.xx Note In the above command, replace the username with the actual user of your server and replace xx.xx.xx.xx with your server IP. What is Rdesktop ​ rdesktop is an implementation of client software for Microsoft's proprietary Remote Desktop Protocol.rdesktop is an open-source UNIX client for connecting to Windows Remote Desktop. If you are using a windows server, You can check the accessibility of your server using Rdesktop using the below command rdesktop xx.xx.xx.xx -u username -p password Replace the username and password with your actual configured username and password ##Check The State of Your Node on Myaccount Portal If your node is not accessible and You have verified this using ping and ssh method, Then we need to first check the state of our Node in Myaccount <https://myaccount.e2enetworks.com/> _ portal and Make sure it's in Running State. Sometimes Due to High Utilization, Your node could go in Power off state. In such cases, you need to power on your server and take the necessary action to avoid the high utilization of your server. Reboot Your Server ​ If you are not able to log in, chances are that your node is out of memory or the CPU has crashed. You would need to reboot the node once from the MyAccount portal and try accessing it. Click on the Reboot button to restart your virtual compute node. It will take a few minutes to restart your virtual compute node. Access Console to Troubleshoot ​ A VNC console is available to provide you direct access to your nodes regardless of your settings. This feature comes to aid in situations such as to log in, revert bad settings, and regain control. Often, nodes get out of memory or face other service/application-level issues where they become inaccessible. In such cases, you can access the server console, check the exact error, and try to resolve it. If your node is hung, the server would get the OOM-killer invoked or show a blank screen on the console, indicating that the node has been hanged. In this case, you need to reboot the server to resolve the issue and take the necessary action to increase the resources of the server. Other cases might involve issues like the firewalls of the server being misconfigured or the network settings being altered, causing you to lose public connectivity on your server. In such cases, you need to log in to the console and revert the changes made. Once you get access, you can reset any misbehaving configuration files or services to restore access. Monitor Resources Utilization of Your Server ​ Your node might become inaccessible frequently if you have high resource utilization on your server. We need to keep a constant eye on the resources of our server to make sure it’s not highly utilized and make necessary upgrades when required. Monitoring resource utilization can be done directly from the MyAccount portal in the Monitoring section, or you can use CloudOne Monitoring for detailed analysis. Check the Disk Utilization ​ Your node might become inaccessible or even go into the power-off state when the disk utilization of your server exceeds 99%. In such cases, you can log in via the console and delete some log files or backup files to clear up some space and get the server back up and accessible. If you are unable to log in to the console, you can contact cloud-platform@e2enetworks.com , and our team can assist you in resolving the issue. Firewall/Network Configuration Messed Up ​ In case you made changes to the firewall or network configuration, or if certain updates have messed up these files and you have lost public connectivity, you can try reverting the changes from the console. If you are unable to revert them, you have two options: If you have enabled CDP Backup, you can restore the backup of your server. If CDP backup is not activated, you can contact cloud-platform@e2enetworks.com , and our team will help you resolve the issue. Slowness and Network Issues ​ Check the ping to the server and a standard site like Google or Facebook. If you see packet losses in both networks, it could be a local network issue. If all other sites are working fine (no packet losses on ping) and only your server at E2E is experiencing packet loss, then it could be a server slowness issue and/or a network issue. In this case, please send us a ping report (your site as well as google.com in parallel) and a traceroute to the server. If possible, please check across multiple network providers. For example, if you have a DSL connection, a second confirmation could be to use mobile data and check the connection. The above guide provides a simple approach to quickly identify the issue and get your server up and running. If the issue is not yet resolved, please contact cloud-platform@e2enetworks.com , and our team will help you resolve the issue. Verifying the Server Status What is ping? What is SSH What is Rdesktop Reboot Your Server Access Console to Troubleshoot Monitor Resources Utilization of Your Server Check the Disk Utilization Firewall/Network Configuration Messed Up Slowness and Network Issues",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/guide/apt-get_update_ubuntu/",
    "site_type": "documentation",
    "content": "Apt-get update issue | E2E Cloud Skip to main content On this page Fix slow apt-get update issue on Ubuntu/Debian Server While updating or installing new packages in Ubuntu/Debian servers, slow download speeds may occur even when the network connection is running smoothly. If you run the command # apt-get update , and experience slow download speeds for packages, it likely means you’re connected to a busy Source Mirror server. Some users report no updates happening, updates stuck at the header, or other issues. Slow speed on Ubuntu/Debian server updates & upgrades can be due to: Mirror issues Name server issues Repository issues Other unknown issues In order to fix apt-get update , check the following: ​ Verify if the correct source repositories are in your /etc/apt/sources.list file. Remove unwanted or unsupported source repositories. Clean the apt-get cache. Choose a fast DNS server. Method 1: Fixing Name Server Issues ​ Clear apt-get cache: apt-get clean Choose a proper DNS server** Edit resolv.conf file: vi /etc/resolv.conf Enter Google/CloudFlare DNS nameservers The following two are Google DNS, admittedly, if Google is broken, we all think the Internet is broken. Hence the reason of using Google DNS. You can choose other DNS servers like CloudFlare if you want that are fast and reliable. nameserver 8.8.8.8 nameserver 8.8.4.4 Or CloudFlare Name Server nameserver 1.1.1.1 nameserver 1.0.0.1 Now save and close the file. Test your changes** Let's put our changes to the test. Do an apt-get update apt-get update Do and upgrade apt-get upgrade Finally, do a distribution upgrade apt-get dist-upgrade Your download speed should be much greater than what you were getting earlier. Method 2 ​ 1. Change HTTP to repo in sources.list file You can check and go with the official LaunchPad mirror <https://launchpad.net/ubuntu/+archivemirrors> _ listing or use the country-code method. But we have a much more scientific method. First, you will need to install a tool called netselect , which automatically pulls the Ubuntu/Debian source mirror list and benchmark them based on their latency to your Server location. This package is not shipped with Ubuntu/Debian by default, so you have to install it manually: wget http://ftp.au.debian.org/debian/pool/main/n/netselect/netselect_0.3.ds1-28+b1_amd64.deb dpkg -i netselect_0.3.ds1-28+b1_amd64.deb The following command will call netselect to benchmark the top 20 source hosts from the source mirror list: netselect -s 20 -t 40 $(wget -qO - http://mirrors.ubuntu.com/mirrors.txt) For example, we have established that in our location, repo.extreme-ix.org is going to be fastest mirror server for apt. We are going to use this information to update the mirror list: vi /etc/apt/sources.list Next, search for the existing server domain (e.g. us.archive.ubuntu.com ) and then replace it with repo.extreme-ix.org . At the prompt, perform this replacement for all entries. Save the sources.list file and run command # apt update && apt upgrade -y to update repo source and server packages. Method 3 ​ Transport HTTP mirrors to HTTPS mirrors in sources.list file 1. Transport source to https. Transport source from http to https. Open the terminal and run the following command to install apt-transport-https package. apt install apt-transport-https 2. Edit resources Just change HTTP to HTTPS and Save the sources.list file and run command # apt update && apt upgrade -y to update repo source and server packages. In order to fix apt-get update , check the following: Method 1: Fixing Name Server Issues Method 2 Method 3",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/guide/reboot-survival/",
    "site_type": "documentation",
    "content": "Reboot Survival – Best Practices | E2E Cloud Skip to main content On this page Reboot Survival – Best Practices Introduction ​ Cloud infrastructure offers resilience but all servers depend on its physical hardware, which in the long run needs maintenance. Round-the-clock servers depend on uptime which is optimum for its usage, but unavoidable downtime does happen. Apart from hardware maintenance, updates and patches require rebooting your server to keep your system secure and up-to-date. The guide below covers best practices to ensure your system handles unexpected reboots, minimizing downtime. Test your Stack by Manual Reboot ​ During the development phase, when you make important changes to your stack, make sure you reboot your server and ensure that your stack is fully operational without any issues. Performing these reboot trials frequently prepares you for unexpected reboots during maintenance or upgrades. Backup your Crucial Data ​ Backing up your most important and critical data is one of the most essential steps. Losing data due to unexpected downtime or accidental deletion can have an adverse impact on your stack. E2E Networks CDP Backups function as an exact replica of your file system, backed up automatically at periodic intervals. Each backup contains all data to restore from the initial provisioning to the most recent block update. This allows point-in-time recovery from any of the archive's recovery points. You can find more details here . You can also back up your databases from MySQL or MariaDB and restore them using the mysqldump command. For those unfamiliar with mysqldump , refer to this guide . Enable Services on Boot ​ Ensure that all your critical and important services and applications configured on your server are set to start at boot. This ensures that during future reboots, all services are up and running without manual intervention. In Debian and Ubuntu, use update-rc.d to add or remove services from startup: sudo update-rc.d service_name defaults To remove service from boot startup,Use below command sudo update-rc.d -f service_name remove In Centos7,Use systemctl command sudo systemctl enable service_name sudo systemctl disable service_name Ensure Firewall rules are saved ​ If you have manually configured the rules in firewall,You should make sure its already be saved, and gets loaded on boot automatically. You can save the firewalls permanently by running the below command. sudo iptables-save > /etc/iptables.firewall.rules Using Load balancer ​ If your system totally cannot afford downtime, You can use a Load Balancer Appliance which helps you to dynamically distribute user traffic to multiple backend nodes — for high availability, scalability, fault-tolerance, and smooth user experience. It also helps you to apply changes to the backend without impacting the end-user experience. You can refer this article on how to launch a Load balancer in E2E . Introduction Test your Stack by Manual Reboot Backup your Crucial Data Enable Services on Boot Ensure Firewall rules are saved Using Load balancer",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation TIR: AI/ML Platform Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler TIR, a cutting-edge AI development platform designed to streamline the training, fine-tuning, and serving of large AI models. With optimized GPU containers, pre-configured environments (PyTorch, TensorFlow, Triton), and automated API generation, TIR offers a seamless and end-to-end solution for the AI/ML lifecycle. From model fine-tuning and scalable pipelines to team collaboration and managed inference, TIR is built to unlock the full potential of AI. With integrations like Hugging Face, Weights & Biases, and cloud storage integration options (S3, Azure Blob, Google Drive), TIR empowers teams to innovate efficiently and effectively. Start building the future of AI with TIR today! Getting Started Products & Services Developer's Guide IAM Identity and access managements. Projects Creating Projects on TIR-AI Platform Billing GPU and cpu plans billing. Security API tokens and SSH keys. BenchMarking Performance comparison tool. FAQ Frequently Asked Questions Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/",
    "site_type": "Cloud Computing Platform",
    "content": "TIR: AI/ML Platform | E2E Cloud Skip to main content On this page TIR: AI/ML Platform TIR is built on top of Jupyter Notebook, an advanced web-based interactive development environment offered by E2E Cloud. It provides users with the latest features and functionalities, including JupyterLab, a cutting-edge interface for working with notebooks, code, and data. JupyterLab empowers users to effortlessly customize and streamline their workflows across diverse domains like data science, scientific computing, computational journalism, and machine learning. Components of TIR Platform ​ TIR Dashboard Nodes, Datasets, Inference, Pipeline, VectorDB, Data Syncer, GenAI API Python SDK TIR SDK Work with TIR objects from the comfort of a python shell or jupyter notebooks (hosted or local) CLI Bring the power of E2E GPU cloud on your local desktop using E2E CLI Why AI Model Development So Hard ? ​ Building and deploying AI models can be overwhelming, but it doesn’t have to be. From the complexity of the tech stack to scaling and production hurdles, model development presents challenges at every stage. That’s why TIR , the AI/ML platform built for modern workflows, is here to help you overcome these obstacles effortlessly. 1. Software Stack Complexity Moving models from development to production requires juggling multiple tools, environments, and processes. It’s not just about training a model but also managing: Data loading and preprocessing Advanced training frameworks like PyTorch and TensorFlow GPU drivers and software optimizations for high-performance computing Fault tolerance and error handling Efficient deployment and orchestration across environments 2. Scaling: The Hidden Cost of AI As your AI/ML models grow in size and complexity, so do your infrastructure demands. Managing resources efficiently can become a costly nightmare. You need: Access to high-performance GPUs when training large models Scalability to handle fluctuating compute demands and optimize costs 3. Breaking Down Silos in AI AI development isn’t a solo journey. Teams need to work together seamlessly to build, train, and fine-tune models. However, traditional tools often lead to siloed work environments where communication breaks down. This makes it harder to: Reproduce results across teams Collaborate in real-time on model improvements 4. Deploying Models to Production: Simplified Deploying AI models shouldn’t require a PhD in software engineering. Yet, many teams struggle to move models into production environments efficiently. The process often requires: Specialized knowledge in DevOps Manual intervention for deployment and scaling Constant monitoring to avoid downtime But Why Choose Only TIR? ​ TIR is the AI/ML platform built for modern data scientists and machine learning engineers. We simplify the complexities of model development, collaboration, and deployment, so you can: 1️⃣ Accelerate your time to market 2️⃣ Collaborate seamlessly 3️⃣ Scale effortlessly 4️⃣ Reduce costs Ready to take your AI models from development to production—without the headaches? TIR has you covered. With TIR , you can easily scale your resources up, down, or even to zero, ensuring you only pay for what you need—when you need it. Our intelligent resource management lets you focus on innovation without worrying about overspending. Components of TIR Platform Why AI Model Development So Hard ? But Why Choose Only TIR?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faq/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs General FAQs 1 . What are TIR Nodes? 2 . How do I create a Chat Assistant? 3 . What is the Fine-Tune SDK? 4 . What is TIR Data Syncer? 5 . What is a Private Cluster in TIR? 6 . What is a vector database, and how is it different from traditional databases? Billing FAQs 1 . What types of plans are available for GPU H100 Notebooks? 2 . What is the difference between Committed and Hourly Billed Inference? 3 . What are the plan options available for inference services? 4 . How is usage calculated for billing purposes? 5 . Can I specify custom intervals for checking usage? 6 . What are the costs associated with the Private Cluster? Node High-performance virtual machines optimized for AI/ML workloads RAG Context-aware responses using real time data retrieval and understanding Dataset Efficient storage and handling system designed for large-scale AI/ML datasets Inference Optimized inference for quick, scalable AI model execution. Foundation Studio & GenAI Platform for building, deploying, and managing AI applications seamlessly. Vector Database Database optimized for storing and retrieving high-dimensional vector data. Data Syncer Platform for seamless synchronization of data across systems efficiently. Private Cluster Dedicated, secure cluster for private cloud infrastructure management.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/",
    "site_type": "Cloud Computing Platform",
    "content": "Security | E2E Cloud Skip to main content Security TIR AI platform security ensures that access to sensitive systems and data is tightly controlled through robust authentication methods. It leverages two key security components: API tokens and SSH keys. API tokens are used for authenticating and securing communication between services or applications, ensuring that only authorized entities can interact with the platform. Meanwhile, SSH keys provide secure, encrypted access to remote systems, facilitating safe server management and data transfer. Together, these security measures safeguard the platform from unauthorized access and ensure data integrity across the entire AI lifecycle. API Tokens Learn how to create API Tokens. SSH Keys Set up SSH-based security.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faq/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs General FAQs 1 . What are TIR Nodes? 2 . How do I create a Chat Assistant? 3 . What is the Fine-Tune SDK? 4 . What is TIR Data Syncer? 5 . What is a Private Cluster in TIR? 6 . What is a vector database, and how is it different from traditional databases? Billing FAQs 1 . What types of plans are available for GPU H100 Notebooks? 2 . What is the difference between Committed and Hourly Billed Inference? 3 . What are the plan options available for inference services? 4 . How is usage calculated for billing purposes? 5 . Can I specify custom intervals for checking usage? 6 . What are the costs associated with the Private Cluster? Node High-performance virtual machines optimized for AI/ML workloads RAG Context-aware responses using real time data retrieval and understanding Dataset Efficient storage and handling system designed for large-scale AI/ML datasets Inference Optimized inference for quick, scalable AI model execution. Foundation Studio & GenAI Platform for building, deploying, and managing AI applications seamlessly. Vector Database Database optimized for storing and retrieving high-dimensional vector data. Data Syncer Platform for seamless synchronization of data across systems efficiently. Private Cluster Dedicated, secure cluster for private cloud infrastructure management.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faqService/?title=Dataset",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs Dataset Dataset FAQs 1. What are TIR datasets? 2. What types of storage are supported for datasets on TIR? 3. How can I create a new dataset in TIR? 4. What is the difference between E2E Managed and User Managed encryption? 5. How can I upload data to my EOS bucket? 6. Can I use datasets from multiple sources? 7. What is the benefit of using shared EOS buckets? 8. What is data streaming in TIR datasets? 9. How do I configure encryption when creating an EOS bucket? 10. How is disk storage priced? FAQs per page: 10 Previous Page 1 of 2 Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faqService/?title=RAG",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs RAG RAG FAQs 1. How do I create a Chat Assistant? 2. What happens after I click on 'Create Assistant'? 3. Can I use multiple Knowledge Bases with different embedding models in a Chat Assistant? 4. What is the role of the Prompt Engine in a Chat Assistant? 5. What does 'similarity threshold' mean in the Prompt Engine? 6. What is 'Keywords similarity weight' in the Prompt Engine? 7. What does 'Top N' refer to in the Prompt Engine? 8. How do I configure the Model Settings in a Chat Assistant? 9. What is the purpose of adjusting the Temperature in Model Settings? 10. What is the 'Top P' setting in the Model Settings? FAQs per page: 10 Previous Page 1 of 2 Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faqService/?title=Foundation%20Studio%20%26%20GenAI",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs Foundation Studio & GenAI Foundation Studio & GenAI FAQs 1. What is fine-tuning in machine learning? 2. How does fine-tuning work in neural networks? 3. What is the Fine-Tune SDK? 4. How do I start a fine-tuning job? 5. What hardware options are available for fine-tuning models? 6. Can I resume training from a previous checkpoint? 7. How do I set up Hugging Face integration? 8. What datasets are supported for fine-tuning? 9. What is the recommended dataset format for stable diffusion models? 10. What is the dataset format for text models like LLaMA or Mistral? FAQs per page: 10 Previous Page 1 of 4 Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/faqService/?title=Vector%20Database",
    "site_type": "Cloud Computing Platform",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Getting Started FAQs Looking for help? Refer our FAQs Vector Database Vector Database FAQs 1. What is a vector database, and how is it different from traditional databases? 2. What is Qdrant, and what makes it unique? 3. What are the key components of Qdrant? 4. What is a vector in Qdrant? 5. What is a collection in Qdrant? 6. How does Qdrant handle scalability with shards? 7. What is the replication factor in Qdrant? 8. How does Qdrant ensure efficient searches? 9. What types of applications can Qdrant power? 10. What is a point in Qdrant? FAQs per page: 10 Previous Page 1 of 3 Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/versioning/",
    "site_type": "Documentation",
    "content": "Object Versioning | E2E Cloud Skip to main content On this page Object Versioning EOS supports Object Versioning , allowing you to preserve, retrieve, and restore every version of every object stored in a bucket. This is especially useful to protect against accidental overwrites or deletions. Enable Versioning ​ To enable versioning: Navigate to the Object Storage section from your My Account dashboard. Select your bucket from the list. Click on the Object Versioning tab in the action panel. Toggle the Enable Versioning option. Once enabled, every new upload of an object will create a new version instead of overwriting the existing file. Viewing Object Versions ​ To view previous versions of an object: Open the Objects tab of your bucket. Click on See all versions above the object list. You’ll now see all available versions of each object with their unique version ID , timestamp , and size . Download a Previous Version ​ To download an older version of an object: In the Objects > See all versions view, locate the desired object. Click the three-dot menu next to the version. Choose Download or Generate Presigned URL depending on your need. Delete a Specific Version ​ To delete a particular object version: In the See all versions view, open the three-dot menu next to the version. Click Delete version . 🗑️ Deleting a version only removes that specific version, not the entire object. Disable Versioning ​ You can suspend versioning but cannot delete version history retroactively. To disable (suspend) versioning: Go to the Versioning tab of the bucket. Toggle the Disable Versioning switch. 🚫 Suspended buckets will stop creating new versions , but all existing versions will remain intact. Use Cases ​ Recover accidentally deleted files Track changes to critical data over time Audit and rollback configurations Note You are billed for all versions of an object. Consider using lifecycle rules to automatically clean up older versions if storage costs are a concern. Enable Versioning Viewing Object Versions Download a Previous Version Delete a Specific Version Disable Versioning Use Cases",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/versioning/#use-cases",
    "site_type": "Documentation",
    "content": "Object Versioning | E2E Cloud Skip to main content On this page Object Versioning EOS supports Object Versioning , allowing you to preserve, retrieve, and restore every version of every object stored in a bucket. This is especially useful to protect against accidental overwrites or deletions. Enable Versioning ​ To enable versioning: Navigate to the Object Storage section from your My Account dashboard. Select your bucket from the list. Click on the Object Versioning tab in the action panel. Toggle the Enable Versioning option. Once enabled, every new upload of an object will create a new version instead of overwriting the existing file. Viewing Object Versions ​ To view previous versions of an object: Open the Objects tab of your bucket. Click on See all versions above the object list. You’ll now see all available versions of each object with their unique version ID , timestamp , and size . Download a Previous Version ​ To download an older version of an object: In the Objects > See all versions view, locate the desired object. Click the three-dot menu next to the version. Choose Download or Generate Presigned URL depending on your need. Delete a Specific Version ​ To delete a particular object version: In the See all versions view, open the three-dot menu next to the version. Click Delete version . 🗑️ Deleting a version only removes that specific version, not the entire object. Disable Versioning ​ You can suspend versioning but cannot delete version history retroactively. To disable (suspend) versioning: Go to the Versioning tab of the bucket. Toggle the Disable Versioning switch. 🚫 Suspended buckets will stop creating new versions , but all existing versions will remain intact. Use Cases ​ Recover accidentally deleted files Track changes to critical data over time Audit and rollback configurations Note You are billed for all versions of an object. Consider using lifecycle rules to automatically clean up older versions if storage costs are a concern. Enable Versioning Viewing Object Versions Download a Previous Version Delete a Specific Version Disable Versioning Use Cases",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams-Team_Id--projects/get",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Project ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/{Team_Id}/projects/ Request Security: API Key & Bearer Auth Path Parameters Team_Id integer required Team ID >= 0 Responses 200 Successful response with project details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 project_id integer Example: 124 project_name string Example: default-project description string or null Example: null created_by object created_at string<date-time> Example: 2023-03-22T05:27:47.892853Z updated_at string<date-time> Example: 2023-03-22T05:27:47.945762Z errors object Example: {} message string Example: Success Auth apikey : Token : Parameters Team_Id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/{Team_Id}/projects/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"project_id\" : 124 , 7 \"project_name\" : \"default-project\" , 8 \"description\" : null , 9 \"created_by\" : { 10 \"id\" : 19 , 11 \"name\" : \"shubham Chaturvedi\" , 12 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 13 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 14 } , 15 \"created_at\" : \"2023-03-22T05:27:47.892853Z\" , 16 \"updated_at\" : \"2023-03-22T05:27:47.945762Z\" 17 } 18 ] , 19 \"errors\" : { } , 20 \"message\" : \"Success\" 21 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/users-iam-accounts/get",
    "site_type": "AI/ML Platform API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight IAM Accounts get https://api.e2enetworks.com/myaccount/api/v1/gpu /users/iam-accounts/ Request Security: API Key & Bearer Auth Responses 200 Successful response with user details and roles Body application/json application/json code integer Example: 200 data array[object] id integer Example: 2421 owner object role string Example: Owner Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/users/iam-accounts/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"id\" : 2421 , 6 \"owner\" : { 7 \"id\" : 3573 , 8 \"name\" : \"Nipun\" , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"username\" : \"nipun.arora@e2enetworks.com\" , 11 \"phone\" : null , 12 \"is_primary_contact\" : true , 13 \"primary_email\" : \"nipun.arora@e2enetworks.com\" , 14 \"currency\" : \"INR\" , 15 \"is_suspended\" : true 16 } , 17 \"role\" : \"Owner\" 18 } 19 ] 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/#how-e2e-managed-encryption-affects-object-uploads-and-downloads-",
    "site_type": "Documentation",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/",
    "site_type": "Documentation",
    "content": "Security | E2E Cloud Skip to main content Security TIR AI platform security ensures that access to sensitive systems and data is tightly controlled through robust authentication methods. It leverages two key security components: API tokens and SSH keys. API tokens are used for authenticating and securing communication between services or applications, ensuring that only authorized entities can interact with the platform. Meanwhile, SSH keys provide secure, encrypted access to remote systems, facilitating safe server management and data transfer. Together, these security measures safeguard the platform from unauthorized access and ensure data integrity across the entire AI lifecycle. API Tokens Learn how to create API Tokens. SSH Keys Set up SSH-based security.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Security | E2E Cloud Skip to main content Security TIR AI platform security ensures that access to sensitive systems and data is tightly controlled through robust authentication methods. It leverages two key security components: API tokens and SSH keys. API tokens are used for authenticating and securing communication between services or applications, ensuring that only authorized entities can interact with the platform. Meanwhile, SSH keys provide secure, encrypted access to remote systems, facilitating safe server management and data transfer. Together, these security measures safeguard the platform from unauthorized access and ensure data integrity across the entire AI lifecycle. API Tokens Learn how to create API Tokens. SSH Keys Set up SSH-based security.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/SSH_Key/",
    "site_type": "Documentation",
    "content": "SSH Keys Management | E2E Cloud Skip to main content On this page SSH Keys Management Introduction ​ Setting up SSH-based security to access your server is a much more effective way than the use of a manual root password. Cracking the security system of a node depending on SSH keys is nearly impossible since it secures your node in a more sophisticated way by the use of encoded keys. Why is password-based authentication vulnerable? ​ A server can authenticate & grant access to the users with different access methods. The most basic of these is password-based authentication, which is easy to use but isn’t the most secure. Modern processing power combined with automated scripts makes brute-forcing a password-protected account very possible since passwords generally are not complex. SSH keys prove to be a reliable and secure alternative. What are SSH keys? ​ SSH key pairs are two cryptographically secure keys that can be used to authenticate a client to an SSH server. Each key pair consists of a public key and a private key. The private key is retained by the client on their local machine and should be kept secret. Any compromise of the private key will allow the attacker to log into servers that are configured with the associated public key without additional authentication. As an additional precaution, the key can be encrypted on disk with a passphrase. The public key is uploaded onto the remote server that you want to be able to log into with SSH. When a client attempts to authenticate using SSH keys, the server can test the client on whether they are in possession of the private key. If the key-pair matches, then a shell session is spawned, or the requested command is executed. How do SSH keys work? ​ A key pair will be generated on your local PC. Generating a key pair provides you with two long strings of characters: a public and a private key. The public key will be added to your node. The corresponding private key pair will be saved on your local PC. Every time you access your node, the SSH system will look up the private key pair of the public key added to it. The system will unlock only when the two keys match. You can also disable the root password after the SSH keys are set up. Note Secure the private key: Make sure that you add the public key to the servers and that the private key is saved in a secure location on your PC. Manage SSH Keys ​ This guide shows you how to access & manage your SSH keys in the E2E Networks TIR AI PLATFORM. Logging into E2E Networks ‘TIR AI PLATFORM’ ​ Please go to ‘TIR AI PLATFORM’ and log in using your credentials set up at the time of creating and activating the E2E Networks ‘TIR AI PLATFORM’. Navigate to SSH Keys ​ After you log in to the E2E Networks ‘TIR AI PLATFORM’, you can click on the left side of the TIR AI PLATFORM dashboard, then click on the “SSH Keys” sub-menu available under the services menu. Add/Delete SSH Keys ​ If you do not have SSH keys and want to create an SSH key pair to access your node, follow the tutorial for your computer OS: MAC Windows Linux ADD SSH Keys ​ Click on the Add Key button: You need to label your SSH key (optional) for easy identification purposes. You can either load the file to add the public SSH Key by clicking the ‘Load from file’ or paste the contents of your public SSH key (copy it as it is and paste it) in the SSH Key content field. Note Before you paste your public SSH keys into your content field, you must check the format of each public SSH key file that you plan to add. After adding the public key, you need to click the ‘Add Key’ button. You will be automatically routed to the ‘Manage SSH Keys’ page. Similarly, you can store multiple SSH Public Keys in TIR AI PLATFORM, which will be accessible to multiple users with different SSH keypairs. Delete SSH Keys ​ To remove a public key, click on the delete button, which will permanently delete your public key. Note Any user accessing the node from the SSH key pair will not be able to access the node once the key is removed from My Account. Using an SSH Key ​ Now the SSH key is added to your TIR AI PLATFORM, and it can be used with any new notebook that you create in the future by simply selecting the public key during the notebook creation process. You can also refer to enable/disable password-based authentication for SSH access to the server . Import SSH keys ​ To import all SSH keys from MyAccount (default project), click on the SYNC SSH button. Note If a different public key with the same name as in TIR exists in MyAccount, that key will not be imported. If the same key exists in MyAccount but with a different name, it will also not be imported. Introduction Why is password-based authentication vulnerable? What are SSH keys? How do SSH keys work? Manage SSH Keys Logging into E2E Networks ‘TIR AI PLATFORM’ Navigate to SSH Keys Add/Delete SSH Keys ADD SSH Keys Delete SSH Keys Using an SSH Key Import SSH keys",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Documentation",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Documentation",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/",
    "site_type": "Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/setup_docker_registry/",
    "site_type": "Documentation",
    "content": "Setup Docker Registry | E2E Cloud Skip to main content On this page Tutorial: Docker Registry with EOS A Docker Registry is a storage and content delivery system that holds named Docker images. Users interact with the registry by pulling or pushing images. When you run a docker pull command, the images are downloaded to your machine from a public or private Docker registry. In this tutorial, we will set up a Docker registry that uses E2E Object Store for storing and retrieving images. Prerequisites ​ Create a Bucket in E2E Object Store. Assign Bucket Writer or Admin privileges on the bucket (from step 1) to newly generated or existing Access Credentials. These credentials will be used to provide appropriate permissions to the registry server on EOS. Step 1: Configure a Registry Server ​ Docker engine by default uses a local filesystem for storing images but also supports overriding the configuration through a YAML file. Prerequisites Step 1: Configure a Registry Server",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes E2E Networks Documentation India's Top Provider of Advanced Cloud GPUs ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs , making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Why us ? 100% Human Support Unlike other cloud providers, our support team is always reachable. 99.99% Uptime SLA Uptime SLAs such that you worry less and do more. High Reliability Cloud platform powered by robust engineering to ensure high-reliability. Ready to Scale? Let's Talk? Our sales team will get in touch with you within 24-48 hours. Promise! Let's talk",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/",
    "site_type": "Cloud Computing Provider",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes E2E Networks Documentation India's Top Provider of Advanced Cloud GPUs ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs , making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Why us ? 100% Human Support Unlike other cloud providers, our support team is always reachable. 99.99% Uptime SLA Uptime SLAs such that you worry less and do more. High Reliability Cloud platform powered by robust engineering to ensure high-reliability. Ready to Scale? Let's Talk? Our sales team will get in touch with you within 24-48 hours. Promise! Let's talk",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation TIR: AI/ML Platform Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler TIR, a cutting-edge AI development platform designed to streamline the training, fine-tuning, and serving of large AI models. With optimized GPU containers, pre-configured environments (PyTorch, TensorFlow, Triton), and automated API generation, TIR offers a seamless and end-to-end solution for the AI/ML lifecycle. From model fine-tuning and scalable pipelines to team collaboration and managed inference, TIR is built to unlock the full potential of AI. With integrations like Hugging Face, Weights & Biases, and cloud storage integration options (S3, Azure Blob, Google Drive), TIR empowers teams to innovate efficiently and effectively. Start building the future of AI with TIR today! Getting Started Products & Services Developer's Guide IAM Identity and access managements. Projects Creating Projects on TIR-AI Platform Billing GPU and cpu plans billing. Security API tokens and SSH keys. BenchMarking Performance comparison tool. FAQ Frequently Asked Questions Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/active_directory/",
    "site_type": "instructional/tutorial",
    "content": "Active Directory | E2E Cloud Skip to main content On this page Active Directory Promoting Your Server to a Domain Controller ​ Open Server Manager ​ If closed, relaunch \"Server Manager\". Check for a yellow triangle warning sign near the menu bar, indicating that Active Directory Domain Services was installed. Access Post-Deployment Configuration ​ Click on the warning sign. A dropdown list with required actions (\"post-deployment configuration\") will appear. Choose \"Promote this Server\" ​ Look for the option \"Promote this server to a domain controller\". Click on it to initiate the promotion process. Add A Forest ​ At this checkpoint, a configuration wizard will open on your screen, which will guide you throughout your deployment configuration. The first step of the deployment configuration is to add a new forest. Deployment Configuration ​ Select \"Add a New Forest\" : At the \"Deployment Configuration\" checkpoint, choose the radio button labeled \"Add a new forest\". Enter Root Domain Name : Input your desired root domain name into the provided field. Proceed to Next Step : Click on the \"Next\" button to move forward in the setup process. Setting Domain Controller Options ​ Proceed to \"Domain Controller Options\" : Move ahead in the setup process. Leave Settings Untouched : Do not make any changes to the existing settings; keep them as they are. Set and Confirm Password : Enter your desired password and confirm it in the respective fields. Remember to keep a note of this password, as changing it later can be inconvenient. Configuring DNS Options ​ Navigate to DNS Options : Move to the DNS Options page in the setup process. Ignore Error Message : Encounter an error message stating there's no parent zone found and no delegation for your DNS server could be created. Click \"Next\" : Disregard the error message and proceed by clicking the \"Next\" button. Leave Settings Unchanged : Do not make any alterations to the settings at this checkpoint. Configure Additional Options ​ Enter your desired NetBIOS domain name in the given textbox. Click “Next”. Confirm Preselected Paths ​ Three or more paths will be listed on your screen. Do not change these paths. You’re not required to keep a note of these paths either. Click “next”. Review Your Selections ​ Check Selected Options : Look at the options listed on the configuration wizard at the \"Review Options\" checkpoint. Navigate Back if Needed : If changes are necessary, use the \"Previous\" button to go back to relevant checkpoints and make desired adjustments. Ensure Satisfaction : Confirm that you are satisfied with the selected options. Proceed to \"Review Options\" : Once content with the choices, click the \"Next\" button on the \"Review Options\" section. Run Prerequisites Check ​ Go to \"Prerequisites Check\" : Navigate to the \"Prerequisites Check\" checkpoint. Check Completion Status : Verify if all prerequisite checks were successfully completed. Identify Errors (If Any) : If errors are present, a list of errors will be displayed. Fix Errors : Go to the stated checkpoint for each error and make necessary fixes. Verify Success : Once errors are fixed, a green check mark with a success message will be displayed. Initiate Installation ​ Click the \"Install\" button to commence the installation process. Congratulations! You have successfully set up Active Directory on your Windows Server 2022. Next, your server machine will need to be restarted once the promotion is successfully complete. How to Connect a Client-Server to a Domain Controller ​ Navigate to Connect Client Server VM → Start → Server Manager → Local Server → Click on WORKGROUP. Now Click on Change ​ Add the Domain Name ​ Now, add the domain name that you promoted as a server in the Domain Controller server and click OK. Click OK in the Computer Name/Domain Changes dialog box, and then restart the computer. Once you have configured the client machine to the controller machine, you can verify the same on the controller machine using the provided path. Navigate to Server Manager → Tools → Active Directory Users and Computers → Domain Controller. To verify the same in the client machine, access the client machine and navigate to the Network & Internet settings. Promoting Your Server to a Domain Controller Open Server Manager Access Post-Deployment Configuration Choose \"Promote this Server\" Add A Forest Deployment Configuration Setting Domain Controller Options Configuring DNS Options Configure Additional Options Confirm Preselected Paths Review Your Selections Run Prerequisites Check Initiate Installation How to Connect a Client-Server to a Domain Controller Now Click on Change Add the Domain Name",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "instructional/tutorial",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/active_directory/#add-the-domain-name",
    "site_type": "instructional/tutorial",
    "content": "Active Directory | E2E Cloud Skip to main content On this page Active Directory Promoting Your Server to a Domain Controller ​ Open Server Manager ​ If closed, relaunch \"Server Manager\". Check for a yellow triangle warning sign near the menu bar, indicating that Active Directory Domain Services was installed. Access Post-Deployment Configuration ​ Click on the warning sign. A dropdown list with required actions (\"post-deployment configuration\") will appear. Choose \"Promote this Server\" ​ Look for the option \"Promote this server to a domain controller\". Click on it to initiate the promotion process. Add A Forest ​ At this checkpoint, a configuration wizard will open on your screen, which will guide you throughout your deployment configuration. The first step of the deployment configuration is to add a new forest. Deployment Configuration ​ Select \"Add a New Forest\" : At the \"Deployment Configuration\" checkpoint, choose the radio button labeled \"Add a new forest\". Enter Root Domain Name : Input your desired root domain name into the provided field. Proceed to Next Step : Click on the \"Next\" button to move forward in the setup process. Setting Domain Controller Options ​ Proceed to \"Domain Controller Options\" : Move ahead in the setup process. Leave Settings Untouched : Do not make any changes to the existing settings; keep them as they are. Set and Confirm Password : Enter your desired password and confirm it in the respective fields. Remember to keep a note of this password, as changing it later can be inconvenient. Configuring DNS Options ​ Navigate to DNS Options : Move to the DNS Options page in the setup process. Ignore Error Message : Encounter an error message stating there's no parent zone found and no delegation for your DNS server could be created. Click \"Next\" : Disregard the error message and proceed by clicking the \"Next\" button. Leave Settings Unchanged : Do not make any alterations to the settings at this checkpoint. Configure Additional Options ​ Enter your desired NetBIOS domain name in the given textbox. Click “Next”. Confirm Preselected Paths ​ Three or more paths will be listed on your screen. Do not change these paths. You’re not required to keep a note of these paths either. Click “next”. Review Your Selections ​ Check Selected Options : Look at the options listed on the configuration wizard at the \"Review Options\" checkpoint. Navigate Back if Needed : If changes are necessary, use the \"Previous\" button to go back to relevant checkpoints and make desired adjustments. Ensure Satisfaction : Confirm that you are satisfied with the selected options. Proceed to \"Review Options\" : Once content with the choices, click the \"Next\" button on the \"Review Options\" section. Run Prerequisites Check ​ Go to \"Prerequisites Check\" : Navigate to the \"Prerequisites Check\" checkpoint. Check Completion Status : Verify if all prerequisite checks were successfully completed. Identify Errors (If Any) : If errors are present, a list of errors will be displayed. Fix Errors : Go to the stated checkpoint for each error and make necessary fixes. Verify Success : Once errors are fixed, a green check mark with a success message will be displayed. Initiate Installation ​ Click the \"Install\" button to commence the installation process. Congratulations! You have successfully set up Active Directory on your Windows Server 2022. Next, your server machine will need to be restarted once the promotion is successfully complete. How to Connect a Client-Server to a Domain Controller ​ Navigate to Connect Client Server VM → Start → Server Manager → Local Server → Click on WORKGROUP. Now Click on Change ​ Add the Domain Name ​ Now, add the domain name that you promoted as a server in the Domain Controller server and click OK. Click OK in the Computer Name/Domain Changes dialog box, and then restart the computer. Once you have configured the client machine to the controller machine, you can verify the same on the controller machine using the provided path. Navigate to Server Manager → Tools → Active Directory Users and Computers → Domain Controller. To verify the same in the client machine, access the client machine and navigate to the Network & Internet settings. Promoting Your Server to a Domain Controller Open Server Manager Access Post-Deployment Configuration Choose \"Promote this Server\" Add A Forest Deployment Configuration Setting Domain Controller Options Configuring DNS Options Configure Additional Options Confirm Preselected Paths Review Your Selections Run Prerequisites Check Initiate Installation How to Connect a Client-Server to a Domain Controller Now Click on Change Add the Domain Name",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/active_directory/#setting-domain-controller-options",
    "site_type": "instructional/tutorial",
    "content": "Active Directory | E2E Cloud Skip to main content On this page Active Directory Promoting Your Server to a Domain Controller ​ Open Server Manager ​ If closed, relaunch \"Server Manager\". Check for a yellow triangle warning sign near the menu bar, indicating that Active Directory Domain Services was installed. Access Post-Deployment Configuration ​ Click on the warning sign. A dropdown list with required actions (\"post-deployment configuration\") will appear. Choose \"Promote this Server\" ​ Look for the option \"Promote this server to a domain controller\". Click on it to initiate the promotion process. Add A Forest ​ At this checkpoint, a configuration wizard will open on your screen, which will guide you throughout your deployment configuration. The first step of the deployment configuration is to add a new forest. Deployment Configuration ​ Select \"Add a New Forest\" : At the \"Deployment Configuration\" checkpoint, choose the radio button labeled \"Add a new forest\". Enter Root Domain Name : Input your desired root domain name into the provided field. Proceed to Next Step : Click on the \"Next\" button to move forward in the setup process. Setting Domain Controller Options ​ Proceed to \"Domain Controller Options\" : Move ahead in the setup process. Leave Settings Untouched : Do not make any changes to the existing settings; keep them as they are. Set and Confirm Password : Enter your desired password and confirm it in the respective fields. Remember to keep a note of this password, as changing it later can be inconvenient. Configuring DNS Options ​ Navigate to DNS Options : Move to the DNS Options page in the setup process. Ignore Error Message : Encounter an error message stating there's no parent zone found and no delegation for your DNS server could be created. Click \"Next\" : Disregard the error message and proceed by clicking the \"Next\" button. Leave Settings Unchanged : Do not make any alterations to the settings at this checkpoint. Configure Additional Options ​ Enter your desired NetBIOS domain name in the given textbox. Click “Next”. Confirm Preselected Paths ​ Three or more paths will be listed on your screen. Do not change these paths. You’re not required to keep a note of these paths either. Click “next”. Review Your Selections ​ Check Selected Options : Look at the options listed on the configuration wizard at the \"Review Options\" checkpoint. Navigate Back if Needed : If changes are necessary, use the \"Previous\" button to go back to relevant checkpoints and make desired adjustments. Ensure Satisfaction : Confirm that you are satisfied with the selected options. Proceed to \"Review Options\" : Once content with the choices, click the \"Next\" button on the \"Review Options\" section. Run Prerequisites Check ​ Go to \"Prerequisites Check\" : Navigate to the \"Prerequisites Check\" checkpoint. Check Completion Status : Verify if all prerequisite checks were successfully completed. Identify Errors (If Any) : If errors are present, a list of errors will be displayed. Fix Errors : Go to the stated checkpoint for each error and make necessary fixes. Verify Success : Once errors are fixed, a green check mark with a success message will be displayed. Initiate Installation ​ Click the \"Install\" button to commence the installation process. Congratulations! You have successfully set up Active Directory on your Windows Server 2022. Next, your server machine will need to be restarted once the promotion is successfully complete. How to Connect a Client-Server to a Domain Controller ​ Navigate to Connect Client Server VM → Start → Server Manager → Local Server → Click on WORKGROUP. Now Click on Change ​ Add the Domain Name ​ Now, add the domain name that you promoted as a server in the Domain Controller server and click OK. Click OK in the Computer Name/Domain Changes dialog box, and then restart the computer. Once you have configured the client machine to the controller machine, you can verify the same on the controller machine using the provided path. Navigate to Server Manager → Tools → Active Directory Users and Computers → Domain Controller. To verify the same in the client machine, access the client machine and navigate to the Network & Internet settings. Promoting Your Server to a Domain Controller Open Server Manager Access Post-Deployment Configuration Choose \"Promote this Server\" Add A Forest Deployment Configuration Setting Domain Controller Options Configuring DNS Options Configure Additional Options Confirm Preselected Paths Review Your Selections Run Prerequisites Check Initiate Installation How to Connect a Client-Server to a Domain Controller Now Click on Change Add the Domain Name",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "instructional/tutorial",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "instructional/tutorial",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/mySQL_backup/",
    "site_type": "Tutorial/Documentation",
    "content": "Backup MySQL Database to EOS | E2E Cloud Skip to main content On this page Backup MySQL Database to EOS on Linux Server Introduction ​ In MySQL, Regular backups of your Mysql data are very important to protect it from data loss. There are several types of backup options available, Here in this tutorial we will show you an easy way to backup your Mysql Database to EOS for a regular interval backup using Linux s3cmd Bash script. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Linux Server with Root access MySQL database credentials. Setting up s3cmd on your server. If you haven't set it up, please refer to the tutorial: Setting up s3cmd . Step 1: Configure Backup Script ​ The shell script provided below is used to back up your database and upload it to S3. Copy and paste the script below on your server with the filename mysqlbackup.sh . To create a file: vim mysqlbackup.sh Edit the below script and add your database credentials , Bucketname and your backup location details #!/bin/bash #Enter the details below # Database credentials USER=\"Username\" PASSWORD=\"YourPassword\" HOST=\"localhost\" DBNAME=\"DatabaseName\" #Enter the Bucket details S3BUCKET=\"s3://YourBucketName\" #Backup_Details LOCATION=\"/tmp/backups\" TIMESTAMP=$(date +\"%d-%b-%Y-%H:%M:%S\") #---------------------------------------------# #Basic Script mysqldump -h$HOST -u$USER -p$PASSWORD $DBNAME | gzip -9 > $LOCATION/$DBNAME-$TIMESTAMP.sql.gz s3cmd sync -r $LOCATION/* $S3BUCKET/ rm -rf $LOCATION/* Note The above script is a Basic Script configured as an Example,You can modify it as per your Need. Step 2 : Make the backup script Executable ​ chmod +x mysqlbackup.sh Run the script to make sure it is working ./mysqlbackup.sh If the above scripts run fine, then your script is now ready. We can now schedule it with Cron Step 3 : Schedule it with Cron ​ Now, We can schedule the BackupScript to Run it Daily or on Weekly basis as per our requirement. Assuming the backup script is available on /opt/scripts ,Edit the crontab file and add below Line To Edit the Crontab File,You can use below command crontab -e Add below Line to backup your script weekly 0 0 * * 0 bash /opt/scripts/mysqlbackup.sh to >/dev/null 2>&1 Conclusion ​ Now you have your database backup (dump) in your EOS bucket. If you face any issues while configuring the same and need assistance, you can contact cloud-Platform@e2enetworks.com where our team can assist you. Introduction Prerequisites Step 1: Configure Backup Script Step 2 : Make the backup script Executable Step 3 : Schedule it with Cron Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Tutorial/Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Tutorial/Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Tutorial/Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/mySQL_backup/#step-2--make-the-backup-script-executable",
    "site_type": "Tutorial/Documentation",
    "content": "Backup MySQL Database to EOS | E2E Cloud Skip to main content On this page Backup MySQL Database to EOS on Linux Server Introduction ​ In MySQL, Regular backups of your Mysql data are very important to protect it from data loss. There are several types of backup options available, Here in this tutorial we will show you an easy way to backup your Mysql Database to EOS for a regular interval backup using Linux s3cmd Bash script. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Linux Server with Root access MySQL database credentials. Setting up s3cmd on your server. If you haven't set it up, please refer to the tutorial: Setting up s3cmd . Step 1: Configure Backup Script ​ The shell script provided below is used to back up your database and upload it to S3. Copy and paste the script below on your server with the filename mysqlbackup.sh . To create a file: vim mysqlbackup.sh Edit the below script and add your database credentials , Bucketname and your backup location details #!/bin/bash #Enter the details below # Database credentials USER=\"Username\" PASSWORD=\"YourPassword\" HOST=\"localhost\" DBNAME=\"DatabaseName\" #Enter the Bucket details S3BUCKET=\"s3://YourBucketName\" #Backup_Details LOCATION=\"/tmp/backups\" TIMESTAMP=$(date +\"%d-%b-%Y-%H:%M:%S\") #---------------------------------------------# #Basic Script mysqldump -h$HOST -u$USER -p$PASSWORD $DBNAME | gzip -9 > $LOCATION/$DBNAME-$TIMESTAMP.sql.gz s3cmd sync -r $LOCATION/* $S3BUCKET/ rm -rf $LOCATION/* Note The above script is a Basic Script configured as an Example,You can modify it as per your Need. Step 2 : Make the backup script Executable ​ chmod +x mysqlbackup.sh Run the script to make sure it is working ./mysqlbackup.sh If the above scripts run fine, then your script is now ready. We can now schedule it with Cron Step 3 : Schedule it with Cron ​ Now, We can schedule the BackupScript to Run it Daily or on Weekly basis as per our requirement. Assuming the backup script is available on /opt/scripts ,Edit the crontab file and add below Line To Edit the Crontab File,You can use below command crontab -e Add below Line to backup your script weekly 0 0 * * 0 bash /opt/scripts/mysqlbackup.sh to >/dev/null 2>&1 Conclusion ​ Now you have your database backup (dump) in your EOS bucket. If you face any issues while configuring the same and need assistance, you can contact cloud-Platform@e2enetworks.com where our team can assist you. Introduction Prerequisites Step 1: Configure Backup Script Step 2 : Make the backup script Executable Step 3 : Schedule it with Cron Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Tutorial/Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/Release-Notes/?myaccount=true",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "Release Notes | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Release Notes Filter By: Product All Products Product MyAccount TIR:AI/ML Platform July 4, 2025 EOS Encryption New You can now enable encryption for your EOS buckets. When creating a bucket in the E2E Object Storage service, encryption check box is enabled by default-ensuring that all objects stored within are automatically encrypted using E2E-managed keys. For More Info Click here July 4, 2025 SFS Encryption New We are excited to announce the introduction of encryption support for SFS (Shared File System). This feature enhances data security by allowing users to enable encryption at the time of SFS creation. For More Info Click here July 3, 2025 VPC Subnet New We’re thrilled to announce the launch of VPC and Subnet configuration for nodes. Users can now create custom VPCs with private CIDR blocks and define subnets within them for more granular control . For More Info Click here July 3, 2025 Auto Scale Encryption New We’re thrilled to announce the launch of the Autoscale Encryption feature.This powerful enhancement enables users to protect data on Nodes within Autoscaling Groups using advanced, industry-standard full-disk encryption methods. By enabling Autoscale Encryption, all data at rest on the Nodes is automatically encrypted, ensuring that sensitive information remains secure even in dynamic scaling environments.This feature significantly enhances the security posture of your Autoscaling infrastructure while also helping meet data protection and compliance requirements with ease. For More Info Click here June 30, 2025 Floating IP New We’re excited to announce the launch of Floating IP within Reserve IP. Users can now attach a Floating IP to up to 4 nodes, enabling greater flexibility, high availability, and improved reliability in their network setup. For More Info Click here June 30, 2025 Pause and Resume Alerts New We’re thrilled to announce support for pause or resume alerts on demand using a single action. Useful for temporarily silencing notifications during maintenance or expected changes. For More Info Click here June 30, 2025 Node New Trigger Volume Read-ops/Write-ops New We’re thrilled to announce support for alerts on Node Volume Read and Write operations. This helps monitor I/O-heavy nodes and receive notifications when thresholds are crossed. For More Info Click here June 30, 2025 Activity Timeline in Audit Logs of Node New A new Activity Timeline tab has been introduced in the Audit Logs section of the Node. It presents a clear, chronological view of all actions performed on the node, along with their timestamps and success/failure status indicators. For More Info Click here June 24, 2025 Resource Listing in Tickets New A new resource dropdown has been added to the Cloud Platform Ticket form. This allows users to optionally select the relevant resource while raising a ticket. Previously, users had to manually specify the resource in the description field. For More Info Click here June 19, 2025 GPU Functions New We’re excited to announce support for GPU-based functions. Now you can run serverless workloads that require GPU acceleration—ideal for machine learning, AI inference, and high-performance computing—directly on our Functions platform. For More Info Click here Results Per Page 10 ​ 1–10 of 81 Previous Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/monitoring/introduction/#types-of-trigger-parameters",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction E2E Networks nodes and load balancers are monitored for commonly tracked parameters to ensure server health in real-time. The information is visually represented on the MyAccount portal. MyAccount also allows you to easily configure alert policies and set email notifications to respond quickly when server health alerts are triggered, aiding in better planning and proactively resolving potential issues. In this guide, we’ll cover how to view monitoring graphs and set alerts through the MyAccount portal. Login to MyAccount portal Once logged in to My Account , select the 'Nodes' or 'Load Balancer' sub-menu under the Products menu on the left side of your dashboard. Clicking on a node redirects you to the 'Manage Node' page. Your running nodes will be listed, and you can create an E2E Node if none exist. Clicking on a load balancer redirects you to the 'Manage Load Balancer' page. Your running load balancers will be listed, and you can create an E2E load balancer if none exist. Monitoring Graphs ​ Server health monitoring is a free service that provides insights into resource usage across your infrastructure. Different display metrics help track the operational health of your infrastructure. Select the node or load balancer to view the metrics. General Information ​ Check Disk and RAM information in the “Node Details” or “Load Balancer Detail” tab. Disk Space ​ Monitor the used and free space on your disk. Memory Usage ​ Monitor the overall used and free RAM. Click on the ‘Monitoring’ tab to check CPU performance, disk read/write operations, and network traffic statistics. CPU Load ​ CPU Load expresses how many processes are waiting in the queue to access the computer processor—used to estimate system performance. It can vary according to the type and amount of computing task because some tasks require substantial CPU time which causes slow performance, errors, and increased load while others require less CPU time. CPU Utilization ​ CPU Utilization indicates the percentage of total processing power currently in use by your resource. It helps assess how efficiently the CPU is being used and can reveal performance bottlenecks caused by high or consistently maxed-out usage. Disk Read Operation ​ Monitor the IOPS of disk read operation on your resource. Disk Write Operation ​ Monitor the IOPS of disk write operation on your resource. Disk Utilization ​ Monitor the overall disk utilization of your resource, indicating the percentage of time the disk is actively processing read or write operations. Memory Utilization ​ Memory Utilization shows the percentage of RAM currently in use by your resource. High memory usage may indicate resource-intensive applications or processes running on the system, and can impact performance if usage approaches the total available memory. Monitoring Alerts ​ Server Health Alerts give you the ability to create triggers about your server's performance and resource utilization metrics, which timely notifies you about any subsequent behavior changes. For this, you need to specify the rules to receive notifications or invoke actions when there is any metric change to the underlying infrastructure. The alerting system works by sending automatic response notifications to a user-defined email list when the value of the metric relative to a preset threshold level changes. Server health alerts are created by default for your newly created virtual node or load balancer using the following recommended parameters. You can also set up new alerts by defining trigger parameters as per your use case. Types of Trigger Parameters: ​ Processor Load : Set the Processor load threshold value (we recommend >10). The alert compares the actual processor load of the node to this threshold and sends notifications when conditions are met (e.g., higher than, less than, equal to, or not equal to the defined value). Consumed Memory : Set the memory utilization level (we recommend <15%). The alert compares actual free and memory utilization of the node against this threshold to decide when to notify. Percentage Free Disk Space : Set the disk space utilization level (we recommend <15%). Notifications are triggered when actual disk space utilization meets the set conditions. Web Check : A web URL monitoring tool that creates alerts on the following conditions: Success Code 200 : The request was fulfilled. Text Match : Web Check crawls a given URL and verifies text. Notifications are sent if differences from the standard text are detected. Max Web Check Limit : 5 URLs. Volume Read Ops Monitors the number of read operations on a storage volume.Set a threshold to receive alerts when read operations exceed or fall below defined limits useful for detecting performance bottlenecks or unusual activity. Volume Write Ops Tracks the number of write operations on a storage volume.Configure thresholds to get notified when write activity crosses expected bounds helpful for identifying potential I/O spikes or disk usage issues. Setup Monitoring Alert for Node ​ Go to the “ Node” page and navigate to the node details section for the desired node. Click on the ‘Alerts’ tab. Click the ‘Create Alert’ button to open the Create Alert window. Select Trigger Type . Select Trigger Operator . Define the Threshold Value (%) . Notifications are triggered when conditions are met. Select Severity . Select the User Group you want to send the alert to. Learn more about User Groups here . Click the ‘Create’ button to save the alert. View created alerts in the Alerts section. Create User Group ​ While setting up an alert, click the ‘+’ button to create a new user group. Enter the group name and click the 'Select' button to add users. Select users from the list and click 'Add' to include them. Click the ‘Create’ button to finalize the user group. Pause and Resume Node Alerts ​ You can pause or resume specific node alerts directly from the Alerts tab in the MyAccount portal. This is useful during maintenance or known issue periods when you want to temporarily disable notifications without deleting the alert. Pause Node Alert ​ Go to the Node page and click the Alerts tab. In the Actions column, click the yellow pause icon for the alert you wish to pause. A confirmation popup will appear: This will stop the trigger across all configured user groups until you choose to resume them. Click Cancel to abort or Pause to confirm the action. The alert status will now reflect the paused state. No notifications will be sent while the alert is paused. Resume Node Alert ​ In the Node → Alerts tab, find the paused alert you want to re-enable. Click the resume icon under the Actions column. A confirmation popup will appear: Click Cancel to dismiss or Resume to re-enable the alert. The alert will now be active and start triggering based on the configured conditions. ✅ Note : Pause/Resume operations do not delete the alert. They only temporarily stop or restart the monitoring triggers across the user groups linked to the alert. Setup Monitoring Alert for Load Balancer ​ Go to the “Manage Load Balancer” page, select the desired load balancer, and click the ‘Alert’ tab. Click the ‘Create Alert’ button to open the Create Alert window. Select Trigger Type . Select Trigger Operator . Define the Threshold Value (%) . Select Severity . Select the User Group you want to send the alert to. Learn more about User Groups here . To create a new user group, click the ‘+’ button. The process is the same as described in Node Monitoring. Learn more here . Click the ‘Create’ button to save the alert. View created alerts in the Alerts section. Pause and Resume Load Balancer Alerts ​ You can pause or resume specific load balancer alerts directly from the Alerts tab in the MyAccount portal. This is helpful during maintenance or troubleshooting periods when alert notifications need to be temporarily disabled without deleting the configuration. Pause Load Balancer Alert ​ Go to the Manage Load Balancer page and click the Alerts tab. In the Actions column, click the pause icon next to the alert you want to pause. A confirmation popup will appear: This will stop the trigger across all configured user groups until you choose to resume them. Click Cancel to abort or Pause to confirm. The alert status will be updated to reflect that the alert is paused. No alert notifications will be triggered until it is resumed. Resume Load Balancer Alert ​ In the Manage Load Balancer → Alerts tab, locate the paused alert. Click the resume icon in the Actions column. A confirmation popup will appear: Are you sure you want to resume this alert? Click Cancel to dismiss or Resume to reactivate the alert. The alert will now be active and begin triggering again based on the defined conditions. ✅ Note : Pause/Resume operations do not modify or delete your alert rules. They simply suspend or reactivate alert notifications as needed. If an alert condition is met, users in the specified user groups will receive a notification. Troubleshooting Steps if the Monitoring Data is not visible ​ Monitoring is pre-configured and data should be visible within 5–10 minutes post-launch. If data isn’t visible: Step 1: Ensure Zabbix-agent is running ​ Check the agent's status: service zabbix-agent status Monitoring Graphs General Information Disk Space Memory Usage CPU Load CPU Utilization Disk Read Operation Disk Write Operation Disk Utilization Memory Utilization Monitoring Alerts Types of Trigger Parameters: Setup Monitoring Alert for Node Create User Group Pause and Resume Node Alerts Pause Node Alert Resume Node Alert Setup Monitoring Alert for Load Balancer Pause and Resume Load Balancer Alerts Pause Load Balancer Alert Resume Load Balancer Alert Troubleshooting Steps if the Monitoring Data is not visible Step 1: Ensure Zabbix-agent is running",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/others/support_tickets/",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "Support ticket | E2E Cloud Skip to main content On this page Support ticket This feature is provided in order to get in touch with our 24x7 support team whenever required. You can create and track support tickets using this page. As of now, we have two categories: Cloud Platform - For all technical support related to the cloud services. Billing - Billing and Payment related queries select Billing type tickets. Create Support Ticket ​ To access the ticketing portal, click on the Cloud Platform. You will be redirected to the \"Support\" page. To create a new ticket, click on the “Create Ticket” button. You will be redirected to the \"New Ticket\" page, where you can fill in the required information. Type: Choose the respective category of ticket created. Service: Select the service for which you want to create the ticket. Resource: Select the resource for which you want to create the ticket. CC: The CC list will display customers associated with the owner's account. If \"Cloud\" is selected, only Admin and Technical customers will appear in the CC list. Once a member of any type is selected, you can add CC emails for customers when creating Zoho Desk tickets, allowing them to include their IAMs in the thread. Note For Cloud-type tickets, you can select up to 10 CC members. This feature is only enabled for Cloud-type tickets. Subject: It can be a tagline for the reported issue. Description: Please share the issue observed in detail (with information like server IP, domain name, etc.) and attach the relevant screenshot which can represent the issue. Click the \"Submit Ticket\" button to create a support ticket. The created ticket will be displayed like below and our team will check and reply on the same shortly. You can further continue the conversation with our team using ticket comments option. Once the reported issue has been resolved, you can close the ticket by clicking the close button. Create Support Ticket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/sfs/intro/#introduction-to-sfs-encryption",
    "site_type": "Software/Cloud Service Release Notes",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Scalable File System is designed to provide simple, scalable, and highly available file storage for cloud-based applications and services. It allows multiple E2E Nodes to access the same file system concurrently, enabling shared file storage across instances. The Scalable File System is commonly used for applications that require shared file storage, such as content management systems, web serving, big data analytics, and development environments. It simplifies the management and provisioning of file storage in the cloud, allowing applications to scale seamlessly and reliably. Create Scalable File System ​ If you want to create a Scalable File System, just go to the left sidebar under the dashboard section, then go to Storage -> Scalable File System . Then click on the Create button to create a Scalable File System. After clicking on Create Scalable File System , give a name to your SFS, select the plan and VPC, and then click on the Launch SFS button. After clicking on the Launch SFS button, your created Scalable File System will be shown like this. Activate Backup ​ You can click Activate Backup under Actions for a particular SFS. The Activate Backup popup will open. You can select a particular backup time and click on the Activate button. After activating the backup, the backup status will be First run pending . Once the backup service is enabled and the status changes from First Run Pending to Backup Available , you can see the backup details under the Backup tab. Deactivate Backup ​ After successfully activating the backup, you can deactivate the backup by clicking Deactivate Backup under Actions . After that, a pop-up will appear. If you click on the Deactivate button, the backup will be deactivated successfully. Grant all access ​ warning If you will grant all access, you will not be able to configure ACL. To configure ACL you have to disable all access. To grant all access, select a particular SFS (Scalable File System) and click on Grant All Access under Actions . After clicking the Grant All Access action, you will see the popup below. If you click on the Grant button, it will grant full access, enabling all resources like Nodes, Load Balancers (LB), Kubernetes, and DBaaS within the same VPC to access this SFS. The permission has been granted, and the process has started. It should be completed within a few minutes. You can view the configured Virtual Private Cloud (VPC) under the ACL tab. Disable All Access ​ warning If you disable all access, it will deny full access to all resources such as Nodes, Load Balancers, Kubernetes, and DBaaS within the same VPC from accessing this SFS. If you want to disable all access from SFS (Scalable File System), click on Disable All Access under Actions . After clicking Disable All Access , you will see the popup below. If you click the Disable button, access will be disabled from all services. The disable access process has started. It should be completed within a few minutes. You can view the configured Virtual Private Cloud (VPC) under the ACL tab. Convert to Committed ​ Click on Convert to Committed Button. After selecting committed plan,Click on Convert Button. Committed Settings ​ Click on Committed Settings Button. After selecting committed settings.Click on Update Settings Button Delete SFS ​ ACL ​ Using ACL configuration, you can give permission to allow a Node to access the SFS. To configure ACL, go to the ACL tab and click on Configure ACL . After clicking on Configure ACL , the nodes attached to the same VPC network will be shown. Select the permissions according to your requirement and click on the Allow button to attach the Node to SFS. After clicking the Allow button, the node will go into Configuring status, and after some time, it will return to Available status. How to Access Scalable File System (SFS)? ​ You need to connect your machine and follow these commands to mount the SFS. 1) For YUM Package Manager ​ Step 1 : Install nfs-utils on your machine using the yum package installer. yum update yum install nfs-utils Step 2 : Make a MOUNT_POINT mkdir MOUNT_POINT Step 3 : Mount SFS on your machine. mount -t nfs -o soft,timeo=n, retrans=n, retry=n, SFS_SERVER_ENDPOINT:/data MOUNT_POINT soft - When NFS tries to access a soft-mounted directory, it gives up and returns an error message after trying retrans times. timeo - The timeout, in tenths of a second, for requests (read and write requests to mounted directories). If a request times out, this timeout value is doubled, and the request is retransmitted. Maximum value is 30 seconds, and the default value is 7 seconds. retrans - The number of times a request (a read or write request to a mounted directory) is retransmitted after it times out. If the request does not succeed after n retransmissions, a soft mount returns an error. The default value is 4. retry - The number of times the client attempts to mount a directory after the first attempt fails. The default value is 1. 2) For APT Package Manager ​ Step 1 : Install nfs-common on your machine using the APT package installer. sudo apt update sudo apt install nfs-common Step 2 : Make a MOUNT_POINT mkdir MOUNT_POINT Step 3 : Mount SFS on your machine. mount -t nfs -o soft,timeo=n, retrans=n, retry=n, SFS_SERVER_ENDPOINT:/data MOUNT_POINT soft - When NFS tries to access a soft-mounted directory, it gives up and returns an error message after trying retrans times. timeo - The timeout, in tenths of a second, for requests (read and write requests to mounted directories). If a request times out, this timeout value is doubled, and the request is retransmitted. Maximum value is 30 seconds, and the default value is 7 seconds. retrans - The number of times a request (a read or write request to a mounted directory) is retransmitted after it times out. If the request does not succeed after n retransmissions, a soft mount returns an error. Default value is 4. retry - The number of times the client attempts to mount a directory after the first attempt fails. Default value is 1. 3) For Windows Machine ​ Step 1 : Make sure you have an NFS Client (Services for NFS) installed from Programs and Features. Step 2 : Mount SFS to a drive. mount -t nfs -o soft,timeo=n, retrans=n, retry=n, SFS_SERVER_ENDPOINT:/data drive: soft - When NFS tries to access a soft-mounted directory, it gives up and returns an error message after trying retrans times. timeo - The timeout, in tenths of a second, for requests (read and write requests to mounted directories). If a request times out, this timeout value is doubled, and the request is retransmitted. Maximum value is 30 sec and the default value is 7 sec. retrans - The number of times a request (a read or write request to a mounted directory) is retransmitted after it times out. If the request does not succeed after n retransmissions, a soft mount returns an error. Default value is 4. retry - The number of times the client attempts to mount a directory after the first attempt fails. Default value is 1. Disallow Node ​ Now to disallow the node, again go to the ACL tab and click on the Disallow button to remove the established connection. Snapshot ​ Upon clicking the \"Snapshot\" tab, the Snapshot page will open, providing options for managing snapshots. These steps manage snapshots within the SFS (Scalable File System) service. Snapshots play a crucial role in capturing data states at specific points in time, allowing for data recovery, replication, and scheduled snapshot creation. Creating a Snapshot Manually ​ To create a snapshot manually, locate the \"Snapshot Now\" button on the Snapshot page and click on it. A pop-up will appear; click on the \"Create Snapshot\" button within the pop-up to confirm the snapshot creation. After the snapshot is successfully created, it will be displayed in the snapshot list on the Snapshot page. Actions on Snapshots ​ To perform actions on a snapshot, click on the three-dot \"Actions\" menu icon for the respective snapshot. Clone a SFS ​ Click on the \"Clone\" option within the \"Actions\" menu to initiate the cloning process. On the \"Clone SFS\" page, select the desired Virtual Private Cloud (VPC), then click on \"Clone SFS\" to proceed. The cloned SFS will be added to the list. Upgrade SFS ​ To upgrade the SFS associated with a snapshot, click on the \"Upgrade\" action for that snapshot. On the upgrade page, select the desired plan for upgrading the SFS, and then click on the \"Upgrade\" button. Delete a Snapshot ​ To delete a snapshot, click on the \"Delete\" action for the specific snapshot. A pop-up will appear; click on the \"Confirm Delete\" button to permanently delete the snapshot. Schedule Snapshot ​ To schedule snapshots, click on the \"Schedule Snapshot\" link. Configure the snapshot interval and specify the time when you want to take scheduled snapshots. Click on the \"Save Changes\" button. Edit Schedule Snapshot Settings ​ After successfully scheduling a snapshot, you can edit it by clicking \"Edit schedule snapshot settings.\" Disable Scheduled Snapshots ​ To disable the scheduled snapshot, click on the \"Disable\" button after clicking on Edit Schedule Snapshot settings. After that, a pop-up will appear for Disable Schedule Snapshot; then click on Confirm. Configure Snapshot Lifecycle ​ To Configure Snapshot Lifecycle, click on \"Configure Snapshot Lifecycle.\" Select the interval after which the scheduled snapshots should be deleted. Edit Lifecycle Settings ​ After successfully scheduling a snapshot, you can edit it by clicking \"Edit schedule snapshot settings.\" Disable Scheduled Snapshots ​ To disable the scheduled snapshot, click on the \"Disable\" button after clicking on Edit Schedule Snapshot settings. After that, a pop-up will appear for Disable Schedule Snapshot; then click on Confirm. info By following these steps, you can effectively manage snapshots, perform various actions, and ensure the data integrity and availability of your files within the SFS service. Backup ​ To enable the backup of any SFS, select a particular SFS, go to the Backup tab, and click on \"Click here to enable it.\" Activate Backup pop-up will open; you can select a particular backup time and click on the \"Activate\" button. Once the backup service is enabled and the status changes from ‘First Run Pending’ to ‘Backup Available’. Backup Now ​ Create Scalable File System Activate Backup Deactivate Backup Grant all access Disable All Access Convert to Committed Committed Settings Delete SFS ACL How to Access Scalable File System (SFS)? 1) For YUM Package Manager 2) For APT Package Manager 3) For Windows Machine Disallow Node Snapshot Creating a Snapshot Manually Actions on Snapshots Clone a SFS Upgrade SFS Delete a Snapshot Schedule Snapshot Edit Schedule Snapshot Settings Disable Scheduled Snapshots Configure Snapshot Lifecycle Edit Lifecycle Settings Disable Scheduled Snapshots Backup Backup Now",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/myaccount/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation MyAccount Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs, making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Getting Started Compute Storage Database Network Billing Sign Up Process for Indian and International Customers Sign In Sign In Methods IAM Identity and Access Management Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation MyAccount Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs, making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Getting Started Compute Storage Database Network Billing Sign Up Process for Indian and International Customers Sign In Sign In Methods IAM Identity and Access Management Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/iam/",
    "site_type": "Cloud Computing Provider",
    "content": "IAM | E2E Cloud Skip to main content On this page IAM Policy-Based Access Control (PBAC) is a mechanism for managing user access to individual or multiple systems, where the permissions granted are contingent upon the user's business responsibilities aligned with predefined policies or custom policies. In contrast to the conventional method of auditing and modifying roles organization-wide, PBAC provides the agility to swiftly adjust access privileges in response to evolving requirements. This ensures that assets remain safeguarded through the enforcement of established rules and policies. PBAC stands out as a versatile authorization solution, capable of accommodating various access points by automating security controls within applications and data. IAM (Identity and Access Management) ​ IAM Model Overview: ​ IAM, which stands for Identity and Access Management, encompasses a structured system for managing user identities and their access privileges within an account. The IAM model comprises various user roles and their corresponding permissions. Key Concepts: ​ IAM Entry: Each IAM entry contains mappings with a primary customer and their associated secondary users. Instead of referencing a contact person table, information regarding secondary users is stored within the IAM table. IAM User Types: Owner: Represents the primary account holder. Primary: Users with existing sign-ups on the platform who can access other accounts using the Primary IAM feature, also known as Multi-CRN view. Multi CRN ​ A Multi-CRN perspective offers users the ability to toggle between multiple CRNs (Customer Reference Numbers). This occurs when a customer (Customer A) who is already registered grants access to some of their projects to another customer (Customer B) who is also registered. As a result, Customer B can access Customer A's projects by switching between their respective CRNs. Contact: Users without existing sign-ups on the platform. Roles and Permissions ​ Roles Resource View Resource Management IAM (User Management) Billing Operations (Pay Now, Auto Pay, and Account Statement) Payment Reminders/Invoice Handling Admin ✓ ✓ ✓ ✓ ✓ Project Lead ✓ ✓ ✓ (except Admin) × × Billing × × × ✓ ✓ Member Policy-based Access Policy-based Access × Policy-based Access × Billing+Member Policy-based Access Policy-based Access × ✓ ✓ Viewer ✓ × × × × Admin: Holds full access rights, including the management of resources and projects, access to the billing dashboard, the handling of invoices, and the ability to add or remove other IAM users. Administrators are essentially co-owners of the account. Project Lead: Has access to resource allocation and project management, with the authority to add or remove other IAM users (excluding Admins). The Project Lead does not have access to billing. Billing User: Authorized to manage billing functions such as Pay Now, Auto Pay, and Account Statements, including viewing and paying outstanding balances, accessing invoices, and configuring auto-pay settings. Member: Users with limited access to the account, with the ability to select services and adhere to established policies that restrict their view within services. Unauthorized attempts to access restricted services or perform restricted actions will redirect them to an unauthorized page. Billing+Member: Users with restricted service access but unrestricted access to the billing dashboard. They can perform any action within the billing dashboard without restrictions. Viewer: Has read-only access to view resources. Cannot create, modify, or delete resources. Suitable for users who only need visibility. Note To use IAM, you have to follow these steps: You have to add an IAM user. You have to create a project. You have to create custom policies or you can use predefined policies. Assign the project and policies to the user. Add User ​ To add users, follow these steps: Navigate to the IAM section on the Dashboard. By default, the details of Owner are displayed in the list. To add a new user to the project, simply click on the 'Add User' option. After selecting \"Add User,\" a new page labeled \"Add New User\" will open. On this page, you need to enter the user's email and choose a role from the dropdown menu. The available roles include Member, Billing, Project Manager, Admin, and Billing+ Member. If you choose the role of Admin, Project Manager, or Billing, predefined policies will be applied to the user based on their role. After selecting all the parameters, click on Add User. Note In the absence of an available policy in the project, you must initially add a custom policy to the project. If you choose the role of \"Member,\" all available projects will be displayed below. After selecting a specific project, you can then assign one or more policies to that user. Upon selecting \"Add User,\" the user will appear in the IAM page under the \"All Users\" section with the status set as 'Invited.' An invitation link will be sent to the user's email address. After clicking the link, a registration form will be presented for completion. Upon completing all the required details in the registration form, the user will be successfully registered. Following registration, the customer must log in using their provided credentials. Note If the customer is an existing user on the E2E platform, they will find the invitation in the Invitation section on the Dashboard. Upon selecting the Invitation button, the Invitation page will be displayed. On the Manage Invitations page, you can view the invitations received and take actions such as accepting or declining them based on your preference. Upon accepting the invitation, the user will appear in the All User list with their assigned role. Actions ​ Reset Password: ​ Click on the \"Reset Password\" action to reset a member's password. Edit Roles and Policies: ​ To modify the roles and policies of a member, click on the Edit action. Once you have made the necessary changes, click on the \"Update User\" button to save the modifications. Delete User: ​ To remove a user, click on the Delete action. Upon selecting the delete action button, a confirmation pop-up will appear on the page. Click on the delete button within the pop-up to confirm the deletion, and the user will be removed from the user list. Manage Project ​ Project Management ​ To manage projects, navigate to the IAM page and click on the Manage Project tab. By default, a Default Project will be displayed in the list. To create a new project, provide a name for the project and click on the Create button. Once a project is created, it will be visible in the Recent tab. To switch from one project to another, select the desired project by clicking on the radio button. A pop-up will appear, prompting you to click on \"Switch Project.\" Upon doing so, the switch will be completed, and you'll be in the selected project. To designate a project as a starred project, click on the star button located in the Starred section. To view all projects, click on the \"All\" section, where you can see a comprehensive list of all projects associated with that user. Member Management ​ Add Member: ​ To modify a project and add members, click on the edit button associated with that project. Upon clicking the edit button, you will find the option to add members to the project. Click on it to proceed. Following the selection of \"Add Member,\" the Add Member page will open. After entering all the necessary information, such as the new member's details and policies, click on \"Save Changes\" to confirm. Modify User's Policy: ​ To modify a user's policy, click on the edit button and then select the appropriate option on the right button. Remove Member: ​ To remove a member from the project, click on the delete button. A popup will appear, and upon confirmation by clicking the Delete button within the popup, the member will be successfully deleted from the project. Policy Set ​ To access established policies, go to the IAM page and select the Policy Set section. If you wish to create a new policy, click on the \"Add Policy\" button. After clicking on Add Policy, the Add New Policy page will appear where you need to give the policy set name and description and select the services to be granted access in this policy, then click on the Save button. Upon saving the policy, it will be displayed in the Policy Set section on the IAM page. To execute actions on a policy set, click on the three dots, and a menu of actions will appear. To view the policy services, select the \"View\" action. Upon selecting the \"View\" action, the Services page will open, allowing you to see all the services associated with that policy. To modify the policy set, click on the \"Edit\" action. Upon choosing the \"Edit\" action, the Edit Policy Set Details page will open. On this page, you can add or remove services from the policy set by ticking or unticking the respective options. After making the desired changes, click on the Save button. To remove a policy set, click on the \"Delete\" action. Upon selecting the \"Delete\" action, a pop-up will appear. Click on \"Delete\" within the pop-up, and the policy set will be removed from the policy set list. IAM (Identity and Access Management) IAM Model Overview: Key Concepts: Multi CRN Roles and Permissions Add User Actions Reset Password: Edit Roles and Policies: Delete User: Manage Project Project Management Member Management Policy Set",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/",
    "site_type": "Cloud Computing Provider",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/",
    "site_type": "Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Documentation",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Documentation",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/private_cluster/",
    "site_type": "Documentation",
    "content": "Private Cluster | E2E Cloud Skip to main content On this page Private Cluster Private Cluster enables the creation of a dedicated environment with a predefined allocation of GPU resources. The pricing for the Private Cluster is fixed, unaffected by the actual usage percentage of the allocated resources. Additionally, deploying Nodes, Inference engines, or Vector Databases within the Private Cluster incurs no extra charges. Create Private Cluster ​ To create a new Private Cluster , click the Create Private Cluster button. Select the desired Cluster Configuration by choosing the appropriate machine type with the required GPU and an available plan. Additionally, you can apply filters to the available resources based on CPU , RAM , or GPU Card specifications. On this page, you can view the details of the selected plan. Depending on whether you choose an Hourly-Billed Plan or a Committed Plan , the summary section will display the corresponding details and associated costs. Private Cluster Hourly plan ​ You can select an Hourly-Based Plan based on your requirements, view the estimated cost, and then click Next to proceed. Private Cluster Committed plan ​ In a Private Cluster with a committed plan, users can choose one of the following post-expiry actions: auto-renew the committed plan, auto-start hourly billing, or automatically delete the cluster after expiry. Manage Private Cluster ​ Overview ​ You can view the details of the selected Private Cluster , including the Cluster Name , Number of Nodes , Plan Name , and the Cluster Node Configuration , which displays the count of GPUs , CPUs , and RAM allocated within the cluster. Monitoring ​ You can view the Disk Usage and Memory Usage for the selected Node within the Private Cluster . Additionally, the following metrics are also available: GPU Utilization , GPU Temperature , CPU Utilization , Memory Utilization , Disk Total Read Bytes , and Disk Total Write Bytes . Services ​ You can view the list of Services that have been launched on the cluster. Actions ​ In the Actions section, you can perform two operation which is Update cluster in which you can increase the Node count and Delete cluster . Update Private Cluster ​ In Actions section, click on Update Cluster . To update the node count, click on the Additional Node Count (+) button and increase the nodes as per your requirements. Delete Private Cluster ​ In Actions section, click on Delete Cluster and confirm. Create Private Cluster Manage Private Cluster Overview Monitoring Services Actions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/#tir-users",
    "site_type": "Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/#e2e-managed-encryption-and-object-versioning",
    "site_type": "Documentation",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-github-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/GettingStarted/#scaler",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction E2E Auto scaling enables you to dynamically scale compute nodes based on varying workloads and a defined policy. Using this feature, you can meet the seasonal or varying demands of infrastructure while optimizing the cost. The core unit of EAS is a scale group. The following list covers the features and capabilities of scale groups: Rule-based Policy setup for adding nodes based on workload Integration with Load Balancer to automatically list or de-list backend servers Automatic removal of nodes when utilization falls below a set threshold SSH access to each node enables activities like log viewing, debugging, etc. Before you define your first scale group, we recommend familiarizing yourself with concepts and terminologies. Concepts ​ Application Scaling helps you offer consistent performance for your end-users during high demand and also reduce your spend during periods of low demand. The following section covers the key terminologies used through this document: Scaler ​ Scaler is the E2E service that manages Application Scaling functionality. Scale Group ​ Scale Groups represent the nodes launched by Scaler. Each group is destined to adhere to a scaling policy (e.g., Add a compute node when CPU utilization on an existing node hovers at 70% for 20 seconds). Group nodes ​ The nodes in a scale group are dynamically added or removed. These nodes will be referred to as Group nodes or just nodes in the rest of the document. The lifecycle of group nodes starts with the creation of scale groups and ends with the termination of the group. You will be charged for the time between the start action of a node and the time of termination. Saved Image ​ Due to the dynamic nature of nodes, you would want to automate the launch sequence of the application too. This is where the saved image comes into play. A saved image is a compute node that you had saved, with the capability to launch your application at startup. Compute Plan ​ The compute plan or plan is where you select infrastructure or hardware requirements for your group nodes. It need not be the same as the plan used to create your saved image. Example Plan Sequence ​ Create a node with a conservative plan for the application (e.g., C Series 1 CPU 1GB) Add a launch sequence to auto-install and start your application during startup Create a scale group with the actual plan required for your production servers (e.g., C Series 16 CPU 64 GB) Scaling Policy ​ A scaling policy determines the lifecycle of group nodes. It consists of an expression containing: Min. nodes Max. nodes Desired nodes (Cardinality) Watch Period and Period Duration Cooldown A negative policy is automatically created by the Scaler to handle the termination of nodes. For example, if a user sets an expression of CPU > 80 for upscaling, the scaler will create a downscaling policy of CPU < 80 . Min and Max nodes ​ These define the maximum and minimum guarantees for your scale group. Cardinality or Desired Nodes ​ While the number of nodes is usually determined by the policy configuration, you can manually adjust it when necessary, such as during code or image updates. Tip: Start with 2 nodes and let the scale group take over. Performance or Target Metric ​ Currently, scaling policies support CPU Utilization only. Watch Periods ​ A watch period has two parts: Periods and Period Duration . Spikes in CPU usage must last for the watch period to trigger a scaling decision. Example: Expression: CPU > 75 Watch Period: 2 Period Duration: 10 seconds The scaler will monitor two consecutive periods of 10 seconds. If CPU utilization stays above 75% during this time, the scaling operation will initiate. Cooldown ​ A cooldown period prevents scaling operations immediately after a previous operation. This ensures stability by waiting to assess the impact of the previous scaling action. Default: 150 seconds . Load Balancer ​ Load balancers serve as entry points for scaling applications. As group nodes (and their IPs) change, the load balancer ensures consistent access for external users. Tip Always bundle your scale groups with a load balancer. Define Scale Groups ​ Application scaling helps you optimize infrastructure by automatically adjusting the number of compute nodes based on a predefined policy. You can define a scale group (a pool of compute nodes) for any web frontend or backend application to maintain consistent performance. Before you Begin ​ To save an image of a Virtual Node, it must be powered down . For this, click Power Off under the Actions section. After powering off the node, click the Action button again, and then click Save Image . Steps to Define Scale Groups ​ Go to My Account Navigate to Compute > Auto Scaling Click Create a new Group Select a Saved Image that can launch your application at startup Click Create a new Group button: Choose the image to use: Select the plan according to your needs: Elastic Policy ​ Elastic policies allow the infrastructure to scale automatically based on conditions such as CPU utilization, network traffic, or request latency. After selecting the plan, provide the scale group name, parameters, and policy. Elastic Policy offers Default and Custom options: Default Policy: Scaling is based on CPU or Memory utilization Custom Policy: Specify custom metrics like memory usage or request count Default Policy ​ CPU: Resources scale based on CPU utilization Memory: Resources scale based on memory utilization Custom Policy ​ A Custom Policy allows scaling based on a custom metric (e.g., disk I/O, network traffic). You’ll receive a CURL command for updating the custom parameter within scripts, cron jobs, or hooks. Note: The default value of the custom parameter is set to 0. Manage Custom Policy ​ The custom policy feature in auto scaling enables you to define your own custom attribute. The auto scaling service utilizes this attribute to make scaling decisions. The customer is responsible for setting this value on the service VM. To configure the custom attribute on the VM, the customer should first set up the attribute on an existing VM. Afterward, they need to create a saved image from that VM and use it to create the scaler service. Note The custom policy attribute must be configured on the image used to create the Scaler service. Custom Policy Name ​ The Custom Policy Name field is where you enter the name of the custom attribute that you want to use to monitor your service. This attribute can be any name that you choose, but it is helpful to use names that are descriptive of the aspect of your service that you are monitoring. For example, you could use the names \"MEMORY\" for memory usage, \"NETTX\" for network traffic, \"DISKWRIOPS\" for disk write operations, etc. Node Utilization Section ​ Specify the values that will trigger a scale-up (increase in cardinality) or scale-down (decrease in cardinality) operation based on your preferences. Scaling Period Policy ​ You need to define the watch period, duration of each period, and cooldown period. Note If your custom policy names are MEMORY, NETTX, NETRX, DISKWRIOPS, DISKRDIOPS, DISKWRBYTES, or DISKWRIOPS, you do not need to worry about anything else. However, if you wish to adjust the cardinality of your auto-scaling service based on different attributes, you must configure them through your node. Scaling (incrementing and decrementing) occurs based on the average value of the custom policy attribute. To Set Custom Attributes on Service Nodes, Follow These Steps: ​ Create a new node. Establish an SSH connection to that node. Add the script provided below to your node and set up a cron job for it if desired. Let us assume that you have set the custom policy name as \"CUSTOM_ATT,\" with a max utilization of 60 units and a minimum utilization of 30 units. The cardinality will increase when the value of CUSTOM_ATT exceeds 60 units and decrease if it falls below 30 units. If your goal is to adjust the cardinality based on the percentage of memory utilization, you need to assign the CUSTOM_ATT attribute to the node. This attribute will monitor memory utilization through the script. To achieve this, create a cron job that monitors memory utilization and updates the attribute periodically. When Writing the Script, You'll Need to Obtain the Following Information: ​ ONEGATE_ENDPOINT TOKENTXT VMID You can find these details at the following location: /var/run/one-context/one_env To Create the Script in a .sh File, Follow These Steps: ​ Create or update the file with the desired file name, like file_name.sh . Inside the script file file_name.sh , you can begin writing your script. Now you have two options to write a script inside the file file_name.sh : either use option 1 or option 2 to write the script. Option 1 ​ TMP_DIR=`mktemp -d` echo \"\" > $TMP_DIR/metrics MEM_TOTAL=`grep MemTotal: /proc/meminfo | awk '{print $2}'` MEM_FREE=`grep MemFree: /proc/meminfo | awk '{print $2}'` MEM_USED=$(($MEM_TOTAL-$MEM_FREE)) MEM_USED_PERC=\"0\" if ! [ -z $MEM_TOTAL ] && [ $MEM_TOTAL -gt 0 ]; then MEM_USED_PERC=`echo \"$MEM_USED $MEM_TOTAL\" | \\ awk '{ printf \"%.2f\", 100 * $1 / $2 }'` fi CUSTOM_ATTR=$MEM_USED_PERC echo \"CUSTOM_ATTR = $CUSTOM_ATTR\" >> $TMP_DIR/metrics VMID=$(source /var/run/one-context/one_env; echo $VMID) ONEGATE_ENDPOINT=$(source /var/run/one-context/one_env; echo $ONEGATE_ENDPOINT) ONEGATE_TOKEN=$(source /var/run/one-context/one_env; echo $TOKENTXT) curl -X \"PUT\" $ONEGATE_ENDPOINT/vm \\ --header \"X-ONEGATE-TOKEN: $ONEGATE_TOKEN\" \\ --header \"X-ONEGATE-VMID: $VMID\" \\ --data-binary @$TMP_DIR/metrics Option2 ​ MEM_TOTAL=`grep MemTotal: /proc/meminfo | awk '{print $2}'` MEM_FREE=`grep MemFree: /proc/meminfo | awk '{print $2}'` MEM_USED=$(($MEM_TOTAL-$MEM_FREE)) MEM_USED_PERC=\"0\" if ! [ -z $MEM_TOTAL ] && [ $MEM_TOTAL -gt 0 ]; then MEM_USED_PERC=`echo \"$MEM_USED $MEM_TOTAL\" | \\ awk '{ printf \"%.2f\", 100 * $1 / $2 }'` fi VMID=$(source /var/run/one-context/one_env; echo $VMID) onegate vm update $VMID --data CUSTOM_ATTR=$MEM_USED_PERC Now To make the (file_name.sh) file executable, execute the following command: chmod +x file_name.sh To run the file_name.sh script, use the following command: ./file_name.sh\": This will execute the script and perform its intended actions. But for continuous monitoring of your attribute there is a need to make a cron of your script. So for this in the terminal execute : crontab -e You will be prompted to specify a file where you need to provide the scheduled time for the cron job and the location of the script. Example: * * * * * /path/to/your/file_name.sh (/root/file_name.sh) Afterward, create an image of that node. Launch your auto scale group using a custom policy name (make sure to use the same name during configuration). This setup will monitor the percentage of memory utilization and store it in the specified custom attribute (CUSTOM_ATTR). Based on the values which you have provided for cardinality increment and decrement, your scheduled actions will be performed. To see the set attributes you can use given blow command - $ onegate vm show VMID --json After run above command the detail will be shown like this:- { \"VM\": { \"NAME\": \"machine_name\", \"ID\": \"machine_id\", \"STATE\": \"machine_state\", \"LCM_STATE\": \"machine_lcm_state\", \"USER_TEMPLATE\": { \"CUSTOM_ATTR\": \"set_attribute\", \"DISTRO\": \"distro\", \"HOT_RESIZE\": { \"CPU_HOT_ADD_ENABLED\": \"NO\", \"MEMORY_HOT_ADD_ENABLED\": \"NO\" }, \"HYPERVISOR\": \"kvm\", \"INPUTS_ORDER\": \"\", \"LOGO\": \"images/logos/centos.png\", \"LXD_SECURITY_PRIVILEGED\": \"true\", \"MEMORY_UNIT_COST\": \"MB\", \"MY_ACCOUNT_DISPLAY_CATEGORY\": \"Linux Virtual Node\", \"OS_TYPE\": \"CentOS-7.5\", \"SAVED_TEMPLATE_ID\": \"0\", \"SCHED_DS_REQUIREMENTS\": \"ID=\\\"0\\\"\", \"SCHED_REQUIREMENTS\": \"ID=\\\"10\\\" | ID=\\\"11\\\"\", \"SKU_TYPE\": \"sku_type\", \"TYPE\": \"Distro\" }, \"TEMPLATE\": { \"NIC\": [ { \"IP\": \"ip_add\", \"MAC\": \"mac_add\", \"NAME\": \"nic_name\", \"NETWORK\": \"your_network\" } ], \"NIC_ALIAS\": [ ] } } } To see the VMID, you can use given blow command - $ onegate vm show Output will be like this: VM 8 NAME : web_0_(service_1) STATE : RUNNING IP : 192.168.122.23 Schedule Policy ​ Schedule Policy - Autoscaling schedule policy allows you to define a predetermined schedule for automatically adjusting the capacity of your resources. For example, you may use a scheduled autoscaling policy to increase the number of instances in your service during peak traffic hours and then decrease the number of instances during off-peak hours. Recurrence - In autoscaling, recurrence refers to scheduling scaling actions on a recurring basis. This is useful for applications with predictable traffic patterns, such as a website that receives more traffic on weekends or during peak business hours. Cron - To configure recurrence in autoscaling, specify a cron expression. For example, the cron expression 0 0 * * * specifies that the scaling action should be run at midnight every day. Upscale Recurrence ​ Specify the cardinality of nodes at a specific time by adjusting the field in the cron settings. Ensure the value is lower than the maximum number of nodes you set. Downscale Recurrence ​ Specify the cardinality of nodes at a specific time by adjusting the field in the cron settings. Ensure the value is greater than the maximum number of nodes you set. To choose a scheduled policy, select Schedule Policy instead of Elastic Policy , set the upscale and downscale recurrence, and click Create Scale . Elastic and Scheduled Policy ​ If you want to create a scaler service using both options, choose the \"Both\" policy option, configure the parameters, and proceed. To see the scale group details, click on Scale Group Details . To view the details of the active nodes, click on the Active Node Details tab. To view the details of terminated nodes, click on the Terminated Node Details tab. To view associated network details, click on the Network tab. To view the details of the attached load balancer (LB), click on the Attached LB tab. To view monitoring details, click on the Monitoring tab. To view security group details, click on the Security Group tab. To view log details, click on the Logs tab. Actions ​ Resize Service ​ To resize the service, click on the 3 dots menu and select Resize Services . Start/Stop Action ​ The start/stop actions in the autoscaling service allow you to manage the service state. Stop Action ​ The stop action halts the service within the autoscaling infrastructure. Process : When initiated, the service transitions to a stopped state after a brief period. State : The service is marked as 'stopped,' with desired nodes set to zero. Billing : Billing is paused during the stopped state. Start Action ​ The start action begins the service within the autoscaling environment. Process : The service transitions to a running state after initiation. State : The service is in a running state, with desired nodes set to the minimum node count. Billing : Billing resumes upon starting the service. Conclusion ​ Utilizing start and stop actions helps you manage autoscaling efficiently, controlling costs and resources. Delete ​ To delete the service, click on the Delete button. Edit & Update Auto Scale ​ To edit scale group details like parameters and policies, click on the Edit icon. To edit scale group parameters, click on the Edit icon. After making changes, click the Update button. To select Elastic Policy , click the Edit icon and choose from the dropdown. To select Scheduled Policy , click the Edit icon and choose from the dropdown. To select both policies, click the Edit icon and choose from the dropdown. warning Deleting a saved image associated with a Scale Group is not allowed. First, terminate the associated scale group to delete the saved image. Concepts Scaler Scale Group Group nodes Saved Image Compute Plan Scaling Policy Load Balancer Define Scale Groups Before you Begin Steps to Define Scale Groups Elastic Policy Default Policy Custom Policy Manage Custom Policy Custom Policy Name Node Utilization Section Scaling Period Policy To Set Custom Attributes on Service Nodes, Follow These Steps: When Writing the Script, You'll Need to Obtain the Following Information: To Create the Script in a .sh File, Follow These Steps: Schedule Policy Elastic and Scheduled Policy Actions Resize Service Start/Stop Action Conclusion Delete Edit & Update Auto Scale",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/copy_EOS/",
    "site_type": "documentation",
    "content": "Copy EOS | E2E Cloud Skip to main content On this page How to copy your EOS bucket object to another E2E Account Introduction ​ By default, Object storage bucket could not be simply transferred or moved to another bucket. This is true even if the destination bucket is owned by another account. In this tutorial, We are going to show the steps on how to migrate your object storage bucket from one account to another account in the myaccount portal using command line interface mc . Step 1: Create a New Bucket on Your New Account ​ Go to object storage and create a new bucket where you want to copy the files/folders from your previous bucket. Enter the name of your bucket and click on Create . We now have a bucket named \"new-bucket-e2e\". Step 2: Attach Admin Permission for CLI Access ​ We need to attach admin permission for CLI access for both the old bucket (from where the data needs to be copied) and the newly created bucket. Select the bucket, go to Permission , and click on Attach access key . If you have an existing key, you can use the same, or you can create a new key to attach it to your bucket. Note If you are creating a new key, make sure to note down the access key and private key as it will be displayed only once. Here, in this case, we have attached a key named \"new_bucket_key\" and have given admin permission for the same. Similarly, we followed the same steps and attached admin permission for the old bucket. Step 3: Configure MinIO Client (mc) on Your Linux Server ​ To configure the MinIO client on your Linux server, please follow the steps below. wget https://dl.min.io/client/mc/release/linux-amd64/mc chmod +x mc mv mc /usr/local/bin Finally, verify whether the mc command is working as expected by using the below command mc --help Step 4: Copy the data from old bucket to new bucket ​ With the mc command installed, You can configure both keys on your server. mc config host add newbucketkey https://objectstore.e2enetworks.net 4ZVRC91VTIJMX6GR33JT 95CZ196OPxxxxxxxxxxxAS3ZQFG8G6SNC1S333 mc config host add old-bucket-key https://objectstore.e2enetworks.net FCNT4DRSGMB5DEQ71KEM C6FUVZ4xxxxxxxxxxxxxxxN76SC798P23 Once the keys have been configured, replace the key name and bucket in the below command and start copying your data from your old bucket to new bucket mc cp --recursive newbucketkey/new-bucket-e2e old-bucket-key/oldbucket-e2e Introduction Step 1: Create a New Bucket on Your New Account Step 2: Attach Admin Permission for CLI Access Step 3: Configure MinIO Client (mc) on Your Linux Server Step 4: Copy the data from old bucket to new bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/block_storage/",
    "site_type": "documentation",
    "content": "Volume | E2E Cloud Skip to main content On this page Volume Topics: ​ Volumes Introduction to Volumes Import Volume Introduction to Import Volume Volumes on Linux Make your Volume available for use on Linux Volumes on Windows Make your Volume available on Windows Topics:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/block_storage/intro/",
    "site_type": "documentation",
    "content": "Volumes | E2E Cloud Skip to main content On this page Introduction to Volumes E2E Volume provides block-level storage volumes to use with our compute nodes. These volumes can be attached to your computing nodes, making their data and file system available for your nodes. If your node is running on Linux, you can mount this volume's filesystem just like mounting any other filesystem. E2E’s Volume can be useful when your storage needs increase more than your computing demands. Since these block storage volumes are directly connected to your nodes, their I/O speeds are much faster compared to alternative storage solutions like object storage. Getting Started ​ Creating Volume ​ You can create a volume and attach it to any of the supported nodes. Before creating a volume, you should consider the storage size. If you are creating a volume for high performance and storage, make sure to create volume storage with enough storage and IOPS. This section will show you how to create volume storage from the MyAccount portal. Login to MyAccount Portal ​ Log in to MyAccount Portal using the credentials set up at the time of creating and activating the E2E Networks ‘My Account’. Navigate to Volume ​ Once you have logged in to MyAccount Portal, navigate to the Volume page from the sidebar menu. Add Volume ​ On the top right section of the block storage dashboard, click on the “Add Volume” button, which will prompt you to enter the details for your Block storage volume. Volume Configurations ​ You need to select the required configuration for your Block storage volume. The IOPS configuration increases with the size of the Block storage. Below are the plans available currently: Volume Size(in TBs) Number Of IOPS 0.25 5000 0.5 10000 1 20000 2 40000 4 80000 8 120000 16 240000 24 360000 For Hourly Plan of Volume For Committed Plan of Volume Once the plan has been selected, enter the Volume name, select the Volume size, and then click on the Launch Volume button to create the volume. Your Volume status will change to Available , and you will now be able to attach it to your nodes. Volume Details ​ You can view the details of your volume configuration on your dashboard. Attaching Volume to Your Node ​ A volume can be attached to your supported compute nodes. Currently, you can attach your node to GPU, vGPU, SDC, SDC3, C3, and all Windows plan (CW & WSDC) nodes only. To attach the volume to a node, click on Action and select Attach Volume . Select the node to which you want to attach your EBS using the scroll-down option and click Attach . info Your node should be powered off before attaching block storage to your nodes. Once you have attached your volume, the status will change to Attached , and you will be able to view the details of your attached node on the dashboard. Enable Monitoring for Your Volume ​ Volume monitoring refers to continuously tracking and observing the performance, usage, and read/write operations of storage volumes. To activate a volume on your node, follow these steps: SSH into your node. Paste this command in the terminal: echo \"UserParameter=mountpoint[*], grep \\\"/dev/\\$1\\\" /proc/mounts | cut -f2 -d' '\" >> /etc/zabbix/zabbix_agentd.conf && systemctl restart zabbix-agent tip If you have recently mounted the volume, please wait for 10-15 minutes to view the monitoring data. Once monitoring is enabled, and a period of time has passed, a graph like this will be displayed. Detaching Volume from Your Node ​ To detach your Block Storage from your node, select Action and click on Detach Volume . You will be asked for confirmation to detach the volume from your node. Tickmark the option and detach the node. To avoid any data loss, ensure that the volume is not in use while performing the detaching action. We recommend you first unmount the volume from the node before detaching it. Once the volume has been detached from your node, its status will change from Attached to Available again. You can then use this volume to attach it to other nodes or delete it. Create a Snapshot ​ To back up the volume's data, you can create a snapshot. To create a snapshot of your database, click on Action and select Create Snapshot . Enter the Snapshot name and click on Create Snapshot . The snapshots will now be available in the Snapshot section of your dashboard. Once the snapshot is created, your data will be backed up and preserved, and you will be able to create new volume storage from the available snapshot. To create a new volume from the snapshot, select Action and click on Create Volume . Enter the details of the new volume name and click on Create . A new volume storage will be created from the snapshot you saved. Move Volume To Another Project ​ Using this action, you can transfer your volume from its current project to another project within the same CRN. On transferring this volume, Snapshots of the volume will also be transferred. warning Ensure the volume is not in Attached , Creating , Deleting , or Error state. The volume must not have any Tags attached. To transfer the volume, click on Move To Another Project in Actions . Then, select the target project , check the checkbox, and click on Transfer . info An audit log will be created for the transfer in both the current and target projects during the transfer. Convert to Committed ​ To convert the volume from Hourly to Committed, it will first convert the Hourly plan volume to a Committed plan. When we set the \"convert to Committed,\" it will apply the Committed setting for the next cycle, once the committed plan ends. warning You will convert the Hourly plan volume to a Committed plan, and no further conversion to Committed will be needed. The user can now set the Committed Volume Settings for the next cycle, which will applied once the current Committed plan ends. Upgrade Volume ​ By utilizing the Upgrade Volume feature, you have the ability to enhance your volume size by increasing its memory capacity. To upgrade the volume, click on Upgrade Volume under the Action button. After clicking on Upgrade Volume , a popup will open where you can select the new volume size. Click on Upgrade . Your volume will then be upgraded with the new volume size. warning If a Volume snapshot has been created, upgrading the volume will not be possible. In order to proceed with the upgrade, you will need to either delete the snapshot associated with the volume you wish to upgrade or create a new volume from that snapshot and upgrade the newly created volume. If a snapshot has been created for the volume, you will encounter an issue when attempting to upgrade it. info In order to upgrade the volume, it is necessary for the volume to be attached to the node. Delete a Volume ​ To delete a volume storage, select Action and click on Delete . You will get a warning message that you will permanently lose data stored in the volume storage and associated snapshot upon deletion. Proceed and click on Delete to delete your volume. info You will need to detach your node from the volume before deleting it. Getting Started Creating Volume Volume Configurations Volume Details Attaching Volume to Your Node Enable Monitoring for Your Volume Detaching Volume from Your Node Create a Snapshot Move Volume To Another Project Convert to Committed Upgrade Volume Delete a Volume",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/",
    "site_type": "Documentation",
    "content": "Nodes Documentation | E2E Cloud Skip to main content Nodes Documentation Welcome to E2E Cloud's Compute Nodes documentation! Here, you'll find everything you need to know about launching nodes through the MyAccount portal, configuring node settings, and managing security with tools like BitNinja. This guide also walks you through essential tasks such as creating and managing snapshots, importing custom images, and resolving common issues. Additionally, you'll learn to set up and manage monitoring alerts, interpret monitoring graphs, and install the Zabbix Agent on your server for effective monitoring. Features Multiple Compute Node Options Choose from Linux Virtual Nodes, Windows Virtual Nodes, Smart Dedicated Nodes, and High-Frequency CPU-Intensive nodes for optimized performance. Easy Node Deployment via MyAccount Portal Deploy, manage, and monitor compute nodes effortlessly through an intuitive web-based interface. API Support for Programmatic Management Automate node creation, scaling, and monitoring using E2E Networks’ API for seamless DevOps integration. Flexible OS Choices Deploy nodes with various operating systems like Ubuntu, CentOS, Debian, Windows Server, cPanel, Plesk, and Webuzo to suit different workloads. Multiple Performance-Tuned Plans Select from high-memory, CPU-intensive, and Smart Dedicated compute plans tailored for AI/ML, big data, and enterprise applications. See All Secure Access with SSH Keys & Password Management Use SSH-based authentication for Linux nodes and secure one-time password login for Windows nodes. Integrated Network & Security Benefit from Virtual Private Cloud (VPC), security groups, reserved IPs, and BitNinja security integration for robust protection. Backup & Snapshot Management Enable automated backups and create snapshots to ensure quick recovery and seamless scaling. Scalable Storage with Volume Attachments Attach additional storage volumes to compute nodes as needed, enabling flexible storage expansion. On-Demand & Committed Billing Pay per hour for flexible usage or opt for 365-day committed plans to save costs on long-term workloads. Real-Time Monitoring & Alerts Track CPU, memory, and network usage via MyAccount’s monitoring dashboard and set up alerts for performance insights. Zabbix Agent Integration Install Zabbix Agent on nodes to access detailed system analytics and proactive resource monitoring. Benefits Performance & Scalability High-speed compute nodes with Intel-based C3 series processors for maximum efficiency. Dedicated Smart Nodes ensure higher performance with reserved network ports. Multiple configurations allow seamless scaling of vCPUs and memory based on workload needs. Cost-Effective Solutions Transparent, predictable pricing with hourly and committed billing models. Optimized cost-performance ratio with specialized compute and memory-intensive node categories. Simplified Deployment & Management Easy-to-use MyAccount portal for managing nodes with a web-based UI. API Access for programmatic control of instances. Quick provisioning with automated setup and pre-configured OS images. Enhanced Security BitNinja Security for proactive protection against threats. SSH key authentication for improved access security. VPC and security group integration to define network access policies. Reliable Backup & Disaster Recovery Automated backup solutions to ensure data protection. Custom snapshots for easy restoration and replication. Volume attachments for flexible data storage expansion. See All Comprehensive Monitoring & Alerts Built-in monitoring graphs for real-time insights into node performance. Zabbix Agent support for detailed monitoring and alert setup. Performance tracking to optimize resource utilization. Virtual Compute Nodes Compute nodes, their deployment and management. Monitoring Set up monitoring alerts, monitoring graphs and Zabbix agent. Active Directory Centralized management of user identities and access permissions.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/static_site/",
    "site_type": "Documentation",
    "content": "Host a static website with EOS | E2E Cloud Skip to main content On this page Host a static website with EOS Introduction ​ In this tutorial, we will show you how to host a static website on EOS S3 Bucket, individual webpages include static content, and they might also contain client-side scripts which can be hosted on an S3 Bucket. Server-side scripts such as PHP, JSP, or ASP.NET is not supported on EOS S3. Create Bucket ​ Go to Products > Storage option in the sidebar menu. Click on Create New Bucket or the (+) icon. Enter a unique bucket name. You must follow these guidelines when choosing the bucket name: You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names can not be changed after creation, so choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Upper case letters or underscores are not allowed . Do not format bucket names like an IP address (e.g., 10.10.10.2 ). Click Create . You will be redirected to the object browser. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to Upload files through the object browser or set bucket permissions to enable CLI access. Add Permission to Your Bucket ​ Once you have created a bucket, you need to provide public access to your bucket. Select the bucket you have created. Click on Permission and select the Make Public option. Select your type of access role (Upload/Download) and click on Save Permission . The contents of your bucket will now be available for public access using the object path prefixed by the following URL: https://objectstore.e2enetworks.net/Your_Bucket_Name/ . Create Distribution with CDN Service ​ Once you have created a bucket, you need to create a distribution on CDN to get the distribution URL. Go to Other Service > CDN Service option in the sidebar menu. Click on the Create Distribution icon. Enter the following options. Origin Domain Name (example.com*) - objectstore.e2enetworks.net Origin path (E.g: /static) - /your_bucket_name Origin ID - objectstore.e2enetworks.net Enter your Origin , Cache , and Distribution settings. tip You can refer to the tooltip on the left side of each option to get information about your options. Once all the settings have been entered, click on Create Distribution . Note Creation of the distribution will take around 10 to 15 minutes. After creating the distribution, you can access your bucket content using the Distribution URL . Create a respective alias for this URL in the DNS panel to access your website with your domain. Introduction Create Bucket Add Permission to Your Bucket Create Distribution with CDN Service",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/iam/",
    "site_type": "Documentation/Informational",
    "content": "IAM | E2E Cloud Skip to main content On this page IAM Policy-Based Access Control (PBAC) is a mechanism for managing user access to individual or multiple systems, where the permissions granted are contingent upon the user's business responsibilities aligned with predefined policies or custom policies. In contrast to the conventional method of auditing and modifying roles organization-wide, PBAC provides the agility to swiftly adjust access privileges in response to evolving requirements. This ensures that assets remain safeguarded through the enforcement of established rules and policies. PBAC stands out as a versatile authorization solution, capable of accommodating various access points by automating security controls within applications and data. IAM (Identity and Access Management) ​ IAM Model Overview: ​ IAM, which stands for Identity and Access Management, encompasses a structured system for managing user identities and their access privileges within an account. The IAM model comprises various user roles and their corresponding permissions. Key Concepts: ​ IAM Entry: Each IAM entry contains mappings with a primary customer and their associated secondary users. Instead of referencing a contact person table, information regarding secondary users is stored within the IAM table. IAM User Types: Owner: Represents the primary account holder. Primary: Users with existing sign-ups on the platform who can access other accounts using the Primary IAM feature, also known as Multi-CRN view. Multi CRN ​ A Multi-CRN perspective offers users the ability to toggle between multiple CRNs (Customer Reference Numbers). This occurs when a customer (Customer A) who is already registered grants access to some of their projects to another customer (Customer B) who is also registered. As a result, Customer B can access Customer A's projects by switching between their respective CRNs. Contact: Users without existing sign-ups on the platform. Roles and Permissions ​ Roles Resource View Resource Management IAM (User Management) Billing Operations (Pay Now, Auto Pay, and Account Statement) Payment Reminders/Invoice Handling Admin ✓ ✓ ✓ ✓ ✓ Project Lead ✓ ✓ ✓ (except Admin) × × Billing × × × ✓ ✓ Member Policy-based Access Policy-based Access × Policy-based Access × Billing+Member Policy-based Access Policy-based Access × ✓ ✓ Viewer ✓ × × × × Admin: Holds full access rights, including the management of resources and projects, access to the billing dashboard, the handling of invoices, and the ability to add or remove other IAM users. Administrators are essentially co-owners of the account. Project Lead: Has access to resource allocation and project management, with the authority to add or remove other IAM users (excluding Admins). The Project Lead does not have access to billing. Billing User: Authorized to manage billing functions such as Pay Now, Auto Pay, and Account Statements, including viewing and paying outstanding balances, accessing invoices, and configuring auto-pay settings. Member: Users with limited access to the account, with the ability to select services and adhere to established policies that restrict their view within services. Unauthorized attempts to access restricted services or perform restricted actions will redirect them to an unauthorized page. Billing+Member: Users with restricted service access but unrestricted access to the billing dashboard. They can perform any action within the billing dashboard without restrictions. Viewer: Has read-only access to view resources. Cannot create, modify, or delete resources. Suitable for users who only need visibility. Note To use IAM, you have to follow these steps: You have to add an IAM user. You have to create a project. You have to create custom policies or you can use predefined policies. Assign the project and policies to the user. Add User ​ To add users, follow these steps: Navigate to the IAM section on the Dashboard. By default, the details of Owner are displayed in the list. To add a new user to the project, simply click on the 'Add User' option. After selecting \"Add User,\" a new page labeled \"Add New User\" will open. On this page, you need to enter the user's email and choose a role from the dropdown menu. The available roles include Member, Billing, Project Manager, Admin, and Billing+ Member. If you choose the role of Admin, Project Manager, or Billing, predefined policies will be applied to the user based on their role. After selecting all the parameters, click on Add User. Note In the absence of an available policy in the project, you must initially add a custom policy to the project. If you choose the role of \"Member,\" all available projects will be displayed below. After selecting a specific project, you can then assign one or more policies to that user. Upon selecting \"Add User,\" the user will appear in the IAM page under the \"All Users\" section with the status set as 'Invited.' An invitation link will be sent to the user's email address. After clicking the link, a registration form will be presented for completion. Upon completing all the required details in the registration form, the user will be successfully registered. Following registration, the customer must log in using their provided credentials. Note If the customer is an existing user on the E2E platform, they will find the invitation in the Invitation section on the Dashboard. Upon selecting the Invitation button, the Invitation page will be displayed. On the Manage Invitations page, you can view the invitations received and take actions such as accepting or declining them based on your preference. Upon accepting the invitation, the user will appear in the All User list with their assigned role. Actions ​ Reset Password: ​ Click on the \"Reset Password\" action to reset a member's password. Edit Roles and Policies: ​ To modify the roles and policies of a member, click on the Edit action. Once you have made the necessary changes, click on the \"Update User\" button to save the modifications. Delete User: ​ To remove a user, click on the Delete action. Upon selecting the delete action button, a confirmation pop-up will appear on the page. Click on the delete button within the pop-up to confirm the deletion, and the user will be removed from the user list. Manage Project ​ Project Management ​ To manage projects, navigate to the IAM page and click on the Manage Project tab. By default, a Default Project will be displayed in the list. To create a new project, provide a name for the project and click on the Create button. Once a project is created, it will be visible in the Recent tab. To switch from one project to another, select the desired project by clicking on the radio button. A pop-up will appear, prompting you to click on \"Switch Project.\" Upon doing so, the switch will be completed, and you'll be in the selected project. To designate a project as a starred project, click on the star button located in the Starred section. To view all projects, click on the \"All\" section, where you can see a comprehensive list of all projects associated with that user. Member Management ​ Add Member: ​ To modify a project and add members, click on the edit button associated with that project. Upon clicking the edit button, you will find the option to add members to the project. Click on it to proceed. Following the selection of \"Add Member,\" the Add Member page will open. After entering all the necessary information, such as the new member's details and policies, click on \"Save Changes\" to confirm. Modify User's Policy: ​ To modify a user's policy, click on the edit button and then select the appropriate option on the right button. Remove Member: ​ To remove a member from the project, click on the delete button. A popup will appear, and upon confirmation by clicking the Delete button within the popup, the member will be successfully deleted from the project. Policy Set ​ To access established policies, go to the IAM page and select the Policy Set section. If you wish to create a new policy, click on the \"Add Policy\" button. After clicking on Add Policy, the Add New Policy page will appear where you need to give the policy set name and description and select the services to be granted access in this policy, then click on the Save button. Upon saving the policy, it will be displayed in the Policy Set section on the IAM page. To execute actions on a policy set, click on the three dots, and a menu of actions will appear. To view the policy services, select the \"View\" action. Upon selecting the \"View\" action, the Services page will open, allowing you to see all the services associated with that policy. To modify the policy set, click on the \"Edit\" action. Upon choosing the \"Edit\" action, the Edit Policy Set Details page will open. On this page, you can add or remove services from the policy set by ticking or unticking the respective options. After making the desired changes, click on the Save button. To remove a policy set, click on the \"Delete\" action. Upon selecting the \"Delete\" action, a pop-up will appear. Click on \"Delete\" within the pop-up, and the policy set will be removed from the policy set list. IAM (Identity and Access Management) IAM Model Overview: Key Concepts: Multi CRN Roles and Permissions Add User Actions Reset Password: Edit Roles and Policies: Delete User: Manage Project Project Management Member Management Policy Set",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation/Informational",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/iam/#multi-crn",
    "site_type": "Documentation/Informational",
    "content": "IAM | E2E Cloud Skip to main content On this page IAM Policy-Based Access Control (PBAC) is a mechanism for managing user access to individual or multiple systems, where the permissions granted are contingent upon the user's business responsibilities aligned with predefined policies or custom policies. In contrast to the conventional method of auditing and modifying roles organization-wide, PBAC provides the agility to swiftly adjust access privileges in response to evolving requirements. This ensures that assets remain safeguarded through the enforcement of established rules and policies. PBAC stands out as a versatile authorization solution, capable of accommodating various access points by automating security controls within applications and data. IAM (Identity and Access Management) ​ IAM Model Overview: ​ IAM, which stands for Identity and Access Management, encompasses a structured system for managing user identities and their access privileges within an account. The IAM model comprises various user roles and their corresponding permissions. Key Concepts: ​ IAM Entry: Each IAM entry contains mappings with a primary customer and their associated secondary users. Instead of referencing a contact person table, information regarding secondary users is stored within the IAM table. IAM User Types: Owner: Represents the primary account holder. Primary: Users with existing sign-ups on the platform who can access other accounts using the Primary IAM feature, also known as Multi-CRN view. Multi CRN ​ A Multi-CRN perspective offers users the ability to toggle between multiple CRNs (Customer Reference Numbers). This occurs when a customer (Customer A) who is already registered grants access to some of their projects to another customer (Customer B) who is also registered. As a result, Customer B can access Customer A's projects by switching between their respective CRNs. Contact: Users without existing sign-ups on the platform. Roles and Permissions ​ Roles Resource View Resource Management IAM (User Management) Billing Operations (Pay Now, Auto Pay, and Account Statement) Payment Reminders/Invoice Handling Admin ✓ ✓ ✓ ✓ ✓ Project Lead ✓ ✓ ✓ (except Admin) × × Billing × × × ✓ ✓ Member Policy-based Access Policy-based Access × Policy-based Access × Billing+Member Policy-based Access Policy-based Access × ✓ ✓ Viewer ✓ × × × × Admin: Holds full access rights, including the management of resources and projects, access to the billing dashboard, the handling of invoices, and the ability to add or remove other IAM users. Administrators are essentially co-owners of the account. Project Lead: Has access to resource allocation and project management, with the authority to add or remove other IAM users (excluding Admins). The Project Lead does not have access to billing. Billing User: Authorized to manage billing functions such as Pay Now, Auto Pay, and Account Statements, including viewing and paying outstanding balances, accessing invoices, and configuring auto-pay settings. Member: Users with limited access to the account, with the ability to select services and adhere to established policies that restrict their view within services. Unauthorized attempts to access restricted services or perform restricted actions will redirect them to an unauthorized page. Billing+Member: Users with restricted service access but unrestricted access to the billing dashboard. They can perform any action within the billing dashboard without restrictions. Viewer: Has read-only access to view resources. Cannot create, modify, or delete resources. Suitable for users who only need visibility. Note To use IAM, you have to follow these steps: You have to add an IAM user. You have to create a project. You have to create custom policies or you can use predefined policies. Assign the project and policies to the user. Add User ​ To add users, follow these steps: Navigate to the IAM section on the Dashboard. By default, the details of Owner are displayed in the list. To add a new user to the project, simply click on the 'Add User' option. After selecting \"Add User,\" a new page labeled \"Add New User\" will open. On this page, you need to enter the user's email and choose a role from the dropdown menu. The available roles include Member, Billing, Project Manager, Admin, and Billing+ Member. If you choose the role of Admin, Project Manager, or Billing, predefined policies will be applied to the user based on their role. After selecting all the parameters, click on Add User. Note In the absence of an available policy in the project, you must initially add a custom policy to the project. If you choose the role of \"Member,\" all available projects will be displayed below. After selecting a specific project, you can then assign one or more policies to that user. Upon selecting \"Add User,\" the user will appear in the IAM page under the \"All Users\" section with the status set as 'Invited.' An invitation link will be sent to the user's email address. After clicking the link, a registration form will be presented for completion. Upon completing all the required details in the registration form, the user will be successfully registered. Following registration, the customer must log in using their provided credentials. Note If the customer is an existing user on the E2E platform, they will find the invitation in the Invitation section on the Dashboard. Upon selecting the Invitation button, the Invitation page will be displayed. On the Manage Invitations page, you can view the invitations received and take actions such as accepting or declining them based on your preference. Upon accepting the invitation, the user will appear in the All User list with their assigned role. Actions ​ Reset Password: ​ Click on the \"Reset Password\" action to reset a member's password. Edit Roles and Policies: ​ To modify the roles and policies of a member, click on the Edit action. Once you have made the necessary changes, click on the \"Update User\" button to save the modifications. Delete User: ​ To remove a user, click on the Delete action. Upon selecting the delete action button, a confirmation pop-up will appear on the page. Click on the delete button within the pop-up to confirm the deletion, and the user will be removed from the user list. Manage Project ​ Project Management ​ To manage projects, navigate to the IAM page and click on the Manage Project tab. By default, a Default Project will be displayed in the list. To create a new project, provide a name for the project and click on the Create button. Once a project is created, it will be visible in the Recent tab. To switch from one project to another, select the desired project by clicking on the radio button. A pop-up will appear, prompting you to click on \"Switch Project.\" Upon doing so, the switch will be completed, and you'll be in the selected project. To designate a project as a starred project, click on the star button located in the Starred section. To view all projects, click on the \"All\" section, where you can see a comprehensive list of all projects associated with that user. Member Management ​ Add Member: ​ To modify a project and add members, click on the edit button associated with that project. Upon clicking the edit button, you will find the option to add members to the project. Click on it to proceed. Following the selection of \"Add Member,\" the Add Member page will open. After entering all the necessary information, such as the new member's details and policies, click on \"Save Changes\" to confirm. Modify User's Policy: ​ To modify a user's policy, click on the edit button and then select the appropriate option on the right button. Remove Member: ​ To remove a member from the project, click on the delete button. A popup will appear, and upon confirmation by clicking the Delete button within the popup, the member will be successfully deleted from the project. Policy Set ​ To access established policies, go to the IAM page and select the Policy Set section. If you wish to create a new policy, click on the \"Add Policy\" button. After clicking on Add Policy, the Add New Policy page will appear where you need to give the policy set name and description and select the services to be granted access in this policy, then click on the Save button. Upon saving the policy, it will be displayed in the Policy Set section on the IAM page. To execute actions on a policy set, click on the three dots, and a menu of actions will appear. To view the policy services, select the \"View\" action. Upon selecting the \"View\" action, the Services page will open, allowing you to see all the services associated with that policy. To modify the policy set, click on the \"Edit\" action. Upon choosing the \"Edit\" action, the Edit Policy Set Details page will open. On this page, you can add or remove services from the policy set by ticking or unticking the respective options. After making the desired changes, click on the Save button. To remove a policy set, click on the \"Delete\" action. Upon selecting the \"Delete\" action, a pop-up will appear. Click on \"Delete\" within the pop-up, and the policy set will be removed from the policy set list. IAM (Identity and Access Management) IAM Model Overview: Key Concepts: Multi CRN Roles and Permissions Add User Actions Reset Password: Edit Roles and Policies: Delete User: Manage Project Project Management Member Management Policy Set",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/iam/#policy-set",
    "site_type": "Documentation/Informational",
    "content": "IAM | E2E Cloud Skip to main content On this page IAM Policy-Based Access Control (PBAC) is a mechanism for managing user access to individual or multiple systems, where the permissions granted are contingent upon the user's business responsibilities aligned with predefined policies or custom policies. In contrast to the conventional method of auditing and modifying roles organization-wide, PBAC provides the agility to swiftly adjust access privileges in response to evolving requirements. This ensures that assets remain safeguarded through the enforcement of established rules and policies. PBAC stands out as a versatile authorization solution, capable of accommodating various access points by automating security controls within applications and data. IAM (Identity and Access Management) ​ IAM Model Overview: ​ IAM, which stands for Identity and Access Management, encompasses a structured system for managing user identities and their access privileges within an account. The IAM model comprises various user roles and their corresponding permissions. Key Concepts: ​ IAM Entry: Each IAM entry contains mappings with a primary customer and their associated secondary users. Instead of referencing a contact person table, information regarding secondary users is stored within the IAM table. IAM User Types: Owner: Represents the primary account holder. Primary: Users with existing sign-ups on the platform who can access other accounts using the Primary IAM feature, also known as Multi-CRN view. Multi CRN ​ A Multi-CRN perspective offers users the ability to toggle between multiple CRNs (Customer Reference Numbers). This occurs when a customer (Customer A) who is already registered grants access to some of their projects to another customer (Customer B) who is also registered. As a result, Customer B can access Customer A's projects by switching between their respective CRNs. Contact: Users without existing sign-ups on the platform. Roles and Permissions ​ Roles Resource View Resource Management IAM (User Management) Billing Operations (Pay Now, Auto Pay, and Account Statement) Payment Reminders/Invoice Handling Admin ✓ ✓ ✓ ✓ ✓ Project Lead ✓ ✓ ✓ (except Admin) × × Billing × × × ✓ ✓ Member Policy-based Access Policy-based Access × Policy-based Access × Billing+Member Policy-based Access Policy-based Access × ✓ ✓ Viewer ✓ × × × × Admin: Holds full access rights, including the management of resources and projects, access to the billing dashboard, the handling of invoices, and the ability to add or remove other IAM users. Administrators are essentially co-owners of the account. Project Lead: Has access to resource allocation and project management, with the authority to add or remove other IAM users (excluding Admins). The Project Lead does not have access to billing. Billing User: Authorized to manage billing functions such as Pay Now, Auto Pay, and Account Statements, including viewing and paying outstanding balances, accessing invoices, and configuring auto-pay settings. Member: Users with limited access to the account, with the ability to select services and adhere to established policies that restrict their view within services. Unauthorized attempts to access restricted services or perform restricted actions will redirect them to an unauthorized page. Billing+Member: Users with restricted service access but unrestricted access to the billing dashboard. They can perform any action within the billing dashboard without restrictions. Viewer: Has read-only access to view resources. Cannot create, modify, or delete resources. Suitable for users who only need visibility. Note To use IAM, you have to follow these steps: You have to add an IAM user. You have to create a project. You have to create custom policies or you can use predefined policies. Assign the project and policies to the user. Add User ​ To add users, follow these steps: Navigate to the IAM section on the Dashboard. By default, the details of Owner are displayed in the list. To add a new user to the project, simply click on the 'Add User' option. After selecting \"Add User,\" a new page labeled \"Add New User\" will open. On this page, you need to enter the user's email and choose a role from the dropdown menu. The available roles include Member, Billing, Project Manager, Admin, and Billing+ Member. If you choose the role of Admin, Project Manager, or Billing, predefined policies will be applied to the user based on their role. After selecting all the parameters, click on Add User. Note In the absence of an available policy in the project, you must initially add a custom policy to the project. If you choose the role of \"Member,\" all available projects will be displayed below. After selecting a specific project, you can then assign one or more policies to that user. Upon selecting \"Add User,\" the user will appear in the IAM page under the \"All Users\" section with the status set as 'Invited.' An invitation link will be sent to the user's email address. After clicking the link, a registration form will be presented for completion. Upon completing all the required details in the registration form, the user will be successfully registered. Following registration, the customer must log in using their provided credentials. Note If the customer is an existing user on the E2E platform, they will find the invitation in the Invitation section on the Dashboard. Upon selecting the Invitation button, the Invitation page will be displayed. On the Manage Invitations page, you can view the invitations received and take actions such as accepting or declining them based on your preference. Upon accepting the invitation, the user will appear in the All User list with their assigned role. Actions ​ Reset Password: ​ Click on the \"Reset Password\" action to reset a member's password. Edit Roles and Policies: ​ To modify the roles and policies of a member, click on the Edit action. Once you have made the necessary changes, click on the \"Update User\" button to save the modifications. Delete User: ​ To remove a user, click on the Delete action. Upon selecting the delete action button, a confirmation pop-up will appear on the page. Click on the delete button within the pop-up to confirm the deletion, and the user will be removed from the user list. Manage Project ​ Project Management ​ To manage projects, navigate to the IAM page and click on the Manage Project tab. By default, a Default Project will be displayed in the list. To create a new project, provide a name for the project and click on the Create button. Once a project is created, it will be visible in the Recent tab. To switch from one project to another, select the desired project by clicking on the radio button. A pop-up will appear, prompting you to click on \"Switch Project.\" Upon doing so, the switch will be completed, and you'll be in the selected project. To designate a project as a starred project, click on the star button located in the Starred section. To view all projects, click on the \"All\" section, where you can see a comprehensive list of all projects associated with that user. Member Management ​ Add Member: ​ To modify a project and add members, click on the edit button associated with that project. Upon clicking the edit button, you will find the option to add members to the project. Click on it to proceed. Following the selection of \"Add Member,\" the Add Member page will open. After entering all the necessary information, such as the new member's details and policies, click on \"Save Changes\" to confirm. Modify User's Policy: ​ To modify a user's policy, click on the edit button and then select the appropriate option on the right button. Remove Member: ​ To remove a member from the project, click on the delete button. A popup will appear, and upon confirmation by clicking the Delete button within the popup, the member will be successfully deleted from the project. Policy Set ​ To access established policies, go to the IAM page and select the Policy Set section. If you wish to create a new policy, click on the \"Add Policy\" button. After clicking on Add Policy, the Add New Policy page will appear where you need to give the policy set name and description and select the services to be granted access in this policy, then click on the Save button. Upon saving the policy, it will be displayed in the Policy Set section on the IAM page. To execute actions on a policy set, click on the three dots, and a menu of actions will appear. To view the policy services, select the \"View\" action. Upon selecting the \"View\" action, the Services page will open, allowing you to see all the services associated with that policy. To modify the policy set, click on the \"Edit\" action. Upon choosing the \"Edit\" action, the Edit Policy Set Details page will open. On this page, you can add or remove services from the policy set by ticking or unticking the respective options. After making the desired changes, click on the Save button. To remove a policy set, click on the \"Delete\" action. Upon selecting the \"Delete\" action, a pop-up will appear. Click on \"Delete\" within the pop-up, and the policy set will be removed from the policy set list. IAM (Identity and Access Management) IAM Model Overview: Key Concepts: Multi CRN Roles and Permissions Add User Actions Reset Password: Edit Roles and Policies: Delete User: Manage Project Project Management Member Management Policy Set",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation/Informational",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation/Informational",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/container_registry/",
    "site_type": "Documentation",
    "content": "Container Registry | E2E Cloud Skip to main content On this page Container Registry The Container Registry section of the E2E Networks documentation is focused on providing users with guidance on using the Container Registry Service. This section includes detailed information on how to effectively use the Container Registry, with user-friendly interfaces for simplifying pull operations. Key Topics ​ For more detailed information on each aspect of the Container Registry service, refer to follow sections in our documentation. Overview Introduction to the service. Managing Containers Instructions on container management and version control. Pulling from the Registry Detailed process for pulling images. Access Tokens Guidelines on managing access tokens for a container registry Security and accesss Guidelines on ensuring security and managing access controls. Key Topics",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/container_registry/managing_container_registry/",
    "site_type": "Documentation",
    "content": "Manage | E2E Cloud Skip to main content On this page Manage Container Registry Working with Container Registry ​ The following sections describe how you can use Container Registry. Create New Container Registry ​ Click on the \"Container Registry” sub-menu available under the Storage section. You will be directed to the ‘Container Registry manager’ page. You can provide the project name (optional). Click on the “Create Container Registry” button. Scan Project ​ To scan the project, click on the three dots next to the respective project and then click on scan. Connecting to your Container Registry ​ Enter the following command at a command prompt on your local or client desktop to connect to a container Registry. To manage access tokens kindly refer to Access Tokens . docker login registry.e2enetworks.net -u <token_name> -p <token_value> Push Commands ​ Using Docker ​ Enter the following command to push your image on the project. Docker Images - docker images Create Tag - docker tag <image>:<tag> registry.e2enetworks.net/<project_name>/<image>:<tag> Push Images - docker push registry.e2enetworks.net/<project_name>/<image_name>:<tag> Scan Repositories ​ To scan the repository, click on the three dots next to the respective repository and then click on scan. Scan Artifact ​ To scan the artifact, click on the repository. A new page will open; then, click on the three dots next to the respective artifact. Delete Artifact ​ To delete the artifact, click on the three dots next to the respective artifact. A confirmation popup will be open, confirm it and click on Delete. Delete Repositories ​ To delete the repository, click on the three dots next to the respective repository. A confirmation popup will be open, confirm it and click on Delete. Delete Project ​ To delete the project, click on the three dots next to the respective project. A confirmation popup will be open, confirm it and click on Delete. Working with Container Registry Create New Container Registry Scan Project Connecting to your Container Registry Push Commands Using Docker Scan Repositories Scan Artifact Delete Artifact Delete Repositories Delete Project",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/images/",
    "site_type": "Documentation",
    "content": "Images | E2E Cloud Skip to main content Images Node images are a way to quickly launch instances without having to manually set up each machine. Users can choose from a range of operating systems (like Ubuntu, CentOS, or Windows) and application stacks, simplifying the process of scaling or provisioning resources. By using these pre-configured images, businesses can save time and effort while ensuring that their virtual machines are ready for their specific use case. Create a Node Image Learn how to create image of your node. Import your own custom Image Guide for importing a custom image to MyAccount.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/Customer_validation_indian/",
    "site_type": "Customer Validation Portal",
    "content": "Customer Validation | E2E Cloud Skip to main content On this page Customer Validation For Indian Customer ​ Aadhaar Validation ​ If the user clicks the option to Initiate , the page will redirect for Aadhaar validation. After completing the Aadhaar validation, the default address will be displayed on the screen, which will be the same as the Aadhaar address. There is an option to add another address if the user wants to add one. After completing the address wizard, the user will need to do the payment verification process. After completion of all processes, the user will be able to use My Account. After clicking Initiate , a pop-up will appear showing a message like: Aadhaar-based validation for the services for E2E Networks Ltd. Then click Agree and Proceed . Then it will redirect to the Bureau site for KYC verification with Digilocker. Click on Proceed to Digilocker . Another popup will appear where the customer has to fill in their Aadhaar details. After completing the Aadhaar validation, a popup will appear on the Dashboard to Update Billing Address . In this field, the customer has the option to choose an address from Aadhaar, or the customer can add another address that is different from the one mentioned in Aadhaar. Other Method of Validation ​ Note: If the customer is having trouble with validation using Initiate , the user needs to follow the steps below: If you are having trouble with validation, click on the Try other way button. A popup will appear. You have to click on the Initiate button. After clicking the Initiate button, a terms and conditions popup will appear. The user has to click Agree and Proceed . Then, upload the front and back of the ID card. After uploading, click on the Submit button. After submitting the ID card, the Selfie Validation process will start. The user has to capture their photo and click the Submit button. After clicking Submit , the user has to enter their billing address and click the Proceed button. The validation will then begin, and after completion, the user will be notified via email. For Indian Customer Aadhaar Validation Other Method of Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Customer Validation Portal",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Customer Validation Portal",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Customer Validation Portal",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Customer Validation Portal",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Customer Validation Portal",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/benchmarks/inference_benchmarks/",
    "site_type": "Benchmarking Website",
    "content": "Inference Benchmarking | E2E Cloud Skip to main content On this page Inference Benchmarks Introduction ​ E2E Networks provides high-performance LLM inference with TIR ( an end-to-end AI/ML Platform ) leveraging state-of-the-art GPU Infrastructure. This page covers the methodology and performance highlights for latency and throughput of LLM Inference on GPUs such as H100, H200, A100 etc. Serving Performance ​ Generative AI Applications often employ an inference engine for performing LLM inference. vLLM is one of the mostly widely used inference engine that supports features such as continuous batching, open AI compatibility, etc. In this section, we evaluate the performance of vLLM with a single GPU (e.g. H100) at serving concurrent requests. The numbers obtained here are based on default configuration of vLLM to showcase a generic solution. Our team can help you further tune these numbers based on your specific use case. Benchmarking Framework : vLLM official benchmarking script with random tokens dataset Metrics : Time to First Token (TTFT): The latency between the initial inference request to the model and the return of the first token. Inter-Token Latency (ITL): The latency between each token after the first. Total Latency: TTFT + (no of tokens * ITL) Token Throughput: The total number of tokens generated per second Request Throughput: The total number of request completed per second Inputs : Input & Output token lengths based on task type: for e.g. summarization often involves a large input and small output Request rate: no of requests / second. we settled on this -after trial and error- based on best results for a combination of input/output tokens Endpoint Protocol : HTTPS LLAMA 3.1 (8B) + H200 ​ Model GPUs Task Type Input-Output Request Rate Requests/Sec Throughput (tokens/sec) TTFT (ms) TPOT (ms) Total Latency (ms) LLAMA3.1 (8B) 1 Simple Chat [128:128] 64 37.32 8955 54.37 16.09 2083.26 LLAMA3.1 (8B) 1 Summarization / RAG [2024:128] 12 8.95 19428 204.51 32.45 4325.66 LLAMA3.1 (8B) 1 Classification [1024:30] 24 19.03 20088 89.05 19.20 645.85 LLAMA3.1 (8B) 1 Creative Writing [200:2024] 4 1.32 2543 24.32 9.30 18838.22 LLAMA 3.1 (8B) + H100 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency LLAMA3.1 (8B) 1 Simple Chat [128:128] 64 35.04 8399 tokens/sec 28.84 ms 22.27 ms 2857.12 ms LLAMA3.1 (8B) 1 Summarization / RAG [2024:128] 12 8.95 19127 tokens/sec 200.06 ms 35.51 ms 4709.83 ms LLAMA3.1 (8B) 1 Classification [1024:30] 24 19.03 19979 tokens/sec 92.74 ms 22.07 ms 732.77 ms LLAMA3.1 (8B) 1 Creative Writing [200:2024] 8 3.42 5060 tokens/sec 47.25 ms 21.57 ms 43682.36 ms LLAMA 3.1 (70B) + H200 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency llama3.1 (70B) 4 Simple Chat [128:128] 24 15.3 3542 tokens/sec 90.59 ms 29.53 ms 3840.9 ms llama3.1 (70B) 4 Summarization / RAG [2024:128] 4 3.45 6139 tokens/sec 455.96 ms 46.11 ms 6311.93 ms llama3.1 (70B) 4 Classification [1024:30] 10 7 7202 tokens/sec 341.49 ms 59.28 ms 2060.61 ms llama3.1 (70B) 4 Creative Writing [200:2024] 8 2.35 2782 tokens/sec 69.44 ms 25.09 ms 50826.51 ms LLAMA 3.1 (70B) + H100 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency llama3.1 (70B) 4 Simple Chat [128:128] 24 15 3438 tokens/sec 84.84 ms 30.63 ms 3976.12 ms llama3.1 (70B) 4 Summarization / RAG [2024:128] 4 3.45 5884.31 tokens/sec 461.72 ms 48.43 ms 6612.33 ms llama3.1 (70B) 4 Classification [1024:30] 10 6.95 7129 tokens/sec 331.69 ms 62.41 ms 2141.58 ms llama3.1 (70B) 4 Creative Writing [200:2024] 8 2.04 2626.71 tokens/sec 74.20 ms 27.31 ms 55322.33 ms Offline Performance ​ While the serving inference over API often introduces network latency and concurrency overhead, in case of an offline or batch applications both factors are often controllable. Consider an example of a video generation pipeline that runs in the background asynchronously and writes the generated video to an object storage bucket. In such scenarios, we observe that the raw token throughput is important metric to optimize for. In this section, we benchmark LLM Inference in offline/batch applications that have local GPU access. Benchmarking Framework : tensor-RT LLM Benchmarking tool LLAMA 3.1 (8B) ​ Model TP / GPUs Input - Output H200 H100 H100 H100 A100 LLaMA 3.1 (8B) 1 128, 128 30637.29 27006.16 15861.63 16119.63 6051.62 128, 2048 20787.93 20190.18 9536.49 9625.49 4910.03 128, 4096 12348.35 12876.06 5357.98 5807.98 3157.45 500, 2000 19079.02 15363.20 8043.10 7927.10 3897.62 1000, 1000 15807.43 14555.28 7425.07 7513.07 3747.46 2048, 128 3570.99 3095.41 1625.07 2000.07 905.56 2048, 2048 9026.93 8632.42 4055.61 4128.61 1826.86 5000, 500 3782.15 2979.61 1555.20 1784.20 831.09 20000, 2000 1487.86 1503.69 852.58 528.58 81.47 LLAMA 3.1 (70B) ​ Model TP / GPUs Input - Output H200 (FP8) H100 (FP8) H100 (mixed) LLaMA 3.1 (70B) 1 128, 128 3959.23 2633.65 128, 2048 1787.33 709.73 128, 4096 883.15 500, 2000 1144.49 868.24 1000, 1000 1535.40 646.07 2048, 128 528.06 325.44 2048, 2048 722.55 427.02 5000, 500 394.32 169.98 20000, 2000 121.02 LLaMA 3.1 (70B) 4 128, 128 10226.19 6085.74 128, 2048 11155.97 5860.27 128, 4096 7454.89 3400.03 500, 2000 9670.33 4419.09 1000, 1000 7081.35 4141.52 2048, 128 1558.33 772.81 2048, 2048 4777.41 2650.39 5000, 500 987.63 787.96 20000, 2000 720.06 261.36 Benchmarking Kit ​ vLLM Scripts ​ Clone Repo $ git clone https://github.com/vllm-project/vllm Start VLLM from terminal $ pip install vllm $ vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8080 --tensor-parallel-size <gpu-count> Start the script from another terminal $ cd vllm/benchmarks $ python3 benchmark_serving.py --backend openai --host localhost --port 8080 --dataset-name=random --random-input-len=<token-size> --random-output-len=<token-size> --model <model-name> --num-prompts 200 --request-rate <request-rate> Tensor-RT LLM Scripts ​ Create a node in TIR with image Tensor-RT LLM Builder . Click on Jupyter labs URL Open terminal to clone repo: $ git clone https://github.com/NVIDIA/TensorRT-LLM $ cd TensorRT-LLM Create dataset $ python benchmarks/cpp/prepare_dataset.py --tokenizer=$model_name --stdout token-norm-dist --num-requests=$num_requests --input-mean=$isl --output-mean=$osl --input-stdev=0 --output-stdev=0 > $dataset_file Build a tensor-rt engine $ trtllm-bench --model $model_name build --tp_size $tp_size --pp_size $pp_size --quantization FP8 --dataset $dataset_file Run a benchmark with a dataset $ trtllm-bench --model $model_name throughput --dataset $dataset_file --engine_dir $engine_dir Introduction Serving Performance Offline Performance Benchmarking Kit",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/benchmarks/inference_benchmarks/#serving-performance",
    "site_type": "Benchmarking Website",
    "content": "Inference Benchmarking | E2E Cloud Skip to main content On this page Inference Benchmarks Introduction ​ E2E Networks provides high-performance LLM inference with TIR ( an end-to-end AI/ML Platform ) leveraging state-of-the-art GPU Infrastructure. This page covers the methodology and performance highlights for latency and throughput of LLM Inference on GPUs such as H100, H200, A100 etc. Serving Performance ​ Generative AI Applications often employ an inference engine for performing LLM inference. vLLM is one of the mostly widely used inference engine that supports features such as continuous batching, open AI compatibility, etc. In this section, we evaluate the performance of vLLM with a single GPU (e.g. H100) at serving concurrent requests. The numbers obtained here are based on default configuration of vLLM to showcase a generic solution. Our team can help you further tune these numbers based on your specific use case. Benchmarking Framework : vLLM official benchmarking script with random tokens dataset Metrics : Time to First Token (TTFT): The latency between the initial inference request to the model and the return of the first token. Inter-Token Latency (ITL): The latency between each token after the first. Total Latency: TTFT + (no of tokens * ITL) Token Throughput: The total number of tokens generated per second Request Throughput: The total number of request completed per second Inputs : Input & Output token lengths based on task type: for e.g. summarization often involves a large input and small output Request rate: no of requests / second. we settled on this -after trial and error- based on best results for a combination of input/output tokens Endpoint Protocol : HTTPS LLAMA 3.1 (8B) + H200 ​ Model GPUs Task Type Input-Output Request Rate Requests/Sec Throughput (tokens/sec) TTFT (ms) TPOT (ms) Total Latency (ms) LLAMA3.1 (8B) 1 Simple Chat [128:128] 64 37.32 8955 54.37 16.09 2083.26 LLAMA3.1 (8B) 1 Summarization / RAG [2024:128] 12 8.95 19428 204.51 32.45 4325.66 LLAMA3.1 (8B) 1 Classification [1024:30] 24 19.03 20088 89.05 19.20 645.85 LLAMA3.1 (8B) 1 Creative Writing [200:2024] 4 1.32 2543 24.32 9.30 18838.22 LLAMA 3.1 (8B) + H100 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency LLAMA3.1 (8B) 1 Simple Chat [128:128] 64 35.04 8399 tokens/sec 28.84 ms 22.27 ms 2857.12 ms LLAMA3.1 (8B) 1 Summarization / RAG [2024:128] 12 8.95 19127 tokens/sec 200.06 ms 35.51 ms 4709.83 ms LLAMA3.1 (8B) 1 Classification [1024:30] 24 19.03 19979 tokens/sec 92.74 ms 22.07 ms 732.77 ms LLAMA3.1 (8B) 1 Creative Writing [200:2024] 8 3.42 5060 tokens/sec 47.25 ms 21.57 ms 43682.36 ms LLAMA 3.1 (70B) + H200 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency llama3.1 (70B) 4 Simple Chat [128:128] 24 15.3 3542 tokens/sec 90.59 ms 29.53 ms 3840.9 ms llama3.1 (70B) 4 Summarization / RAG [2024:128] 4 3.45 6139 tokens/sec 455.96 ms 46.11 ms 6311.93 ms llama3.1 (70B) 4 Classification [1024:30] 10 7 7202 tokens/sec 341.49 ms 59.28 ms 2060.61 ms llama3.1 (70B) 4 Creative Writing [200:2024] 8 2.35 2782 tokens/sec 69.44 ms 25.09 ms 50826.51 ms LLAMA 3.1 (70B) + H100 ​ Model GPUs Task Type Input - Output Request Rate Requests/Sec Throughput Time to First Token (TTFT) Time Per Output Token (TPOT) Total Latency llama3.1 (70B) 4 Simple Chat [128:128] 24 15 3438 tokens/sec 84.84 ms 30.63 ms 3976.12 ms llama3.1 (70B) 4 Summarization / RAG [2024:128] 4 3.45 5884.31 tokens/sec 461.72 ms 48.43 ms 6612.33 ms llama3.1 (70B) 4 Classification [1024:30] 10 6.95 7129 tokens/sec 331.69 ms 62.41 ms 2141.58 ms llama3.1 (70B) 4 Creative Writing [200:2024] 8 2.04 2626.71 tokens/sec 74.20 ms 27.31 ms 55322.33 ms Offline Performance ​ While the serving inference over API often introduces network latency and concurrency overhead, in case of an offline or batch applications both factors are often controllable. Consider an example of a video generation pipeline that runs in the background asynchronously and writes the generated video to an object storage bucket. In such scenarios, we observe that the raw token throughput is important metric to optimize for. In this section, we benchmark LLM Inference in offline/batch applications that have local GPU access. Benchmarking Framework : tensor-RT LLM Benchmarking tool LLAMA 3.1 (8B) ​ Model TP / GPUs Input - Output H200 H100 H100 H100 A100 LLaMA 3.1 (8B) 1 128, 128 30637.29 27006.16 15861.63 16119.63 6051.62 128, 2048 20787.93 20190.18 9536.49 9625.49 4910.03 128, 4096 12348.35 12876.06 5357.98 5807.98 3157.45 500, 2000 19079.02 15363.20 8043.10 7927.10 3897.62 1000, 1000 15807.43 14555.28 7425.07 7513.07 3747.46 2048, 128 3570.99 3095.41 1625.07 2000.07 905.56 2048, 2048 9026.93 8632.42 4055.61 4128.61 1826.86 5000, 500 3782.15 2979.61 1555.20 1784.20 831.09 20000, 2000 1487.86 1503.69 852.58 528.58 81.47 LLAMA 3.1 (70B) ​ Model TP / GPUs Input - Output H200 (FP8) H100 (FP8) H100 (mixed) LLaMA 3.1 (70B) 1 128, 128 3959.23 2633.65 128, 2048 1787.33 709.73 128, 4096 883.15 500, 2000 1144.49 868.24 1000, 1000 1535.40 646.07 2048, 128 528.06 325.44 2048, 2048 722.55 427.02 5000, 500 394.32 169.98 20000, 2000 121.02 LLaMA 3.1 (70B) 4 128, 128 10226.19 6085.74 128, 2048 11155.97 5860.27 128, 4096 7454.89 3400.03 500, 2000 9670.33 4419.09 1000, 1000 7081.35 4141.52 2048, 128 1558.33 772.81 2048, 2048 4777.41 2650.39 5000, 500 987.63 787.96 20000, 2000 720.06 261.36 Benchmarking Kit ​ vLLM Scripts ​ Clone Repo $ git clone https://github.com/vllm-project/vllm Start VLLM from terminal $ pip install vllm $ vllm serve meta-llama/Meta-Llama-3.1-70B-Instruct --port 8080 --tensor-parallel-size <gpu-count> Start the script from another terminal $ cd vllm/benchmarks $ python3 benchmark_serving.py --backend openai --host localhost --port 8080 --dataset-name=random --random-input-len=<token-size> --random-output-len=<token-size> --model <model-name> --num-prompts 200 --request-rate <request-rate> Tensor-RT LLM Scripts ​ Create a node in TIR with image Tensor-RT LLM Builder . Click on Jupyter labs URL Open terminal to clone repo: $ git clone https://github.com/NVIDIA/TensorRT-LLM $ cd TensorRT-LLM Create dataset $ python benchmarks/cpp/prepare_dataset.py --tokenizer=$model_name --stdout token-norm-dist --num-requests=$num_requests --input-mean=$isl --output-mean=$osl --input-stdev=0 --output-stdev=0 > $dataset_file Build a tensor-rt engine $ trtllm-bench --model $model_name build --tp_size $tp_size --pp_size $pp_size --quantization FP8 --dataset $dataset_file Run a benchmark with a dataset $ trtllm-bench --model $model_name throughput --dataset $dataset_file --engine_dir $engine_dir Introduction Serving Performance Offline Performance Benchmarking Kit",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/Security/SSH_Key/",
    "site_type": "Benchmarking Website",
    "content": "SSH Keys Management | E2E Cloud Skip to main content On this page SSH Keys Management Introduction ​ Setting up SSH-based security to access your server is a much more effective way than the use of a manual root password. Cracking the security system of a node depending on SSH keys is nearly impossible since it secures your node in a more sophisticated way by the use of encoded keys. Why is password-based authentication vulnerable? ​ A server can authenticate & grant access to the users with different access methods. The most basic of these is password-based authentication, which is easy to use but isn’t the most secure. Modern processing power combined with automated scripts makes brute-forcing a password-protected account very possible since passwords generally are not complex. SSH keys prove to be a reliable and secure alternative. What are SSH keys? ​ SSH key pairs are two cryptographically secure keys that can be used to authenticate a client to an SSH server. Each key pair consists of a public key and a private key. The private key is retained by the client on their local machine and should be kept secret. Any compromise of the private key will allow the attacker to log into servers that are configured with the associated public key without additional authentication. As an additional precaution, the key can be encrypted on disk with a passphrase. The public key is uploaded onto the remote server that you want to be able to log into with SSH. When a client attempts to authenticate using SSH keys, the server can test the client on whether they are in possession of the private key. If the key-pair matches, then a shell session is spawned, or the requested command is executed. How do SSH keys work? ​ A key pair will be generated on your local PC. Generating a key pair provides you with two long strings of characters: a public and a private key. The public key will be added to your node. The corresponding private key pair will be saved on your local PC. Every time you access your node, the SSH system will look up the private key pair of the public key added to it. The system will unlock only when the two keys match. You can also disable the root password after the SSH keys are set up. Note Secure the private key: Make sure that you add the public key to the servers and that the private key is saved in a secure location on your PC. Manage SSH Keys ​ This guide shows you how to access & manage your SSH keys in the E2E Networks TIR AI PLATFORM. Logging into E2E Networks ‘TIR AI PLATFORM’ ​ Please go to ‘TIR AI PLATFORM’ and log in using your credentials set up at the time of creating and activating the E2E Networks ‘TIR AI PLATFORM’. Navigate to SSH Keys ​ After you log in to the E2E Networks ‘TIR AI PLATFORM’, you can click on the left side of the TIR AI PLATFORM dashboard, then click on the “SSH Keys” sub-menu available under the services menu. Add/Delete SSH Keys ​ If you do not have SSH keys and want to create an SSH key pair to access your node, follow the tutorial for your computer OS: MAC Windows Linux ADD SSH Keys ​ Click on the Add Key button: You need to label your SSH key (optional) for easy identification purposes. You can either load the file to add the public SSH Key by clicking the ‘Load from file’ or paste the contents of your public SSH key (copy it as it is and paste it) in the SSH Key content field. Note Before you paste your public SSH keys into your content field, you must check the format of each public SSH key file that you plan to add. After adding the public key, you need to click the ‘Add Key’ button. You will be automatically routed to the ‘Manage SSH Keys’ page. Similarly, you can store multiple SSH Public Keys in TIR AI PLATFORM, which will be accessible to multiple users with different SSH keypairs. Delete SSH Keys ​ To remove a public key, click on the delete button, which will permanently delete your public key. Note Any user accessing the node from the SSH key pair will not be able to access the node once the key is removed from My Account. Using an SSH Key ​ Now the SSH key is added to your TIR AI PLATFORM, and it can be used with any new notebook that you create in the future by simply selecting the public key during the notebook creation process. You can also refer to enable/disable password-based authentication for SSH access to the server . Import SSH keys ​ To import all SSH keys from MyAccount (default project), click on the SYNC SSH button. Note If a different public key with the same name as in TIR exists in MyAccount, that key will not be imported. If the same key exists in MyAccount but with a different name, it will also not be imported. Introduction Why is password-based authentication vulnerable? What are SSH keys? How do SSH keys work? Manage SSH Keys Logging into E2E Networks ‘TIR AI PLATFORM’ Navigate to SSH Keys Add/Delete SSH Keys ADD SSH Keys Delete SSH Keys Using an SSH Key Import SSH keys",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Benchmarking Website",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/myaccount/",
    "site_type": "Benchmarking Website",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation MyAccount Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs, making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Getting Started Compute Storage Database Network Billing Sign Up Process for Indian and International Customers Sign In Sign In Methods IAM Identity and Access Management Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Benchmarking Website",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/projects/",
    "site_type": "Documentation",
    "content": "Projects | E2E Cloud Skip to main content Creating Projects on TIR-AI Platform For creating GPU Projects, go to the TIR AI Platform. You will be redirected to the TIR-AI platform dashboard with a default project created. The user can also create customized projects by clicking on the plus icon next to the default project name. Users can input a customized name for the projects and save the required name by clicking on the \"✓\" icon. Users can see the number of projects by clicking the dropdown. Users can delete a project from the project settings by selecting the associated project that needs to be deleted.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Documentation",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Documentation",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/",
    "site_type": "Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/private_cluster/",
    "site_type": "Documentation",
    "content": "Private Cluster | E2E Cloud Skip to main content On this page Private Cluster Private Cluster enables the creation of a dedicated environment with a predefined allocation of GPU resources. The pricing for the Private Cluster is fixed, unaffected by the actual usage percentage of the allocated resources. Additionally, deploying Nodes, Inference engines, or Vector Databases within the Private Cluster incurs no extra charges. Create Private Cluster ​ To create a new Private Cluster , click the Create Private Cluster button. Select the desired Cluster Configuration by choosing the appropriate machine type with the required GPU and an available plan. Additionally, you can apply filters to the available resources based on CPU , RAM , or GPU Card specifications. On this page, you can view the details of the selected plan. Depending on whether you choose an Hourly-Billed Plan or a Committed Plan , the summary section will display the corresponding details and associated costs. Private Cluster Hourly plan ​ You can select an Hourly-Based Plan based on your requirements, view the estimated cost, and then click Next to proceed. Private Cluster Committed plan ​ In a Private Cluster with a committed plan, users can choose one of the following post-expiry actions: auto-renew the committed plan, auto-start hourly billing, or automatically delete the cluster after expiry. Manage Private Cluster ​ Overview ​ You can view the details of the selected Private Cluster , including the Cluster Name , Number of Nodes , Plan Name , and the Cluster Node Configuration , which displays the count of GPUs , CPUs , and RAM allocated within the cluster. Monitoring ​ You can view the Disk Usage and Memory Usage for the selected Node within the Private Cluster . Additionally, the following metrics are also available: GPU Utilization , GPU Temperature , CPU Utilization , Memory Utilization , Disk Total Read Bytes , and Disk Total Write Bytes . Services ​ You can view the list of Services that have been launched on the cluster. Actions ​ In the Actions section, you can perform two operation which is Update cluster in which you can increase the Node count and Delete cluster . Update Private Cluster ​ In Actions section, click on Update Cluster . To update the node count, click on the Additional Node Count (+) button and increase the nodes as per your requirements. Delete Private Cluster ​ In Actions section, click on Delete Cluster and confirm. Create Private Cluster Manage Private Cluster Overview Monitoring Services Actions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/RAG/",
    "site_type": "Documentation",
    "content": "RAG (Retrieval-Augmented Generation) | E2E Cloud Skip to main content On this page RAG (Retrieval-Augmented Generation) Introduction ​ Retrieval-Augmented Generation (RAG) enhances the performance of large language models (LLMs) by enabling them to access a specific knowledge base, rather than relying solely on their general training data. LLMs, which are trained on extensive datasets and contain billions of parameters, excel at generating responses for tasks like Q&A, translation, and text completion. RAG further refines this capability by allowing LLMs to retrieve information from a trusted external knowledge source—such as an organization’s internal data—before generating responses. This approach enables accurate, context-specific, and up-to-date answers without requiring model retraining, making it an efficient and cost-effective way to tailor LLM responses for specialized domains. Retrieval ​ This refers to the process of fetching or retrieving information from an external source, usually a database, knowledge base, or document repository. In the context of RAG, retrieval is the process of searching for relevant data (such as text or documents) based on a query or input provided by the user or system. Augmented ​ Augmentation refers to the enhancement or improvement of something. In the case of RAG, it means enhancing the generation process of a model by supplementing it with additional, relevant information retrieved during the retrieval step. Rather than relying solely on the model's internal knowledge (which can be limited), the model is \"augmented\" with external data, making it more accurate and context-aware. Generation ​ Generation refers to the process of creating or producing content, such as text, based on an input or prompt. In the context of RAG, it refers to the generation of text or responses by the large language model (LLM). After retrieving relevant data, the LLM generates an output, typically by using both the retrieved information and its own internal knowledge. Use Case which RAG Supports ​ RAG (Retrieval-Augmented Generation) supports a range of specific use cases, making it a powerful framework for applications that require the synthesis of contextually relevant information. Here are some notable use cases: 1. Creating Chat Assistants ​ Customer Support Bots : RAG enables the development of chatbot that can answer customer inquiries using a company's internal knowledge base or FAQ repository, providing detailed, context-aware responses. Virtual Assistants : Personal assistants powered by RAG can access external knowledge bases to provide informative responses that go beyond their training data, making them capable of more personalized interactions. Technical Support Assistants : Assistants designed for IT or technical domains can retrieve documentation, troubleshooting guides, or step-by-step instructions from a relevant database to help users with complex queries. 2. Handling FAQs and Knowledge Management ​ FAQ Automation : RAG can be used to create intelligent FAQ systems that retrieve specific answers from company documentation, ensuring that responses are always current and accurate. Dynamic Knowledge Base Queries : Organizations can leverage RAG to allow employees or users to search and receive comprehensive, generated responses from extensive knowledge bases that span different topics or departments. Internal Document Search Tools : Tools powered by RAG can facilitate document search within an enterprise, where users input queries and receive synthesized answers extracted from various internal documents or policies. 3. Content Generation ​ Article Summarization : RAG can pull relevant information from multiple sources and generate cohesive summaries or articles. Report Compilation : It can compile data from various reports and generate a consolidated document or response. Educational Tools : RAG can help create interactive learning tools that provide informative and precise responses from educational databases or textbooks. 4. Research and Analysis ​ Data-Driven Research Assistants : Researchers can use RAG to query large academic databases or datasets, retrieving relevant studies and generating summaries or insights. Legal and Compliance Analysis : In legal or regulatory fields, RAG-powered tools can search through large collections of legal documents, case studies, and compliance requirements, delivering detailed, contextually enriched responses. 5. Personalized Recommendations ​ Content Curation : RAG can tailor recommendations for articles, videos, or other resources based on a user's queries and preferences by pulling related content from knowledge bases. Product Support : Assistants powered by RAG can offer troubleshooting or how-to recommendations specific to the user's products or issues. RAG (Retrieval-Augmented Generation) enhances standard LLMs by integrating a retrieval mechanism that accesses external, up-to-date data sources. This approach improves the accuracy, relevance, and contextuality of responses, addressing limitations such as outdated knowledge and hallucination. RAG allows models to provide domain-specific and real-time information without needing retraining, making it ideal for applications requiring precise and current data. Introduction Retrieval Augmented Generation Use Case which RAG Supports 1. Creating Chat Assistants 2. Handling FAQs and Knowledge Management 3. Content Generation 4. Research and Analysis 5. Personalized Recommendations",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-indian-customers",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Computing Platform Documentation/Support",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/create_encrypted_eos/",
    "site_type": "Documentation",
    "content": "Steps for Encryption | E2E Cloud Skip to main content On this page Steps for Encryption E2E Networks provides two methods to secure your objects in Object Storage using encryption: E2E Managed Encryption – Encryption is handled automatically by E2E Networks. User-Managed Keys – User manage and apply your own encryption keys using the MinIO client (mc) . Option 1: Enable E2E Managed Encryption (Server-Side) ​ E2E Managed Encryption allows you to encrypt your bucket and its contents automatically. E2E Networks handles key management and encryption at rest. Steps to Enable E2E Managed Encryption ​ Navigate to Object Storage Go to Object Storage under Storage section from the MyAccount dashboard. Create a New Bucket Click the Add Bucket button. The Enable Encryption checkbox will be checked by default . Proceed to create the bucket. It will now be encrypted by E2E Managed encryption service. Generate Access Credentials Click on Manage Access Keys . Then click Create Access Key . Enter a name and click Generate Keys . Configure Credentials Locally Use the command shown in the UI to configure your credentials locally using the MinIO client: mc alias set <alias> https://<eos-url> <ACCESS_KEY> <SECRET_KEY> (This command is pre-filled in the UI for your convenience.) Attach Access Key to the Bucket Return to your Buckets list. Open the relevant bucket and go to the Permissions tab. Click Attach Access Key . Select the newly created access key. Choose Bucket Admin to allow full permissions. Upload an Object Go to the Objects tab inside the bucket. Click the Upload button and select the file you want to upload. P Verify Encryption Status Run the following command to verify encryption on the uploaded file: mc stat <alias>/<bucket-name>/<object-name> The output will look like this. Option 2: Encryption through User Manged Keys ​ You can also manage encryption yourself using your own passphrases or keys. Client-Side Steps ​ Follow these steps to encrypt objects before uploading them: Generate a 256-bit Hex Encryption Key openssl rand -base64 32 | base64 -d | xxd -p -c 32 Upload the Object with Encryption mc cp <local-file-path> <alias>/<bucket-name> --enc-c \"<alias>/<bucket-name>/ <object-name>=<hex-encoded-256-bit-key>\" Parameters ​ <local-file-path> : Path to the file you wish to upload. Example : seed_data.json <alias> : The alias configured in your MinIO Client for the storage. Example : enctest <bucket-name> : Name of your target bucket. Example : my-bucket <object-key> : Desired name for the object in the bucket. Example : seed_data.json <hex-encoded-256-bit-key> : A 64-character hexadecimal string representing your 256-bit encryption key. Example : 4a6566656b656e6472616b61737361636b656e6372797074696f6e6b6579733031323334 Important Note ​ All future operations on this object — such as download , viewing metadata — will require the same encryption key , provided in this format: --enc-c \"<bucket-name>/<object-key>=<hex-encoded-256-bit-key>\" Delete operations are not restricted by encryption keys. Data Recovery Warning : If the encryption key is lost, data will be permanently inaccessible. Recovery is not possible without the original encryption key. UI Action Error : Trying to do operations such as download/create presigned-URL from UI on objects encrypted with User Managed Keys will result in an error. Note E2E Managed Encryption settings can be overridden by User Managed Keys Encryption during individual object upload through Minio Client (mc cli). Option 1: Enable E2E Managed Encryption (Server-Side) Steps to Enable E2E Managed Encryption Option 2: Encryption through User Manged Keys Client-Side Steps Important Note",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation MyAccount Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs, making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Getting Started Compute Storage Database Network Billing Sign Up Process for Indian and International Customers Sign In Sign In Methods IAM Identity and Access Management Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/iam/",
    "site_type": "Cloud Computing Provider",
    "content": "IAM | E2E Cloud Skip to main content On this page IAM Policy-Based Access Control (PBAC) is a mechanism for managing user access to individual or multiple systems, where the permissions granted are contingent upon the user's business responsibilities aligned with predefined policies or custom policies. In contrast to the conventional method of auditing and modifying roles organization-wide, PBAC provides the agility to swiftly adjust access privileges in response to evolving requirements. This ensures that assets remain safeguarded through the enforcement of established rules and policies. PBAC stands out as a versatile authorization solution, capable of accommodating various access points by automating security controls within applications and data. IAM (Identity and Access Management) ​ IAM Model Overview: ​ IAM, which stands for Identity and Access Management, encompasses a structured system for managing user identities and their access privileges within an account. The IAM model comprises various user roles and their corresponding permissions. Key Concepts: ​ IAM Entry: Each IAM entry contains mappings with a primary customer and their associated secondary users. Instead of referencing a contact person table, information regarding secondary users is stored within the IAM table. IAM User Types: Owner: Represents the primary account holder. Primary: Users with existing sign-ups on the platform who can access other accounts using the Primary IAM feature, also known as Multi-CRN view. Multi CRN ​ A Multi-CRN perspective offers users the ability to toggle between multiple CRNs (Customer Reference Numbers). This occurs when a customer (Customer A) who is already registered grants access to some of their projects to another customer (Customer B) who is also registered. As a result, Customer B can access Customer A's projects by switching between their respective CRNs. Contact: Users without existing sign-ups on the platform. Roles and Permissions ​ Roles Resource View Resource Management IAM (User Management) Billing Operations (Pay Now, Auto Pay, and Account Statement) Payment Reminders/Invoice Handling Admin ✓ ✓ ✓ ✓ ✓ Project Lead ✓ ✓ ✓ (except Admin) × × Billing × × × ✓ ✓ Member Policy-based Access Policy-based Access × Policy-based Access × Billing+Member Policy-based Access Policy-based Access × ✓ ✓ Viewer ✓ × × × × Admin: Holds full access rights, including the management of resources and projects, access to the billing dashboard, the handling of invoices, and the ability to add or remove other IAM users. Administrators are essentially co-owners of the account. Project Lead: Has access to resource allocation and project management, with the authority to add or remove other IAM users (excluding Admins). The Project Lead does not have access to billing. Billing User: Authorized to manage billing functions such as Pay Now, Auto Pay, and Account Statements, including viewing and paying outstanding balances, accessing invoices, and configuring auto-pay settings. Member: Users with limited access to the account, with the ability to select services and adhere to established policies that restrict their view within services. Unauthorized attempts to access restricted services or perform restricted actions will redirect them to an unauthorized page. Billing+Member: Users with restricted service access but unrestricted access to the billing dashboard. They can perform any action within the billing dashboard without restrictions. Viewer: Has read-only access to view resources. Cannot create, modify, or delete resources. Suitable for users who only need visibility. Note To use IAM, you have to follow these steps: You have to add an IAM user. You have to create a project. You have to create custom policies or you can use predefined policies. Assign the project and policies to the user. Add User ​ To add users, follow these steps: Navigate to the IAM section on the Dashboard. By default, the details of Owner are displayed in the list. To add a new user to the project, simply click on the 'Add User' option. After selecting \"Add User,\" a new page labeled \"Add New User\" will open. On this page, you need to enter the user's email and choose a role from the dropdown menu. The available roles include Member, Billing, Project Manager, Admin, and Billing+ Member. If you choose the role of Admin, Project Manager, or Billing, predefined policies will be applied to the user based on their role. After selecting all the parameters, click on Add User. Note In the absence of an available policy in the project, you must initially add a custom policy to the project. If you choose the role of \"Member,\" all available projects will be displayed below. After selecting a specific project, you can then assign one or more policies to that user. Upon selecting \"Add User,\" the user will appear in the IAM page under the \"All Users\" section with the status set as 'Invited.' An invitation link will be sent to the user's email address. After clicking the link, a registration form will be presented for completion. Upon completing all the required details in the registration form, the user will be successfully registered. Following registration, the customer must log in using their provided credentials. Note If the customer is an existing user on the E2E platform, they will find the invitation in the Invitation section on the Dashboard. Upon selecting the Invitation button, the Invitation page will be displayed. On the Manage Invitations page, you can view the invitations received and take actions such as accepting or declining them based on your preference. Upon accepting the invitation, the user will appear in the All User list with their assigned role. Actions ​ Reset Password: ​ Click on the \"Reset Password\" action to reset a member's password. Edit Roles and Policies: ​ To modify the roles and policies of a member, click on the Edit action. Once you have made the necessary changes, click on the \"Update User\" button to save the modifications. Delete User: ​ To remove a user, click on the Delete action. Upon selecting the delete action button, a confirmation pop-up will appear on the page. Click on the delete button within the pop-up to confirm the deletion, and the user will be removed from the user list. Manage Project ​ Project Management ​ To manage projects, navigate to the IAM page and click on the Manage Project tab. By default, a Default Project will be displayed in the list. To create a new project, provide a name for the project and click on the Create button. Once a project is created, it will be visible in the Recent tab. To switch from one project to another, select the desired project by clicking on the radio button. A pop-up will appear, prompting you to click on \"Switch Project.\" Upon doing so, the switch will be completed, and you'll be in the selected project. To designate a project as a starred project, click on the star button located in the Starred section. To view all projects, click on the \"All\" section, where you can see a comprehensive list of all projects associated with that user. Member Management ​ Add Member: ​ To modify a project and add members, click on the edit button associated with that project. Upon clicking the edit button, you will find the option to add members to the project. Click on it to proceed. Following the selection of \"Add Member,\" the Add Member page will open. After entering all the necessary information, such as the new member's details and policies, click on \"Save Changes\" to confirm. Modify User's Policy: ​ To modify a user's policy, click on the edit button and then select the appropriate option on the right button. Remove Member: ​ To remove a member from the project, click on the delete button. A popup will appear, and upon confirmation by clicking the Delete button within the popup, the member will be successfully deleted from the project. Policy Set ​ To access established policies, go to the IAM page and select the Policy Set section. If you wish to create a new policy, click on the \"Add Policy\" button. After clicking on Add Policy, the Add New Policy page will appear where you need to give the policy set name and description and select the services to be granted access in this policy, then click on the Save button. Upon saving the policy, it will be displayed in the Policy Set section on the IAM page. To execute actions on a policy set, click on the three dots, and a menu of actions will appear. To view the policy services, select the \"View\" action. Upon selecting the \"View\" action, the Services page will open, allowing you to see all the services associated with that policy. To modify the policy set, click on the \"Edit\" action. Upon choosing the \"Edit\" action, the Edit Policy Set Details page will open. On this page, you can add or remove services from the policy set by ticking or unticking the respective options. After making the desired changes, click on the Save button. To remove a policy set, click on the \"Delete\" action. Upon selecting the \"Delete\" action, a pop-up will appear. Click on \"Delete\" within the pop-up, and the policy set will be removed from the policy set list. IAM (Identity and Access Management) IAM Model Overview: Key Concepts: Multi CRN Roles and Permissions Add User Actions Reset Password: Edit Roles and Policies: Delete User: Manage Project Project Management Member Management Policy Set",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/",
    "site_type": "Cloud Computing Provider",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/tir/",
    "site_type": "Cloud Computing Provider",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation TIR: AI/ML Platform Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler TIR, a cutting-edge AI development platform designed to streamline the training, fine-tuning, and serving of large AI models. With optimized GPU containers, pre-configured environments (PyTorch, TensorFlow, Triton), and automated API generation, TIR offers a seamless and end-to-end solution for the AI/ML lifecycle. From model fine-tuning and scalable pipelines to team collaboration and managed inference, TIR is built to unlock the full potential of AI. With integrations like Hugging Face, Weights & Biases, and cloud storage integration options (S3, Azure Blob, Google Drive), TIR empowers teams to innovate efficiently and effectively. Start building the future of AI with TIR today! Getting Started Products & Services Developer's Guide IAM Identity and access managements. Projects Creating Projects on TIR-AI Platform Billing GPU and cpu plans billing. Security API tokens and SSH keys. BenchMarking Performance comparison tool. FAQ Frequently Asked Questions Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/resource-quota-details/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Resource Details get https://api.e2enetworks.com/myaccount/api/v1 /resource-quota-details/ Retrieves the current status of resource quotas. Request Security: API Key & Bearer Auth Query Parameters location string required Location (Delhi or Mumbai) Allowed values: Delhi Mumbai project_id integer required Project ID Find your project id here Responses 200 Successful response with resource quota information Body application/json application/json responses / 200 code integer Example: 200 data object resource_quota_enabled boolean Example: true gpu_and_higher_plans_enabled boolean Example: true resource_quota_used boolean Example: false capped_resources_quota integer Example: 30 consumed_resources_quota integer Example: 2 consumed_quota_details object errors object Example: {} message string Example: Success Auth apikey : Token : Parameters location* : Delhi Mumbai Delhi project_id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/resource-quota-details/?location=Delhi&apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"resource_quota_enabled\" : true , 5 \"gpu_and_higher_plans_enabled\" : true , 6 \"resource_quota_used\" : false , 7 \"capped_resources_quota\" : 30 , 8 \"consumed_resources_quota\" : 2 , 9 \"consumed_quota_details\" : { 10 \"node\" : 0 , 11 \"dbaas\" : 0 , 12 \"load_balancer\" : 1 , 13 \"vpc\" : 1 14 } 15 } , 16 \"errors\" : { } , 17 \"message\" : \"Success\" 18 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/resource-quota-details/get#response-body",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Resource Details get https://api.e2enetworks.com/myaccount/api/v1 /resource-quota-details/ Retrieves the current status of resource quotas. Request Security: API Key & Bearer Auth Query Parameters location string required Location (Delhi or Mumbai) Allowed values: Delhi Mumbai project_id integer required Project ID Find your project id here Responses 200 Successful response with resource quota information Body application/json application/json responses / 200 code integer Example: 200 data object resource_quota_enabled boolean Example: true gpu_and_higher_plans_enabled boolean Example: true resource_quota_used boolean Example: false capped_resources_quota integer Example: 30 consumed_resources_quota integer Example: 2 consumed_quota_details object errors object Example: {} message string Example: Success Auth apikey : Token : Parameters location* : Delhi Mumbai Delhi project_id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/resource-quota-details/?location=Delhi&apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"resource_quota_enabled\" : true , 5 \"gpu_and_higher_plans_enabled\" : true , 6 \"resource_quota_used\" : false , 7 \"capped_resources_quota\" : 30 , 8 \"consumed_resources_quota\" : 2 , 9 \"consumed_quota_details\" : { 10 \"node\" : 0 , 11 \"dbaas\" : 0 , 12 \"load_balancer\" : 1 , 13 \"vpc\" : 1 14 } 15 } , 16 \"errors\" : { } , 17 \"message\" : \"Success\" 18 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/faq/",
    "site_type": "Documentation",
    "content": "Frequently Asked Questions (FAQs) | E2E Cloud Skip to main content On this page Frequently Asked Questions (FAQs) What are the usage limitations of EOS? ​ EOS is highly optimized for the most common scenarios. Below are the limits that you may need to account for while designing your solution with EOS. Browser Access ​ Item Specification Web browser (My Account) upload size limit 30 MB API Limits ​ Item Specification Max number of buckets no-limit Max number of objects per bucket no-limit Max object size 5 TiB Minimum object size 0 B Max object size per PUT operation 5 TiB Max number of parts per upload 10,000 Part size 5 MiB to 5 GiB (Last part can be 0 B to 5 GiB) Maximum number of parts returned per list parts request 1000 Maximum number of objects returned per list objects request 1000 Maximum number of multipart uploads returned per list multipart uploads request 1000 API Restrictions ​ Item Specification Bucket Creation Not permitted CLI Restrictions ​ Item Specification Bucket Creation Not permitted Object Storage Data Transfer Charges ​ The data transfer charge of ₹3.0/GB applies only for external networks (i.e., from e2e to the public). What's the maximum transfer speed between E2E Compute Node and E2E Object Storage? ​ Traffic between E2E Compute Node and E2E Object Storage can leverage up to 40 Gbps of bandwidth. However, the actual transfer rate and network performance depend on several factors, including: The data transfer medium, such as whether it’s between E2E nodes and E2E Object Storage or from an external point to Object Storage via the internet. The size of objects involved in the transfer. The E2E nodes' resources and utilization, including CPU, RAM, Disk I/O, and bandwidth limits. What are the usage limitations of EOS? Browser Access API Limits API Restrictions CLI Restrictions Object Storage Data Transfer Charges What's the maximum transfer speed between E2E Compute Node and E2E Object Storage?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/faq/#object-storage-data-transfer-charges",
    "site_type": "Documentation",
    "content": "Frequently Asked Questions (FAQs) | E2E Cloud Skip to main content On this page Frequently Asked Questions (FAQs) What are the usage limitations of EOS? ​ EOS is highly optimized for the most common scenarios. Below are the limits that you may need to account for while designing your solution with EOS. Browser Access ​ Item Specification Web browser (My Account) upload size limit 30 MB API Limits ​ Item Specification Max number of buckets no-limit Max number of objects per bucket no-limit Max object size 5 TiB Minimum object size 0 B Max object size per PUT operation 5 TiB Max number of parts per upload 10,000 Part size 5 MiB to 5 GiB (Last part can be 0 B to 5 GiB) Maximum number of parts returned per list parts request 1000 Maximum number of objects returned per list objects request 1000 Maximum number of multipart uploads returned per list multipart uploads request 1000 API Restrictions ​ Item Specification Bucket Creation Not permitted CLI Restrictions ​ Item Specification Bucket Creation Not permitted Object Storage Data Transfer Charges ​ The data transfer charge of ₹3.0/GB applies only for external networks (i.e., from e2e to the public). What's the maximum transfer speed between E2E Compute Node and E2E Object Storage? ​ Traffic between E2E Compute Node and E2E Object Storage can leverage up to 40 Gbps of bandwidth. However, the actual transfer rate and network performance depend on several factors, including: The data transfer medium, such as whether it’s between E2E nodes and E2E Object Storage or from an external point to Object Storage via the internet. The size of objects involved in the transfer. The E2E nodes' resources and utilization, including CPU, RAM, Disk I/O, and bandwidth limits. What are the usage limitations of EOS? Browser Access API Limits API Restrictions CLI Restrictions Object Storage Data Transfer Charges What's the maximum transfer speed between E2E Compute Node and E2E Object Storage?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/tags/tag/",
    "site_type": "Documentation",
    "content": "Tags | E2E Cloud Skip to main content On this page Tags Tags are labels or keywords assigned to data, files, or pieces of content to facilitate categorization, search, and retrieval. Tags are typically short, descriptive terms or phrases that help identify the characteristics or attributes of the tagged item. Tags can be user-generated, allowing individuals to assign tags that make sense to them personally. Alternatively, they can be predefined or standardized, providing a predetermined set of tags to ensure consistency and facilitate efficient search and retrieval across a system. How to manage Tag? ​ After you log in to the E2E Networks ‘My Account’, you can click on the “Tags” sub-menu available under the “Settings” section. You will be routed to the ‘Tag Management’ page where you can create new tags, and also see all your tags already created in the list. Create New Tags ​ Click on the ‘Tags” sub-menu available under the Settings section. You will be directed to the ‘Tags Management’ page. Click on the “Create New Tag” button. After clicking on ‘Create new Tag’, a new page will open where you need to provide the tag name and description of the Tag. Then click on the ‘Create’ button and it will be shown in the list. Click on the three dots of the tag, and you can Edit or Delete the tag. If you want to change the name of the tag, click on the Edit button. If you want to delete your tag, click on the Delete button. After clicking on the delete button, the tag will be deleted from the list. The created tags will appear in the list as shown in the above screenshot. Node With Tags ​ Customers can add the tag at the time of Node creation. Customers can also manage the tags from Nodes as shown in the image below. When the customer clicks on the Tag, they will see the ‘Add a tag to your Node’. After clicking on the ‘Add a tag to your Node’, the list of tags will be shown, from where the customer can add a tag to the node. They can also add multiple tags to one Node, and can remove or create new tags. After selecting the tags, click on ‘Apply Tags’ and it will show how many Nodes are attached to the Node. How to manage Tag? Create New Tags Node With Tags",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/wordpress_backup/",
    "site_type": "Tutorial/Documentation",
    "content": "Backup your WordPress | E2E Cloud Skip to main content On this page How to Backup Your WordPress files and Databases to Object Storage. Introduction: ​ Backup copies of your WordPress files and database allow data to be restored from an earlier point in time, helping businesses recover from unplanned events. Storing copies of the data on a separate medium is critical to protect against primary data loss or corruption. In this tutorial, we will walk through the steps involved in backing up and restoring your WordPress files and database using the UpdraftPlus plugin for WordPress. Prerequisite: ​ WordPress Version 3.2 or later Access to the MyAccount Portal. Step 1: Create a Bucket in Object Storage ​ First, create a bucket where you will back up your WordPress files and database. Select Object Storage from the left panel in the Product section, and click on Add Bucket . In this tutorial, we are creating a bucket named backupe2e . Step 2: Grant Admin Access Permission for Your Bucket ​ To backup and restore your data from WordPress, attach an access key to your bucket with bucket admin access. This option is available under the Permission section of your bucket. Click on Attach access key . You can select an existing key if you already have one or create a new one. Here we are creating a new access key called wordpresskey . After generating the key, note down the access key and secret key , as we will use them later in the WordPress plugin to backup and restore. Grant Bucket Admin access permission to the key and attach it to your bucket. Now the key has been attached with admin access. Step 3: Install and Activate the UpdraftPlus Plugin in WordPress ​ UpdraftPlus simplifies backups and restoration. It’s the world’s highest-ranking and most popular scheduled backup plugin, with over three million active installs. Backup your files and database backups to the cloud and restore with a single click! You can skip these steps if you’ve already activated the plugin. If not, follow the steps below: Go to the WordPress Plugin Directory and search for UpdraftPlus . Click on Install Now . After the plugin has been installed, click on Activate . Step 4: Configure Backups to Object Storage Buckets ​ After installing and activating the UpdraftPlus plugin, you need to configure it to backup to the object storage bucket created earlier in Step 1. Go to Settings -> UpdraftPlus Backup -> Settings . Scroll down to the Remote Storage option, and select S3-Compatible Generic . Next, update your bucket and key details: Add the S3 access key and S3 secret key . In the S3 Location option, add your bucket name. In the S3 endpoint , enter objectstore.e2enetworks.net . Once the details have been added, click on Test S3 Settings . If the connection is successful, you’ll see the following output. Scroll down further and save the changes made. Step 5: Backup Your Data to Object Storage ​ After successfully updating the configuration, we will test the backup and restore it to our bucket in the UpdraftPlus plugin. Go to the UpdraftPlus plugin, select the Backup/Restore tab, and click on Backup Now . A backup options window will pop up. Ensure Send this Backup to Remote Storage is ticked. Once the backup is successfully completed, you’ll see the following output. Scroll down to view the details of the latest backups available. You can also verify the backup data is now available in your bucket by refreshing the object storage portal. You will be able to view the backed-up data. Step 6: Restoring Your Data to WordPress ​ To restore your data, click on the Restore button. Select the necessary options for restoring and proceed. Once the restoration is completed, you will see the following output. Conclusion: ​ With the steps outlined above, you can easily backup and restore your files and database to an object storage bucket. Additionally, you can configure timely backups and include/exclude files and folders under the settings. Introduction: Prerequisite: Step 1: Create a Bucket in Object Storage Step 2: Grant Admin Access Permission for Your Bucket Step 3: Install and Activate the UpdraftPlus Plugin in WordPress Step 4: Configure Backups to Object Storage Buckets Step 5: Backup Your Data to Object Storage Step 6: Restoring Your Data to WordPress Conclusion:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Tutorial/Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Tutorial/Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Tutorial/Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Tutorial/Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Tutorial/Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Service Provider",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Service Provider",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Service Provider",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Service Provider",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Service Provider",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Cloud Service Provider",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation/Tutorial",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation/Tutorial",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation/Tutorial",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation/Tutorial",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/#prerequisites",
    "site_type": "Documentation/Tutorial",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation/Tutorial",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Storage Service Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-github-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/#key-topics",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/connect_dbaas/",
    "site_type": "Documentation",
    "content": "Connect DBaaS | E2E Cloud Skip to main content On this page Connecting Kubernetes Cluster to E2E DBaaS This article will guide you on how to integrate Kubernetes with Database as a Service (E2E DBaaS). Using an external Database as a Service (E2E DBaaS) with Kubernetes offers several benefits. This reduces the administrative burden on your Kubernetes team, allowing them to focus on application development and deployment. Benefits of Using E2E DBaaS with Kubernetes ​ High Availability: E2E DBaaS, especially when provided as managed services, often come with built-in high availability features. This means your database can continue to operate even if a pod in your Kubernetes cluster fails, contributing to improved application uptime and reliability. Scalability: Kubernetes allows you to scale your application pods independently of the database. When using an E2E DBaaS as an external database, you can scale your application horizontally to meet increased demand without impacting database performance. This scalability is crucial for handling variable workloads. Data Persistence: Placing the database outside of the Kubernetes cluster ensures data persistence, a fundamental requirement for safeguarding crucial application data. Even when your application pods are temporary and subject to rescheduling or replacement, your data remains securely preserved within the external database. In this article, we will implement this integration using the MySQL DB engine. Prerequisites ​ Provision a DBaaS Instance: Begin by provisioning a DBaaS instance using MySQL, choosing the desired version that suits your project requirements. This will serve as your managed database backend. Create a Virtual Private Cloud (VPC): Establish network isolation by creating a VPC. Within this VPC, you will connect your DBaaS and create your Kubernetes cluster. Proper VPC configuration ensures network security and segmentation. Deploy a Kubernetes Cluster: Deploy a Kubernetes cluster within the VPC you've created. This cluster will be the foundation for orchestrating your application containers. Step 1: Establishing the Configuration for Your Kubernetes Cluster ​ To allow Kubernetes to connect with DBaaS, you need to select the Allowed Host IP as the VPC CIDR Range and attach the VPC to the DBaaS where Kubernetes has been deployed. Step 2: Create a ConfigMap for Endpoint Configuration ​ Create a ConfigMap that contains the endpoint information (database host and port): apiVersion : v1 kind : ConfigMap metadata : name : database - config data : DB_HOST : \"10.12.162.11\" # Attached VPC IP address DB_PORT : \"3306\" # MySQL Standard Database Port To create the ConfigMap please run the below mentioned command after successful creation of above mentioned file. kubectl apply -f database-configmap.yaml Step 3: Create a Secret for Username and Password ​ Create a Secret file to securely store the DBaaS username and password in encoded format. Please refer to the screenshot below on how to encode the DBaaS username and password. Create a SecretKey file that contains the key information (database username and password): apiVersion : v1 kind : Secret metadata : name : external - db - credentials type : Opaque data : MYSQL_USERNAME : a3ViZWRiZC5jb20= # DBaaS Username in encoded format MYSQL_ROOT_PASSWORD : Y1gzVWpXRXRRejRmVDRTIQo= # DBaaS Password in encoded format To create the SecretKey please run the below mentioned command after successful creation of above mentioned file. kubectl apply -f database-secret.yaml Step 4 : Create a DB client Deployment ​ apiVersion: apps/v1 kind: Deployment metadata: name: mysql-client-deployment spec: replicas: 1 selector: matchLabels: app: mysql-client template: metadata: labels: app: mysql-client spec: containers: - name: mysql-client image: mariadb env: - name: DB_HOST valueFrom: configMapKeyRef: name: database-config key: DB_HOST - name: DB_PORT valueFrom: configMapKeyRef: name: database-config key: DB_PORT - name: MYSQL_USERNAME valueFrom: secretKeyRef: name: external-db-credentials key: MYSQL_USERNAME - name: MYSQL_ROOT_PASSWORD valueFrom: secretKeyRef: name: external-db-credentials key: MYSQL_ROOT_PASSWORD Check the DB Client Pod Status : To check the Pod status please run the below mentioned command. kubectl get pods To Check the Connectivity from the Pod to DBaaS ​ Execute the following command in the MySQL pod shell: kubectl exec -it mysql-client-deployment-76dfb78bc9-mmtzk -- /bin/bash Benefits of Using E2E DBaaS with Kubernetes Prerequisites Step 1: Establishing the Configuration for Your Kubernetes Cluster Step 2: Create a ConfigMap for Endpoint Configuration Step 3: Create a Secret for Username and Password Step 4 : Create a DB client Deployment To Check the Connectivity from the Pod to DBaaS",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/kubernetes_object_storage/",
    "site_type": "Documentation",
    "content": "Kubernetes With Object Storage (EOS) | E2E Cloud Skip to main content Kubernetes With Object Storage (EOS) i) Create Object Storage and Kubernetes cluster through my account dashboard. ii) Check the cluster nodes using kubectl config . iii) Configure/Install the dependencies of Datashim such as CRDs, SA, etc. using the following command: kubectl create ns kubectl apply -f https://raw.githubusercontent.com/datashim-io/datashim/master/release-tools/manifests/dlf.yaml kubectl wait --for=condition=ready pods -l app.kubernetes.io/name=datashim -n dlf kubectl label namespace default monitor-pods-datasets=enabled iv) Create a new dataset using the below configuration: cat <<EOF | kubectl apply -f - apiVersion: datashim.io/v1alpha1 kind: Dataset metadata: name: example-dataset spec: local: type: \"COS\" accessKeyID: \"{EOS_ACCESS_KEY_ID}\" secretAccessKey: \"{EOS_SECRET_ACCESS_KEY}\" endpoint: \"{EOS_URL}\" bucket: \"{BUCKET_NAME}\" readonly: \"true\" #OPTIONAL, default is false region: \"\" #OPTIONAL EOF Provide the credentials, URL, and Region such as Delhi/Mumbai If everything works okay, you should see a PVC and a ConfigMap named example-dataset which you can mount in your pods. As an easier way to use the Dataset in your pod, you can instead label the pod as follows: Once verified, you can create a new pod/deployment connected with EOS using the following YAML configuration: cat <<EOF | kubectl apply -f - apiVersion: v1 kind: Pod metadata: name: nginx labels: dataset.0.id: \"example-dataset\" dataset.0.useas: \"mount\" spec: containers: - name: nginx image: nginx EOF As a convention, the Dataset will be mounted in /mnt/datasets/example-dataset . We recommend using secrets to pass your Object Storage Service credentials to Datashim. For more information, click here . Refer to the Datashim documentation for more details.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/Network-Load-Balancer/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Network Load Balancer | E2E Cloud Skip to main content On this page Network Load Balancer Initiate Load Balancer Creation ​ Log in to the MyAccount portal using your credentials. On the MyAccount dashboard, click on Load Balancers . Select your Load Balancer Plan ​ Load balancer plans are listed by memory, vCPU, storage, and price. Choose a plan to create your load balancer. After selecting a plan, choose the load balancer type: Application Load Balancer (ALB): Works at Layer 7, making decisions based on content and application logic. Network Load Balancer (NLB): Works at Layer 4, routing TCP traffic based on IP and port. To create a Network Load Balancer (NLB) , click on the Network Load Balancer (NLB) option. Enter configuration details (name, mode, port, SSL certificates, etc.) for front-end and back-end connections. ALB Deployment Help Details ​ Name: A default name is provided based on the selected plan, but you can modify it. Type: Choose between Internal or External load balancer. Target Mapping ​ Backend Name ​ Routing Policy ​ Choose a Balancing Policy: Round Robin: Distributes requests evenly among backend servers. Source IP Hash: Routes based on the user’s IP address to ensure consistency. Least Connection: Routes traffic to the server with the fewest active connections. How Least Connection Works: The load balancer tracks active connections for each server. Incoming requests are routed to the server with the least active connections. Port ​ For NLB , use a port between 1024-65535 , except 8080, 10050, and 9101. ALB does not require a target port. Backends ​ Adding a backend is mandatory. Click Add Backend to add a backend. View the backend list via the dropdown. Peak Performance Features ​ Create New VPC Enable this option to use a VPC IP as the default VPC IP for your load balancer to connect internally. After creating a VPC, you can see it in the dropdown list. Add New Reserve IP Enable this option to use a reserved IP as the default Public IP for your load balancer. You can dynamically update the backend resources of your applications and websites by re-assigning the reserved IP address without downtime. After creating an IP, you can see it in the dropdown list. BitNinja BitNinja is a user-friendly server security tool that combines various powerful defense mechanisms. Every BitNinja-protected load balancer learns from every attack, automatically applying this information across all BitNinja-enabled servers/load balancers, strengthening protection with each attack. Learn more Enable BitNinja Enable this option to use the BitNinja security tool for your load balancer. BitNinja has modules for different types of cyberattacks. It’s easy to install, requires minimal maintenance, and provides immediate protection against a wide range of cyberattacks. Timeouts You can set different timeout values, such as connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, according to your requirements. Summary ​ In the summary section, you can verify your Plan, Type, Details, Network Mapping, and Peak Performance Features. Deploy Load Balancer ​ After filling in all the details successfully, click on the Submit button. It will take a few minutes to set up the scale group, and you will be taken to the ‘Load Balancers’ page. Load Balancer Info ​ You can check all the basic, security, backend configurations, and network details of your load balancer on the Load Balancer info tab. Backend Mapping ​ Once you've created your load balancer, you can manage it from the My Account Portal. Click on the installed LoadBalancer instance to see various management options. To add a backend, click on the Add Backend button. After adding the backend, you can see the list below. You will be redirected to the Edit Load Balancer page, where you can add or change backend and frontend configurations for your load balancer. You will be redirected to the Delete Load Balancer page, where you can delete backend and frontend configurations for your load balancer. Monitoring ​ Monitoring is an essential part of maintaining the reliability, availability, and performance of your load balancer. You can view monitoring information for your load balancer on the Monitoring tab. This data is collected from your load balancer and processed into readable graphs, each based on a different metric. Learn more . Alerts ​ Server health alerts are automatically created for your newly created load balancer using recommended alert policy parameters. You can also set up custom alerts by defining trigger parameters to suit your use case. The alerting system sends automatic response notifications to your defined email list. Learn more . Stats ​ Prometheus Stats ​ Action Logs ​ Action logs contain detailed information about requests sent to your load balancer, such as the date/time the request was received, client’s IP address, request protocol, request paths, and server responses. These access logs are useful for understanding incoming network traffic patterns and troubleshooting any issues. Billing Logs ​ Actions ​ Types of actions you can perform with your Load Balancer. Stopping Your Load Balancer ​ To stop your Load Balancer, click the Stop button. A confirmation popup will appear; click on Power Off to confirm. Upgrade Your Load Balancer ​ The Load Balancer (LB) upgrade feature allows customers to easily upgrade their LB plan based on specific usage needs. To upgrade, click the Upgrade button under Actions. Then, click on the Apply button with the selected plan. The upgrade process will start. Note: Please ensure that your load balancer is stopped when performing the upgrade action. Delete ​ To delete your Load Balancer, click on the Delete button. Initiate Load Balancer Creation Select your Load Balancer Plan Details Target Mapping Peak Performance Features Summary Deploy Load Balancer Load Balancer Info Backend Mapping Monitoring Alerts Stats Prometheus Stats Action Logs Billing Logs Actions Stopping Your Load Balancer Upgrade Your Load Balancer Delete",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/Application-Load-Balancer/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Application Load Balancer | E2E Cloud Skip to main content On this page Application Load Balancer Select your Load Balancer Plan ​ All the load balancer plans are listed based on different memory, vCPU, storage configuration, and price. Select a plan to create the new load balancer. Type ​ After selecting the plan, choose the Application Load Balancer type. Details ​ Name : A default name is provided based on the selected plan, but you can modify it. Type : Select either Internal or External, depending on your requirement. Mode ​ Choose Mode : Mode checks for connection requests using a specified protocol and port for front-end (client to load balancer) connections. E2E Networks Load Balancer supports the following protocols: HTTP and HTTPS protocols independently. HTTPS (secure HTTP) using SSL/TCL: Supports the X-Forwarded headers and requires an SSL certificate on the load balancer. HTTP: Supports the X-Forwarded headers. Note: For back-end (load balancer to nodes) connections, the HTTP protocol is used by default. HTTP Redirect Select \"Redirect HTTP to HTTPS\" if you use HTTPS for the front-end protocol of the load balancer. For web user safety, accessibility, or PCI compliance, it may be essential to enable this redirect. Target Mapping ​ Backend Name Health Check Your load balancer checks the health of the web application configuration you specify. If the backend node responds with a 2xx or 3xx HTTP status code for the defined URL path, it is marked as UP; otherwise, it is marked as DOWN. Select \"Add HTTP Health Checks\" to define HTTP-based monitoring for the health of your backend nodes. Define a URL path to which HTTP HEAD requests will be sent to fetch the response code. Note: The default URL path is / , which can be changed to any other URI path as required. Routing Policy Choose Balancing Policy : Different load balancing policies offer different benefits: Round Robin : Distributes connection requests evenly among backend servers. Source IP Hash : Routes based on a hash of the source IP to keep a user on the same backend server. Least Connection : Distributes traffic by sending requests to the server with the least active connections. Backend Type In the List Type, select either Node or Auto Scale Group (for auto-scaling group nodes) to configure the backend connection. Node ​ Registering an E2E node adds it to your load balancer. The load balancer monitors the health of registered nodes and routes requests only to healthy nodes. Select Node in the list type field to display the Node Details section. Specify the details of virtual nodes you wish to register behind the load balancer, including name, IP (preferably private IP if on E2E cloud), and port. Add Backend Click Add Backend to add a backend. After adding backends, view the backend list by clicking the dropdown. You can also set a websocket timeout for an ALB. Auto Scale Group ​ Registering your Auto Scaling group with a load balancer helps you set up a load-balanced application because EAS enables you to dynamically scale compute nodes based on varying workloads and defined policy. This feature allows you to meet seasonal or fluctuating infrastructure demands, optimize cost, and distribute incoming traffic across your healthy E2E nodes—enhancing scalability and availability. Select the Dynamic Scale group in the list type field. The node details section will display. In the Scale Group Details section, select an application scaling group from the dropdown list to register behind the Load Balancer. After selecting the scale group, define the port to send/receive traffic via the Load Balancer in the Target Port field. To add an auto-scaling group, click on Add New . Peak Performance Features ​ Create New VPC - Enable this option to use a VPC IP as the default VPC IP for your load balancer, allowing internal connections. After creating a VPC, it will appear in the dropdown list. Add New Reserve IP - Enable this option to use a reserved IP as the default Public IP for your load balancer. You can dynamically update backend resources without downtime by re-assigning the reserved IP address. After creating the IP, it will appear in the dropdown list. BitNinja ​ BitNinja is a server security tool that combines powerful defense mechanisms. Each protected load balancer learns from every attack, applying this information across all BitNinja-enabled servers and load balancers. Learn more . Enable BitNinja - Enable this option to use BitNinja for your load balancer. BitNinja offers various modules to defend against cyberattacks, is easy to install, requires minimal maintenance, and provides immediate protection. Timeouts ​ Configure different timeout values like connection timeout, client timeout, server timeout, and HTTP keep-alive timeout as needed. Summary ​ In the Summary section, verify your Plan, Type, Details, Network Mapping, and Peak Performance Features. Deploy Load Balancer ​ After completing all fields, click Submit . The setup may take a few minutes, after which you will be redirected to the ‘Load Balancers’ page. Application Load Balancer Info ​ You can review basic, security, backend configurations, and network details of your load balancer on the Load Balancer Info tab. Backend Mapping ​ Once your load balancer is created, you can access and manage it from the My Account Portal. Click on the installed LoadBalancer instance to see various management options. To add a backend, click on Add Backend . After adding a backend, it will appear in the list below. Users can add or edit multiple backends simultaneously. After making edits, a “Save and Deploy” button appears along with an info icon. Click on Save and Deploy to save changes. The Edit Load Balancer page allows you to modify backend and frontend configurations. You can delete backend and frontend configurations from the Delete Load Balancer page. ACL ​ You can add ACL by clicking ADD ACL button under the ACL tab. Users have the option to add multiple ACL rules simultaneously. After making desired edits, a “Save and Deploy” button will appear. Additionally, an info icon will be displayed next to the newly added rules. Click on the “Save and Deploy” button to save your changes. Access rules can be added based on five conditions. Path Based Condition Host Based Condition Query Parameters Match HTTP Request Method Source IP 1. Path Based Condition ​ You can use path conditions to define rules that route requests based on the URL in the request. The path pattern is applied only to the path of the URL, not to its query parameters. For example, in the below image the path is added as e2enetworks.com/test . Path Matching Types ​ Exact Match : Matches exactly \"pathbase\". Example: \"pathbase\" Prefix Match : Matches any word beginning with \"pathbase\". Example: \"pathbasefolder\", \"pathbaseconfig\", \"pathbasedirectory\" Suffix Match : Matches any word ending with \"pathbase\". Example: \"datapathbase\", \"sourcepathbase\", \"projectpathbase\" Regex Match : Matches any word containing \"pathbase\". Example: \\b\\w*pathbase\\w*\\b (matches words like \"pathbasefile\", \"mypathbaseproject\", etc.) Exact Match (Case Sensitive) : Matches \"pathbase\" exactly with the same capitalization. Example: \"pathbase\" (matches), \"PathBase\" (does not match) Prefix Match (Case Sensitive) : Matches any word beginning with \"pathbase\" with exact capitalization. Example: \"pathbaseFolder\" (matches), \"PathBaseConfig\" (does not match) Suffix Match (Case Sensitive) : Matches the suffix \"pathbase\" with exact capitalization. Example: \"pathbase\" (matches), \"PathBase\" (does not match) Regex Match (Case Sensitive) : Matches words containing \"pathbase\" with exact capitalization. Example: \\b\\w*pathbase\\w*\\b (matches \"pathbasefile\" but not \"mypathbaseProject\") After adding the ACL type Path Based and conditions, you can see the list below. 2. Host Based Condition ​ Use host conditions to define rules that route requests based on the hostname in the host header, known as host-based routing. For example, the host is added as test.e2enetworks.com . Host Matching Types ​ Exact Match : Matches exactly \"hostbase\". Example: \"hostbase\" Prefix Match : Matches words beginning with \"hostbase\". Example: \"hostname\", \"hosting\" Suffix Match : Matches words ending with \"hostbase\". Example: \"database\", \"homebase\" Regex Match : Matches any word containing \"hostbase\". Example: \\b\\w*pathbase\\w*\\b After adding the ACL type Host Based and conditions, you can see the list below. 3. Query Parameters Match ​ Query parameters are used to pass data from a client to a server through the URL. Matching options include exact match, prefix match, suffix match, and regex match. Query Parameter Matching Types ​ Exact Match : Matches specific values exactly. Example: https://example.com/users?id=123 Prefix Match : Matches values that start with a specific string. Example: https://example.com/search?query=phone Suffix Match : Matches values that end with a specific string. Example: https://example.com/files?type=pdf Regex Match : Matches values based on complex patterns. Example: https://example.com/articles?search=python\\+\\+programming Exact Match (Case-Sensitive) : Matches specific values exactly with case sensitivity. Example: https://example.com/users?id=USER123 Prefix Match (Case-Sensitive) : Matches case-sensitive values starting with a specific string. Example: https://example.com/search?query=phone Suffix Match (Case-Sensitive) : Matches case-sensitive values ending with a specific string. Example: https://example.com/files?type=PDF Regex Match (Case-Sensitive) : Matches case-sensitive patterns using regular expressions. Example: https://example.com/articles?search=Python\\+\\+Programming 4. HTTP Request Method ​ HTTP request method matching is used to direct incoming requests to specific servers or services based on the HTTP method used in the request. Match GET Requests : Routes all GET requests to a specific server for static content. Match POST Requests : Routes all POST requests to a server for handling form submissions. Match PUT Requests : Routes all PUT requests to a server for file uploads. 5. Source IP ​ Source IP matching is a feature commonly used in load balancers to direct incoming requests to specific servers or services based on the source IP address of the request. Here's an example of how source IP matching can be used in a load balancer. Match requests from a specific IP address: This type of source IP matching is used to direct all incoming requests from a specific IP address to a specific server or service. For example, if you have a client that is accessing your application from a dedicated IP address, you could use a load balancer to match all incoming requests from that IP address and direct them to a specific server. Match requests from a range of IP addresses: This type of source IP matching is used to direct all incoming requests from a range of IP addresses to a specific server or service. For example, if you have a set of servers that are optimized for handling requests from a specific geographic region, you could use a load balancer to match all incoming requests from that region and direct them to those servers. Here's an example configuration in the load balancer: Monitoring ​ Monitoring is an important part of maintaining the reliability, availability, and performance of your load balancer. You can check the monitoring information for your load balancer on the Monitoring tab. This information is collected from your load balancer and processes raw data into readable graphs. Each graph is based on one of the different metrics. Learn more. Alerts ​ Server health alerts are automatically created for your newly created load balancer using recommended parameters for alert policy. You can also set up new alerts by defining trigger parameters as per your use case. The alerting system works by sending automatic response notifications to your defined email list. Learn more. Stats ​ Prometheus Stats ​ Action Logs ​ Action logs contain detailed information about requests sent to your load balancer such as the date/time the request was received, client’s IP address, request protocol, request paths, and server responses. These access logs are useful to understand incoming network traffic patterns and troubleshoot issues if any arise. Billing Logs ​ Actions ​ Types of actions you can perform with Load Balancer. Stopping your Load Balancer ​ To stop your Load Balancer, click on the Stop button. A confirmation popup will open; click on the Power Off button to confirm. Upgrade your Load Balancer ​ The LB upgrade feature enables customers to easily upgrade their LB plan based on their specific usage requirements. To upgrade your Load Balancer, click on the Upgrade button under the Action button. After that, click on the Apply button with the selected plan. The upgrading process will then start. Note: Please ensure that your load balancer is stopped when performing the upgrade action. Delete ​ To delete your Load Balancer, click on the Delete button. Network Load Balancer Initiate Load Balancer Creation ​ Log in to the MyAccount portal using your credentials. On the MyAccount dashboard, click on Load Balancers . Select your Load Balancer Plan ​ Load balancer plans are listed by memory, vCPU, storage, and price. Choose a plan to create your load balancer. After selecting a plan, choose the load balancer type: Application Load Balancer (ALB): Works at Layer 7, making decisions based on content and application logic. Network Load Balancer (NLB): Works at Layer 4, routing TCP traffic based on IP and port. To create a Network Load Balancer (NLB) , click on the Network Load Balancer (NLB) option. Enter configuration details (name, mode, port, SSL certificates, etc.) for front-end and back-end connections. ALB Deployment Help Details ​ Name: A default name is provided based on the selected plan, but you can modify it. Type: Choose between Internal or External load balancer. Target Mapping ​ Backend Name ​ Routing Policy ​ Choose a Balancing Policy: Round Robin: Distributes requests evenly among backend servers. Source IP Hash: Routes based on the user’s IP address to ensure consistency. Least Connection: Routes traffic to the server with the fewest active connections. How Least Connection Works: The load balancer tracks active connections for each server. Incoming requests are routed to the server with the least active connections. Port ​ For NLB , use a port between 1024-65535 , except 8080, 10050, and 9101. ALB does not require a target port. Backends ​ Adding a backend is mandatory. Click Add Backend to add a backend. View the backend list via the dropdown. Peak Performance Features ​ Create New VPC Enable this option to use a VPC IP as the default VPC IP for your load balancer to connect internally. After creating a VPC, you can see it in the dropdown list. Add New Reserve IP Enable this option to use a reserved IP as the default Public IP for your load balancer. You can dynamically update the backend resources of your applications and websites by re-assigning the reserved IP address without downtime. After creating an IP, you can see it in the dropdown list. BitNinja BitNinja is a user-friendly server security tool that combines various powerful defense mechanisms. Every BitNinja-protected load balancer learns from every attack, automatically applying this information across all BitNinja-enabled servers/load balancers, strengthening protection with each attack. Learn more Enable BitNinja Enable this option to use the BitNinja security tool for your load balancer. BitNinja has modules for different types of cyberattacks. It’s easy to install, requires minimal maintenance, and provides immediate protection against a wide range of cyberattacks. Timeouts You can set different timeout values, such as connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, according to your requirements. Summary ​ In the summary section, you can verify your Plan, Type, Details, Network Mapping, and Peak Performance Features. Deploy Load Balancer ​ After filling in all the details successfully, click on the Submit button. It will take a few minutes to set up the scale group, and you will be taken to the ‘Load Balancers’ page. Load Balancer Info ​ You can check all the basic, security, backend configurations, and network details of your load balancer on the Load Balancer info tab. Backend Mapping ​ Once you've created your load balancer, you can manage it from the My Account Portal. Click on the installed LoadBalancer instance to see various management options. To add a backend, click on the Add Backend button. After adding the backend, you can see the list below. You will be redirected to the Edit Load Balancer page, where you can add or change backend and frontend configurations for your load balancer. You will be redirected to the Delete Load Balancer page, where you can delete backend and frontend configurations for your load balancer. Monitoring ​ Monitoring is an essential part of maintaining the reliability, availability, and performance of your load balancer. You can view monitoring information for your load balancer on the Monitoring tab. This data is collected from your load balancer and processed into readable graphs, each based on a different metric. Learn more . Alerts ​ Server health alerts are automatically created for your newly created load balancer using recommended alert policy parameters. You can also set up custom alerts by defining trigger parameters to suit your use case. The alerting system sends automatic response notifications to your defined email list. Learn more . Stats ​ Prometheus Stats ​ Action Logs ​ Action logs contain detailed information about requests sent to your load balancer, such as the date/time the request was received, client’s IP address, request protocol, request paths, and server responses. These access logs are useful for understanding incoming network traffic patterns and troubleshooting any issues. Billing Logs ​ Actions ​ Types of actions you can perform with your Load Balancer. Stopping Your Load Balancer ​ To stop your Load Balancer, click the Stop button. A confirmation popup will appear; click on Power Off to confirm. Upgrade Your Load Balancer ​ The Load Balancer (LB) upgrade feature allows customers to easily upgrade their LB plan based on specific usage needs. To upgrade, click the Upgrade button under Actions. Then, click on the Apply button with the selected plan. The upgrade process will start. Note: Please ensure that your load balancer is stopped when performing the upgrade action. Delete ​ To delete your Load Balancer, click on the Delete button. Select your Load Balancer Plan Type Details Target Mapping Node Auto Scale Group Peak Performance Features BitNinja Timeouts Summary Deploy Load Balancer Application Load Balancer Info Backend Mapping ACL 1. Path Based Condition Path Matching Types 2. Host Based Condition Host Matching Types 3. Query Parameters Match Query Parameter Matching Types 4. HTTP Request Method 5. Source IP Monitoring Alerts Stats Prometheus Stats Action Logs Billing Logs Actions Stopping your Load Balancer Upgrade your Load Balancer Delete Initiate Load Balancer Creation Select your Load Balancer Plan Details Target Mapping Peak Performance Features Summary Deploy Load Balancer Load Balancer Info Backend Mapping Monitoring Alerts Stats Prometheus Stats Action Logs Billing Logs Actions Stopping Your Load Balancer Upgrade Your Load Balancer Delete",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Computing Service/Product Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/terraform-e2e/",
    "site_type": "Documentation",
    "content": "Terraform | E2E Cloud Skip to main content Terraform E2E Networks Terraform refers to the integration of E2E Networks, a cloud computing service provider, with Terraform, an open-source infrastructure as code (IaC) tool developed by HashiCorp. Terraform allows users to define, provision, and manage cloud infrastructure using declarative configuration files. By using Terraform with E2E Networks, organizations can automate the deployment and management of cloud resources such as virtual machines, storage, and networking components on the E2E cloud platform. This approach enhances infrastructure scalability, version control, and efficient resource management, making it ideal for DevOps practices and continuous integration/continuous deployment (CI/CD) pipelines. Getting Started Install Terraform and configure a provider file. e2e_node (Resource) Manage terraform on your E2E clusters. GPU Available GPUs. Linux Virtual Node Available Images/OS. Linux Smart Dedicated Compute Smart Dedicated Compute 3rd Generation Windows Virtual Node Cost-effective way to deploy instances vGPU Cost-effective way to deploy instances e2e_image (Resource) Provides an e2e image resource",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/terraform-e2e/terraform_intro/",
    "site_type": "Documentation",
    "content": "Getting Started | E2E Cloud Skip to main content On this page Getting Started How to Configure Terraform for E2E ​ To use Terraform with E2E, you need to install Terraform and configure a provider file. Install Terraform ​ You can install the latest version of Terraform on most operating systems from the command line using various package managers. Click your operating system’s tab below to view instructions on how to install Terraform. Linux ​ To install Terraform on Ubuntu, add the HashiCorp GPG key to your system: curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add - Next, add the official HashiCorp Terraform Linux repository to apt: sudo apt-add-repository \"deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main\" Then update apt and install Terraform: sudo apt-get update && sudo apt-get install terraform Once installed, verify the installation: terraform -v MacOS :- ​ To install Terraform on MacOS using Homebrew, run the following command in a terminal: brew install terraform Once installed, verify Terraform’s installation: terraform -v Windows :- ​ To install Terraform on Windows using Chocolatey, run the following command from the command prompt: choco install terraform Once installed, verify Terraform’s installation: terraform -v CentOS :- ​ To install Terraform on CentOS, install the yum-config-manager to manage your repositories: sudo yum install -y yum-utils Use yum-config-manager to add the official HashiCorp Linux repository: sudo yum-config-manager --add-repo https://rpm.releases.hashicorp.com/RHEL/hashicorp.repo Then install Terraform: sudo yum -y install terraform Once installed, verify Terraform’s installation: terraform -v To use the e2e provider with Terraform, you have to configure the plugin using a provider file. This file tells Terraform which provider you’re using (e2e) and where to find the necessary credentials (your e2e API token, and your auth To start, create and move into a directory from which you will configure and deploy your infrastructure. This is also where you create the provider file. To install this provider, copy and paste this code into your Terraform configuration. Then, run terraform init. Checkout the terraform registry for e2e provider here <https://registry.terraform.io/providers/e2eterraformprovider/e2e/latest> _ and choose the latest version. terraform { required_providers { e2e = { source = \"e2eterraformprovider/e2e\" version = \"2.0.4\" # checkout the latest version from terraform registry } } } provider \"e2e\" { # Configuration options } Provider Configuration Schema ​ Argument Reference ​ api_key (String) (Required). auth_token (String) (Required). api_endpoint(String) (Optional) default Api_endpoint :- https://api.e2enetworks.com/myaccount/api/v1/ . Example usage ​ terraform { required_providers { e2e = { source = \"e2eterraformprovider/e2e\" version = \"2.0.4\" # use latest version } } } provider \"e2e\" { api_key = \"your api_key\" auth_token = \"your auth_token\" } Execute Terraform ​ Once you have configured your Terraform files, you can deploy all of the resources you have configured from the command line. Terraform requires three steps for deployment: initializing the directory, reviewing an execution plan, and applying (executing) the Terraform plan. Initialization prepares the working directory for use by accounting for any changes in Terraform’s backend configuration. The planning step provides you a detailed manifest of the resources for you to review before execution. Lastly, the terraform apply command executes the deployment of the resources into your account. To initialize the working directory: terraform init If Terraform was successful in initializing the directory, you receive the message Terraform has been successfully initialized!. Next, you need to create and view your Terraform plan. To create your Terraform plan: terraform plan Terraform returns a manifest of resources it will deploy when you apply the plan.After reviewing the plan, you can apply it and deploy the resources to your account. To execute the plan: Before applying terraform will prompt you to confirm by typing yes. You must checkout the changes in the configuration before applying. terraform apply You can checkout the current terraform state: terraform show You can also delete your resource created by terraform terraform destroy But it will destroy all the resources. To destroy a target resource use the command below terraform destroy —- target e2e_node.demo_node_name Here resource of type e2e_node and name demo_node_name is deleted. Or you can simply clear the resource from configuration file and then command terraform apply. The resource will be deleted. Create Terraform Configuration Files ​ Once you have configured Terraform to access your e2e account, you can begin developing Terraform files that describe and declare the e2e resources that you want to deploy into your account. Terraform configuration files are text files stored with .tf extensions. They are human-readable and they support comments. During deployment, Terraform loads all files with a .tf extension and creates a manifest of resources to deploy called a “plan”. You can divide resource configurations between as many or as few .tf files as you want. Below is the sample terraform file for launching a node. You can copy paste the file into your working directory as a new .tf file. The fields inside the resource e2e_node is discussed in the next section. example.tf terraform { required_providers { e2e = { source = \"e2eterraformprovider/e2e\" version = \"2.0.4\" } } } provider \"e2e\" { api_key = \"your e2e api key\" auth_token = \"your e2e auth bearer token\" } resource \"e2e_node\" \"demo_node_1\" { name=\"C2-4GB-416B\" region=\"Delhi\" plan=\"C2.12GB\" image=\"CentOS-7\" } Importing already existing infrastructure ​ Write Config for Resource To Be Import. Terraform import does not generate the configuration files by itself. Thus, you need to create the corresponding configuration for the node resource manually. you can skip a few arguments anyway. In a moment we will take a look at how to adjust our configuration to reflect the exact resource. For now, append the main.tf file with node config. remember that you have to include the required fields (refer e2e_node docs) resource \"e2e_node\" \"mynode\" { name = \"unknown\" plan = \"unknown\" image = \"unknown\" region = \"unknown\" } Think of it as if the cloud resource (node) and its corresponding configuration were available in our files. All that’s left to do is to map the two into our state file. We do that by running the import command as follows. terraform import e2e_node.mynode <Node ID> Later after import is successful. Run terraform plan. The plan indicates that it would attempt to replace the node resource. But this goes completely against our purpose. We could do it anyway by simply not caring about the existing resources, and creating new resources using configuration. Observe the plan output, and find all those attributes which cause the replacement (4 in our case). The plan output will highlight the same. use terraform show command and copy the values of those fields to the configuration file. Closing this gap should avoid the replacement of the node resource. How to Configure Terraform for E2E Install Terraform MacOS :- Windows :- CentOS :- Provider Configuration Schema Argument Reference Example usage Execute Terraform Create Terraform Configuration Files Importing already existing infrastructure",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/terraform-e2e/GPU/",
    "site_type": "Documentation",
    "content": "GPU | E2E Cloud Skip to main content On this page GPU NVIDIA A100 ​ GPU Card GPU Memory OS/Image Plan vCPU RAM SSD Storage Price NVIDIA - A100 40 GB CentOS - 7 GDC.A100-16.115GB 16 115 GB 1500 GB 124100 /mo 170 /hr NVIDIA - A100-80 80 GB CentOS - 7 GDC.A10080-16.115GB 16 115 GB 1500 GB 164980 /mo 226 /hr NVIDIA - 2XA100 80 GB CentOS - 7 GDC.2xA100-32.230GB 32 230 GB 3000 GB 248200 /mo 340 /hr NVIDIA - 2XA100-80 160 GB CentOS - 7 GDC.2xA10080-32.230GB 32 230 GB 3000 GB 329960 /mo 452 /hr NVIDIA - 4XA100 160 GB CentOS - 7 GDC.4xA100-64.460GB 64 460 GB 6000 GB 496400 /mo 680 /hr NVIDIA - 4XA100-80 320 GB CentOS - 7 GDC.4xA10080-64.460GB 64 460 GB 6000 GB 659920 /mo 904 /hr NVIDIA - A100 40 GB CentOS - 8 GDC.A100-16.115GB 16 115 GB 1500 GB 124100 /mo 170 /hr NVIDIA - A100-80 80 GB CentOS - 8 GDC.A10080-16.115GB 16 115 GB 1500 GB 164980 /mo 226 /hr NVIDIA - 2XA100 80 GB CentOS - 8 GDC.2xA100-32.230GB 32 230 GB 3000 GB 248200 /mo 340 /hr NVIDIA - 2XA100-80 160 GB CentOS - 8 GDC.2xA10080-32.230GB 32 230 GB 3000 GB 329960 /mo 452 /hr NVIDIA - 4XA100 160 GB CentOS - 8 GDC.4xA100-64.460GB 64 460 GB 6000 GB 496400 /mo 680 /hr NVIDIA - 4XA100-80 320 GB CentOS - 8 GDC.4xA10080-64.460GB 64 460 GB 6000 GB 659920 /mo 904 /hr NVIDIA - A100-80 80 GB RockyLinux - 8 GDC3.A10080-16.115GB 16 115 GB 250 GB 164980 /mo 226 /hr NVIDIA - 2x A100-80 160 GB RockyLinux - 8 GDC3.2xA10080-32.230GB 32 230 GB 250 GB 329960 /mo 452 /hr NVIDIA - 4x A100-80 320 GB RockyLinux - 8 GDC3.4xA10080-64.460GB 64 460 GB 250 GB 659920 /mo 904 /hr NVIDIA - A100 - CUDA-11 40 GB Ubuntu - 18.04 GDC.A100-16.115GB 16 115 GB 1500 GB 124100 /mo 170 /hr NVIDIA - A100 - CUDA-10 40 GB Ubuntu - 18.04 GDC.A100-16.115GB 16 115 GB 1500 GB 124100 /mo 170 /hr NVIDIA - A100-80 - CUDA-11 80 GB Ubuntu - 18.04 GDC.A10080-16.115GB 16 115 GB 1500 GB 164980 /mo 226 /hr NVIDIA - A100-80 - CUDA-10 80 GB Ubuntu - 18.04 GDC.A10080-16.115GB 16 115 GB 1500 GB 164980 /mo 226 /hr NVIDIA - 2XA100 - CUDA-10 80 GB Ubuntu - 18.04 GDC.2xA100-32.230GB 32 230 GB 3000 GB 248200 /mo 340 /hr NVIDIA - 2XA100 - CUDA-11 80 GB Ubuntu - 18.04 GDC.2xA100-32.230GB 32 230 GB 3000 GB 248200 /mo 340 /hr NVIDIA - 2XA100-80 - CUDA-11 160 GB Ubuntu - 18.04 GDC.2xA10080-32.230GB 32 230 GB 3000 GB 329960 /mo 452 /hr NVIDIA - 2XA100-80 - CUDA-10 160 GB Ubuntu - 18.04 GDC.2xA10080-32.230GB 32 230 GB 3000 GB 329960 /mo 452 /hr NVIDIA - 4XA100 - CUDA-10 160 GB Ubuntu - 18.04 GDC.4xA100-64.460GB 64 460 GB 6000 GB 496400 /mo 680 /hr NVIDIA - 4XA100 - CUDA-11 160 GB Ubuntu - 18.04 GDC.4xA100-64.460GB 64 460 GB 6000 GB 496400 /mo 680 /hr NVIDIA - 4XA100-80 - CUDA-11 320 GB Ubuntu - 18.04 GDC.4xA10080- NVIDIA RTX 8000 ​ GPU Card GPU Memory OS/Image Plan vCPU RAM SSD Storage Price NVIDIA - RTX8000 48 GB CentOS - 7 GDC.RTX-16.115GB 16 115 GB 900 GB 52560 /mo 72 /hr NVIDIA - 2xRTX8000 96 GB CentOS - 7 GDC.2xRTX-32.230GB 32 230 GB 1800 GB 105120 /mo 144 /hr NVIDIA - 4 x RTX8000 192 GB CentOS - 7 GDC.4xRTX-64.460GB 64 460 GB 3600 GB 210240 /mo 288 /hr NVIDIA - RTX8000 - CUDA-11 48 GB Ubuntu - 18.04 GDC.RTX-16.115GB 16 115 GB 900 GB 52560 /mo 72 /hr NVIDIA - RTX8000 - CUDA-10 48 GB Ubuntu - 18.04 GDC.RTX-16.115GB 16 115 GB 900 GB 52560 /mo 72 /hr NVIDIA - 2xRTX8000 - CUDA-11 96 GB Ubuntu - 18.04 GDC.2xRTX-32.230GB 32 230 GB 1800 GB 105120 /mo 144 /hr NVIDIA - 2xRTX8000 - CUDA-10 96 GB Ubuntu - 18.04 GDC.2xRTX-32.230GB 32 230 GB 1800 GB 105120 /mo 144 /hr NVIDIA - 4 x RTX8000 - CUDA-11 192 GB Ubuntu - 18.04 GDC.4xRTX-64.460GB 64 460 GB 3600 GB 210240 /mo 288 /hr NVIDIA - 4 x RTX8000 - CUDA-10 192 GB Ubuntu - 18.04 GDC.4xRTX-64.460GB 64 460 GB 3600 GB 210240 /mo 288 /hr NVIDIA - RTX8000 48 GB Ubuntu - 20.04 GDC.RTX-16.115GB 16 115 GB 900 GB 52560 /mo 72 /hr NVIDIA - 2xRTX8000 96 GB Ubuntu - 20.04 GDC.2xRTX-32.230GB 32 230 GB 1800 GB 105120 /mo 144 /hr NVIDIA - 4 x RTX8000 192 GB Ubuntu - 20.04 GDC.4xRTX-64.460GB 64 460 GB 3600 GB 210240 /mo 288 /hr NVIDIA - RTX8000 48 GB Ubuntu - 22.04 GDC.RTX-16.115GB 16 115 GB 900 GB 52560 /mo 72 /hr NVIDIA - 2xRTX8000 96 GB Ubuntu - 22.04 GDC.2xRTX-32.230GB 32 230 GB 1800 GB 105120 /mo 144 /hr NVIDIA - 4 x RTX8000 192 GB Ubuntu - 22.04 GDC.4xRTX-64.460GB 64 460 GB 3600 GB 210240 /mo 288 /hr NVIDIA - RTX8000 48 GB Windows - 2016 GDCW.RTX-16.115GB 16 115 GB 900 GB 57214.05 /mo 78.4 /hr NVIDIA - 2 x RTX8000 96 GB Windows - 2016 GDCW.2xRTX-32.230GB 32 230 GB 1800 GB 113104.45 /mo 154.9 /hr NVIDIA - 4 x RTX8000 192 GB Windows - 2016 GDCW.4xRTX-64.460GB 64 460 GB 3600 GB 225259 /mo 308.6 /hr NVIDIA - RTX8000 48 GB Windows - 2019 GDCW.RTX-16.115GB 16 115 GB 900 GB 57214.05 /mo 78.4 /hr NVIDIA - 2 x RTX8000 96 GB Windows - 2019 GDCW.2xRTX-32.230GB 32 230 GB 1800 GB 113104.45 /mo 154.9 /hr NVIDIA - 4 x RTX8000 192 GB Windows - 2019 GDCW.4xRTX-64.460GB 64 460 GB 3600 GB 225259 /mo 308.6 /hr NVIDIA T4 ​ GPU Card GPU Memory OS/Image Plan vCPU RAM SSD Storage Price NVIDIA - T4 16 GB CentOS - 7 GDC.T4-12.50GB 12 50 GB 900 GB 21900 /mo 30 /hr NVIDIA - 2xT4 32 GB CentOS - 7 GDC.2XT4-24.100GB 24 100 GB 1800 GB 43800 /mo 60 /hr NVIDIA - T4 - CUDA-11 16 GB Ubuntu - 18.04 GDC.T4-12.50GB 12 50 GB 900 GB 21900 /mo 30 /hr NVIDIA - T4 - CUDA-10 16 GB Ubuntu - 18.04 GDC.T4-12.50GB 12 50 GB 900 GB 21900 /mo 30 /hr NVIDIA - 2xT4 - CUDA-11 32 GB Ubuntu - 18.04 GDC.2XT4-24.100GB 24 100 GB 1800 GB 43800 /mo 60 /hr NVIDIA - 2xT4 - CUDA-10 32 GB Ubuntu - 18.04 GDC.2XT4-24.100GB 24 100 GB 1800 GB 43800 /mo 60 /hr NVIDIA - T4 16 GB Ubuntu - 20.04 GDC.T4-12.50GB 12 50 GB 900 GB 21900 /mo 30 /hr NVIDIA - 2xT4 32 GB Ubuntu - 20.04 GDC.2XT4-24.100GB 24 100 GB 1800 GB 43800 /mo 60 /hr NVIDIA - T4 16 GB Ubuntu - 22.04 GDC.T4-12.50GB 12 50 GB 900 GB 21900 /mo 30 /hr NVIDIA - T4 16 GB Windows - 2016 GDCW.T4-12.50GB 12 50 GB 900 GB 26280 /mo 36 /hr NVIDIA - 2 x T4 32 GB Windows - 2016 GDCW.2XT4-24.100GB 24 100 GB 1800 GB 48910 /mo 67 /hr NVIDIA - T4 16 GB Windows - 2019 GDCW.T4-12.50GB 12 50 GB 900 GB 26280 /mo 36 /hr NVIDIA - 2 x T4 32 GB Windows - 2019 GDCW.2XT4-24.100GB 24 100 GB 1800 GB 48910 /mo 67 /hr NVIDIA V 100 ​ GPU Card GPU Memory OS/Image Plan vCPU RAM SSD Storage Price NVIDIA - V100 32 GB CentOS - 7 GDC.V100-8.120GB 8 120 GB 900 GB 73000 /mo 100 /hr NVIDIA - 2xV100 64 GB CentOS - 7 GDC.2xV100-16.240GB 16 240 GB 1800 GB 116800 /mo 160 /hr NVIDIA - 4xV100 128 GB CentOS - 7 GDC.4xV100-32.480GB 32 480 GB 3600 GB 292000 /mo 400 /hr NVIDIA - V100 32 GB CentOS - 8 GDC.V100-8.120GB 8 120 GB 900 GB 73000 /mo 100 /hr NVIDIA - 2xV100 64 GB CentOS - 8 GDC.2xV100-16.240GB 16 240 GB 1800 GB 116800 /mo 160 /hr NVIDIA - 4xV100 128 GB CentOS - 8 GDC.4xV100-32.480GB 32 480 GB 3600 GB 292000 /mo 400 /hr NVIDIA - V100 32 GB Ubuntu - 18.04 GDC.V100-8.120GB 8 120 GB 900 GB 73000 /mo 100 /hr NVIDIA - 2xV100 64 GB Ubuntu - 18.04 GDC.2xV100-16.240GB 16 240 GB 1800 GB 116800 /mo 160 /hr NVIDIA - 4xV100 128 GB Ubuntu - 18.04 GDC.4xV100-32.480GB 32 480 GB 3600 GB 292000 /mo 400 /hr NVIDIA - V100 32 GB Ubuntu - 20.04 GDC.V100-8.120GB 8 120 GB 900 GB 73000 /mo 100 /hr NVIDIA - 2xV100 64 GB Ubuntu - 20.04 GDC.2xV100-16.240GB 16 240 GB 1800 GB 116800 /mo 160 /hr NVIDIA - 4xV100 128 GB Ubuntu - 20.04 GDC.4xV100-32.480GB 32 480 GB 3600 GB 292000 /mo 400 /hr NVIDIA - V100 32 GB Ubuntu - 22.04 GDC.V100-8.120GB 8 120 GB 900 GB 73000 /mo 100 /hr NVIDIA - 2xV100 64 GB Ubuntu - 22.04 GDC.2xV100-16.240GB 16 240 GB 1800 GB 116800 /mo 160 /hr NVIDIA - 4xV100 128 GB Ubuntu - 22.04 GDC.4xV100-32.480GB 32 480 GB 3600 GB 292000 /mo 400 /hr NVIDIA - V100 32 GB Windows - 2016 GDCW.V100-8.120GB 8 120 GB 900 GB 76306.9 /mo 105 /hr NVIDIA - 2xV100 64 GB Windows - 2016 GDCW.2xV100-16.240GB 16 240 GB 1800 GB 121785.9 /mo 167 /hr NVIDIA - 4xV100 128 GB Windows - 2016 GDCW.4xV100-32.480GB 32 480 GB 3600 GB 300395 /mo 412 /hr NVIDIA - V100 32 GB Windows - 2019 GDCW.V100-8.120GB 8 120 GB 900 GB 76306.9 /mo 105 /hr NVIDIA - 2xV100 64 GB Windows - 2019 GDCW.2xV100-16.240GB 16 240 GB 1800 GB 121785.9 /mo 167 /hr NVIDIA - 4xV100 128 GB Windows - 2019 GDCW.4xV100-32.480GB 32 480 GB 3600 GB 300395 /mo 412 /hr NVIDIA A30 ​ GPU Card GPU Memory OS Plan vCPU RAM SSD Storage Price NVIDIA - A30 24 GB CentOS - 7 GDC.A30-16.90GB 16 90 GB 640 GB 65700 /mo 90 /hr NVIDIA - 2 x A30 48 GB CentOS - 7 GDC.2xA30-32.180GB 32 180 GB 1280 GB 131400 /mo 180 /hr NVIDIA - 2 x A30 48 GB CentOS - 7 GDC.2xA30-64.180GB 64 180 GB 1280 GB 182500 /mo 250 /hr NVIDIA - 4 x A30 96 GB CentOS - 7 GDC.4xA30-64.360GB 64 360 GB 2560 GB 262800 /mo 360 /hr NVIDIA - A30 24 GB CentOS - 8 GDC.A30-16.90GB 16 90 GB 640 GB 65700 /mo 90 /hr NVIDIA - A30 24 GB CentOS - 8 GDC.A30-32.90GB 32 90 GB 640 GB 91250 /mo 125 /hr NVIDIA - 2 x A30 48 GB CentOS - 8 GDC.2xA30-32.180GB 32 180 GB 1280 GB 131400 /mo 180 /hr NVIDIA - 2 x A30 48 GB CentOS - 8 GDC.2xA30-64.180GB 64 180 GB 1280 GB 182500 /mo 250 /hr NVIDIA - 4 x A30 96 GB CentOS - 8 GDC.4xA30-64.360GB 64 360 GB 2560 GB 262800 /mo 360 /hr NVIDIA - A30 24 GB Ubuntu - 18.04 GDC.A30-16.90GB 16 90 GB 640 GB 65700 /mo 90 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 18.04 GDC.2xA30-32.180GB 32 180 GB 1280 GB 131400 /mo 180 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 18.04 GDC.2xA30-64.180GB 64 180 GB 1280 GB 182500 /mo 250 /hr NVIDIA - 4 x A30 96 GB Ubuntu - 18.04 GDC.4xA30-64.360GB 64 360 GB 2560 GB 262800 /mo 360 /hr NVIDIA - A30 24 GB Ubuntu - 20.04 GDC.A30-16.90GB 16 90 GB 640 GB 65700 /mo 90 /hr NVIDIA - A30 24 GB Ubuntu - 20.04 GDC.A30-32.90GB 32 90 GB 640 GB 91250 /mo 125 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 20.04 GDC.2xA30-32.180GB 32 180 GB 1280 GB 131400 /mo 180 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 20.04 GDC.2xA30-64.180GB 64 180 GB 1280 GB 182500 /mo 250 /hr NVIDIA - 4 x A30 96 GB Ubuntu - 20.04 GDC.4xA30-64.360GB 64 360 GB 2560 GB 262800 /mo 360 /hr NVIDIA - A30 24 GB Ubuntu - 22.04 GDC.A30-16.90GB 16 90 GB 640 GB 65700 /mo 90 /hr NVIDIA - A30 24 GB Ubuntu - 22.04 GDC.A30-32.90GB 32 90 GB 640 GB 91250 /mo 125 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 22.04 GDC.2xA30-32.180GB 32 180 GB 1280 GB 131400 /mo 180 /hr NVIDIA - 2 x A30 48 GB Ubuntu - 22.04 GDC.2xA30-64.180GB 64 180 GB 1280 GB 182500 /mo 250 /hr NVIDIA - 4 x A30 96 GB Ubuntu - 22.04 GDC.4xA30-64.360GB 64 360 GB 2560 GB 262800 /mo 360 /hr NVIDIA - A30 24 GB Windows - 2016 GDCW.A30-16.90GB 16 90 GB 640 GB 70727.8 /mo 96.9 /hr NVIDIA - A30 24 GB Windows - 2016 GDCW.A30-32.90GB 32 90 GB 640 GB 99608 /mo 136.4 /hr NVIDIA - 2 x A30 48 GB Windows - 2016 GDCW.2xA30-32.180GB 32 180 GB 1280 GB 139758.2 /mo 191.4 /hr NVIDIA - 2 x A30 48 GB Windows - 2016 GDCW.2xA30-64. NVIDIA A40 ​ GPU Card GPU Memory OS/Image Plan vCPU RAM SSD Storage Price NVIDIA - A40 48 GB CentOS - 7 GDC.A40-16.100GB 16 100 GB 750 GB 70080 /mo 96 /hr NVIDIA - 2xA40 96 GB CentOS - 7 GDC.2xA40-32.200GB 32 200 GB 1500 GB 140890 /mo 193 /hr NVIDIA - 4xA40 192 GB CentOS - 7 GDC.4xA40-64.400GB 64 400 GB 3000 GB 281780 /mo 386 /hr NVIDIA - A40 48 GB Ubuntu - 18.04 GDC.A40-16.100GB 16 100 GB 750 GB 70080 /mo 96 /hr NVIDIA - 2xA40 96 GB Ubuntu - 18.04 GDC.2xA40-32.200GB 32 200 GB 1500 GB 140890 /mo 193 /hr NVIDIA - 4xA40 192 GB Ubuntu - 18.04 GDC.4xA40-64.400GB 64 400 GB 3000 GB 281780 /mo 386 /hr NVIDIA - A40 48 GB Ubuntu - 20.04 GDC.A40-16.100GB 16 100 GB 750 GB 70080 /mo 96 /hr NVIDIA - 2xA40 96 GB Ubuntu - 20.04 GDC.2xA40-32.200GB 32 200 GB 1500 GB 140890 /mo 193 /hr NVIDIA - 4xA40 192 GB Ubuntu - 20.04 GDC.4xA40-64.400GB 64 400 GB 3000 GB 281780 /mo 386 /hr NVIDIA - A40 48 GB Ubuntu - 22.04 GDC.A40-16.100GB 16 100 GB 750 GB 70080 /mo 96 /hr NVIDIA - A40 48 GB Ubuntu - 22.04 GDC.A40-16.100GB 16 100 GB 750 GB 70080 /mo 96 /hr NVIDIA - 2xA40 96 GB Ubuntu - 22.04 GDC.2xA40-32.200GB 32 200 GB 1500 GB 140890 /mo 193 /hr NVIDIA - 2xA40 96 GB Ubuntu - 22.04 GDC.2xA40-32.200GB 32 200 GB 1500 GB 140890 /mo 193 /hr NVIDIA - 4xA40 192 GB Ubuntu - 22.04 GDC.4xA40-64.400GB 64 400 GB 3000 GB 281780 /mo 386 /hr NVIDIA - 4xA40 192 GB Ubuntu - 22.04 GDC.4xA40-64.400GB 64 400 GB 3000 GB 281780 /mo 386 /hr NVIDIA - A40 48 GB Windows - 2016 GDCW.A40-16.100GB 16 100 GB 750 GB 75482 /mo 103 /hr NVIDIA - 2xA40 96 GB Windows - 2016 GDCW.2xA40-32.200GB 32 200 GB 1500 GB 150004 /mo 205 /hr NVIDIA - 4xA40 192 GB Windows - 2016 GDCW.4xA40-64.400GB 64 400 GB 3000 GB 298318 /mo 409 /hr NVIDIA - A40 48 GB Windows - 2019 GDCW.A40-16.100GB 16 100 GB 750 GB 75482 /mo 103 /hr NVIDIA - 2xA40 96 GB Windows - 2019 GDCW.2xA40-32.200GB 32 200 GB 1500 GB 150004 /mo 205 /hr NVIDIA - 4xA40 192 GB Windows - 2019 GDCW.4xA40-64.400GB 64 400 GB 3000 GB 298318 /mo 409 /hr NVIDIA A100 NVIDIA RTX 8000 NVIDIA T4 NVIDIA V 100 NVIDIA A30 NVIDIA A40",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/customer_validation_faq/",
    "site_type": "FAQ",
    "content": "FAQs | E2E Cloud Skip to main content On this page FAQs Why is customer validation required for customers? ​ Due to the new CERT-In directives <https://www.cert-in.org.in/PDF/CERT-In_Directions_70B_28.04.2022.pdf> _, all Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers are required to maintain validated name, address and other relevant details for their subscribers. Therefore, in order to meet regulatory requirements, we are required to validate these details. Can we delegate someone in the team/organization to perform customer validation? ​ Yes, the Primary/Admin user can nominate any user in the CRN to perform customer validation. Are we able to delink/revoke the linked Aadhaar to the account in the future ? ​ Yes, we need a minimum of one user Aadhaar to be linked with the account/CRN. Primary user and users who linked Aadhaar can any time revoke their Aadhaar provided there is atleast one aadhaar linked user in the CRN. Are users allowed to change the Aadhaar number once linked ? ​ No, users are not allowed to change Aadhaar number once linked. The user can only delink the Aadhaar by revoking their nomination. Do all users in the CRN need to complete customer validation? ​ Minimum one user in the CRN needs to complete customer validation. All users do not need to complete customer validation. What happens if the user is no longer associated with the organization for which he validated the details? ​ The users will be able to revoke their nomination for the CRN, provided there is atleast one validated user in the CRN. You may need to coordinate with admin/primary users to add another user who completes validation first, and thereafter you will be able to revoke your nomination. Why is customer validation required for customers? Can we delegate someone in the team/organization to perform customer validation? Are we able to delink/revoke the linked Aadhaar to the account in the future ? Are users allowed to change the Aadhaar number once linked ? Do all users in the CRN need to complete customer validation? What happens if the user is no longer associated with the organization for which he validated the details?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "FAQ",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "FAQ",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "FAQ",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "FAQ",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/customer_validation_faq/#do-all-users-in-the-crn-need-to-complete-customer-validation",
    "site_type": "FAQ",
    "content": "FAQs | E2E Cloud Skip to main content On this page FAQs Why is customer validation required for customers? ​ Due to the new CERT-In directives <https://www.cert-in.org.in/PDF/CERT-In_Directions_70B_28.04.2022.pdf> _, all Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers are required to maintain validated name, address and other relevant details for their subscribers. Therefore, in order to meet regulatory requirements, we are required to validate these details. Can we delegate someone in the team/organization to perform customer validation? ​ Yes, the Primary/Admin user can nominate any user in the CRN to perform customer validation. Are we able to delink/revoke the linked Aadhaar to the account in the future ? ​ Yes, we need a minimum of one user Aadhaar to be linked with the account/CRN. Primary user and users who linked Aadhaar can any time revoke their Aadhaar provided there is atleast one aadhaar linked user in the CRN. Are users allowed to change the Aadhaar number once linked ? ​ No, users are not allowed to change Aadhaar number once linked. The user can only delink the Aadhaar by revoking their nomination. Do all users in the CRN need to complete customer validation? ​ Minimum one user in the CRN needs to complete customer validation. All users do not need to complete customer validation. What happens if the user is no longer associated with the organization for which he validated the details? ​ The users will be able to revoke their nomination for the CRN, provided there is atleast one validated user in the CRN. You may need to coordinate with admin/primary users to add another user who completes validation first, and thereafter you will be able to revoke your nomination. Why is customer validation required for customers? Can we delegate someone in the team/organization to perform customer validation? Are we able to delink/revoke the linked Aadhaar to the account in the future ? Are users allowed to change the Aadhaar number once linked ? Do all users in the CRN need to complete customer validation? What happens if the user is no longer associated with the organization for which he validated the details?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/Indian_customer_Signup/",
    "site_type": "Cloud Service Provider",
    "content": "Signup for Indian Customers | E2E Cloud Skip to main content On this page Signup for Indian Customers Navigate to URL https://myaccount.e2enetworks.com/accounts/signup Fill in all details and click on SignUp button After filling all details and clicking on SignUp , an OTP verification pop-up will appear. You will need to fill out an OTP sent to your mobile number and email. If you do not receive the OTP in Two attempts , you can click on Receive OTP via call to receive the OTP over a voice call. After OTP verification, the Billing information page will open. You need to fill in the required fields. The Indian customer may SignUp as either an individual or an organization. SignUp as Indian Organization ​ We validate whether customers have added the GSTIN and if it is correct or incorrect. After validation is completed, proceed with the SignUp process. After filling in all details and clicking on Next , the second step for payment validation will start. We offer Indian customers two payment gateway options, Stripe and Razorpay (including Razorpay card and Razorpay UPI), for payment validation. Users can choose the option that suits them best. If you select Razorpay card , you will see the following screen: After clicking on Card , enter the card details and click on Next . After this, the payment validation process will be complete and the Payment validated screen will open. You must click on Proceed to Next , and the page will automatically redirect to the Dashboard. If the Indian customer with GSTN wants to do Customer Validation voluntarily, they can click on Customer Validation as shown in the above screenshot. SignUp as Indian Individual ​ We validate whether customers have added an Individual PAN or Corporate PAN . Corporate PAN is not allowed for Individual accounts. If the user selects Individual and tries to enter a Corporate PAN , a message will be displayed: \"The PAN you entered is not of a Person. Kindly SignUp as an Organization.\" The 4th digit of the PAN should be P (This is fixed for individual PAN holders as per PAN allocation rules). If the user selects Individual and tries to enter an Organization GSTIN , a message will be displayed: \"Your GSTIN does not relate to an individual. You should signup as an organization.\" If users enter an incorrect PAN, a message will be displayed: \"The PAN you entered is not of a Person. Kindly sign up as an Organization.\" If users enter an incorrect GSTIN, a message will be displayed: \"Please enter valid GSTIN.\" If the user enters an Individual PAN , they can proceed to the next steps. After filling in all details and clicking on Next , the second step for payment validation will start. We offer Indian customers two payment gateway options, Stripe and Razorpay (including Razorpay card and Razorpay UPI), for payment validation. Users can choose the option that suits them best. If you select Razorpay card , you will see the following screen: After clicking on Card , enter the card details and click on Next . After this, the payment validation process will be complete and the Payment validated screen will open. You must click on Proceed to Next . After that, the Customer validation process will start. Skip Validation ​ If the user clicks on Skip , another pop-up will appear on the screen where the customer will need to fill in their Billing address . After filling in the Billing address, click on the Proceed button. The page will automatically redirect to the Dashboard page. The following message will be displayed on the Dashboard page. Note Your customer validation process is pending. Please complete validation before DD MM YYYY to use uninterrupted services. Click Here to complete your customer validation. Note After payment verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 6th day after SignUp and a second reminder we will send on the 13th day after registration and then 19th or final reminder will be on the 20th day But still, the customer will not complete his validation after 20 days his account will be suspended. Customer Account Validation Process After a few days of using the services, if a customer wants to validate their account, they will need to click on the ‘Click here’ link. After clicking on the link, a pop-up will appear showing a message about Aadhaar-based validation for the services for E2E Networks Ltd. Then, click on Agree and Proceed . Then, it will redirect to the Bureau site for KYC verification with Digilocker . Click on Proceed to Digilocker . A pop-up will appear in which the customer must fill in their Aadhaar details . After completing the Aadhaar validation, a pop-up will appear on the Dashboard to update the billing address. The customer has the option to choose the address previously mentioned, the address from Aadhaar, or they can add a new address that is different from both of the above-mentioned addresses. After keeping the same address or filling in a new address, the customer validation process will be completed, and they will be able to access all services. SignUp as Indian Organization SignUp as Indian Individual Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Service Provider",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/Indian_customer_Signup/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Service Provider",
    "content": "Signup for Indian Customers | E2E Cloud Skip to main content On this page Signup for Indian Customers Navigate to URL https://myaccount.e2enetworks.com/accounts/signup Fill in all details and click on SignUp button After filling all details and clicking on SignUp , an OTP verification pop-up will appear. You will need to fill out an OTP sent to your mobile number and email. If you do not receive the OTP in Two attempts , you can click on Receive OTP via call to receive the OTP over a voice call. After OTP verification, the Billing information page will open. You need to fill in the required fields. The Indian customer may SignUp as either an individual or an organization. SignUp as Indian Organization ​ We validate whether customers have added the GSTIN and if it is correct or incorrect. After validation is completed, proceed with the SignUp process. After filling in all details and clicking on Next , the second step for payment validation will start. We offer Indian customers two payment gateway options, Stripe and Razorpay (including Razorpay card and Razorpay UPI), for payment validation. Users can choose the option that suits them best. If you select Razorpay card , you will see the following screen: After clicking on Card , enter the card details and click on Next . After this, the payment validation process will be complete and the Payment validated screen will open. You must click on Proceed to Next , and the page will automatically redirect to the Dashboard. If the Indian customer with GSTN wants to do Customer Validation voluntarily, they can click on Customer Validation as shown in the above screenshot. SignUp as Indian Individual ​ We validate whether customers have added an Individual PAN or Corporate PAN . Corporate PAN is not allowed for Individual accounts. If the user selects Individual and tries to enter a Corporate PAN , a message will be displayed: \"The PAN you entered is not of a Person. Kindly SignUp as an Organization.\" The 4th digit of the PAN should be P (This is fixed for individual PAN holders as per PAN allocation rules). If the user selects Individual and tries to enter an Organization GSTIN , a message will be displayed: \"Your GSTIN does not relate to an individual. You should signup as an organization.\" If users enter an incorrect PAN, a message will be displayed: \"The PAN you entered is not of a Person. Kindly sign up as an Organization.\" If users enter an incorrect GSTIN, a message will be displayed: \"Please enter valid GSTIN.\" If the user enters an Individual PAN , they can proceed to the next steps. After filling in all details and clicking on Next , the second step for payment validation will start. We offer Indian customers two payment gateway options, Stripe and Razorpay (including Razorpay card and Razorpay UPI), for payment validation. Users can choose the option that suits them best. If you select Razorpay card , you will see the following screen: After clicking on Card , enter the card details and click on Next . After this, the payment validation process will be complete and the Payment validated screen will open. You must click on Proceed to Next . After that, the Customer validation process will start. Skip Validation ​ If the user clicks on Skip , another pop-up will appear on the screen where the customer will need to fill in their Billing address . After filling in the Billing address, click on the Proceed button. The page will automatically redirect to the Dashboard page. The following message will be displayed on the Dashboard page. Note Your customer validation process is pending. Please complete validation before DD MM YYYY to use uninterrupted services. Click Here to complete your customer validation. Note After payment verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 6th day after SignUp and a second reminder we will send on the 13th day after registration and then 19th or final reminder will be on the 20th day But still, the customer will not complete his validation after 20 days his account will be suspended. Customer Account Validation Process After a few days of using the services, if a customer wants to validate their account, they will need to click on the ‘Click here’ link. After clicking on the link, a pop-up will appear showing a message about Aadhaar-based validation for the services for E2E Networks Ltd. Then, click on Agree and Proceed . Then, it will redirect to the Bureau site for KYC verification with Digilocker . Click on Proceed to Digilocker . A pop-up will appear in which the customer must fill in their Aadhaar details . After completing the Aadhaar validation, a pop-up will appear on the Dashboard to update the billing address. The customer has the option to choose the address previously mentioned, the address from Aadhaar, or they can add a new address that is different from both of the above-mentioned addresses. After keeping the same address or filling in a new address, the customer validation process will be completed, and they will be able to access all services. SignUp as Indian Organization SignUp as Indian Individual Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Service Provider",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Service Provider",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Cloud Service Provider",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/billing/",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "Billing | E2E Cloud Skip to main content On this page Billing Nodes ​ Nodes are billed according to the cost of the machine it is launched on. There are a wide variety of CPU & GPU Machine Plans available on the TIR platform to launch nodes, and each of these plans has a price associated with it on which the customer is billed. The billing for these machines is done on an hourly or committed basis. Note To launch any node on a paid machine, one must have enough credits to run that node for about 24 hours. We also provide a certain number of free machine plans to launch nodes. Kindly refer to the Free-Tier Nodes section for more details. As soon as the node is launched or started, the billing starts. Billing of a particular node stops when the node is stopped or terminated. Nodes are not billed when in the stopped state. Free-Tier Nodes ​ Free-Tier Nodes are the nodes running on the free machine plans available on the platform. Each Primary Account gets a fixed number of free hours every month. The free hours available in a month are different for CPU & GPU Machines. Currently, every account gets 2 hours of monthly free usage for GPU Machines. For CPU Machines, there is no time limit. As long as free usage hours are available in the account, any customer (Primary or Secondary) can launch these Free-Tier Nodes. Node Limit ​ At any point in time, only 1 Free-Tier node each for CPU & GPU-type machines is allowed per account, i.e., across projects & teams of primary & secondary customers. If your monthly free hours are consumed, or the node-limit condition is not met, free-tier nodes cannot be launched. Nevertheless, you will always be able to launch nodes on paid machines, without any restrictions. When the monthly free usage limit has been reached, free-tier nodes are either auto-shutdown or converted to paid instances depending on the termination policy chosen by the user at the time of launching the node. If the \"Convert to Paid Version\" option is chosen, billing of nodes will start as soon as the free hours have been consumed. Node Disks (PVC) ​ Every node comes with a default 30 GB of disk space. This disk space can be upgraded to a maximum of 5000 GB based on the user’s choice. Users are not charged anything for the default 30 GB of disk space. However, every additional GB of space beyond the default 30 GB will be charged on a per GB per month basis. Datasets ​ Creation of any dataset leads to the creation of a bucket in the customer’s Object Store on TIR. Datasets are not charged explicitly, but all the corresponding buckets in TIR will be charged as per the pricing of Object Storage. Playground ​ The cost of LAMA-2 and Code Llama models is based on the number of tokens you input and the number of tokens in the output. For Stable Diffusion , the cost is based on the number of inference steps. Nodes Free-Tier Nodes Node Limit Node Disks (PVC) Datasets Playground",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/billing/#datasets",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "Billing | E2E Cloud Skip to main content On this page Billing Nodes ​ Nodes are billed according to the cost of the machine it is launched on. There are a wide variety of CPU & GPU Machine Plans available on the TIR platform to launch nodes, and each of these plans has a price associated with it on which the customer is billed. The billing for these machines is done on an hourly or committed basis. Note To launch any node on a paid machine, one must have enough credits to run that node for about 24 hours. We also provide a certain number of free machine plans to launch nodes. Kindly refer to the Free-Tier Nodes section for more details. As soon as the node is launched or started, the billing starts. Billing of a particular node stops when the node is stopped or terminated. Nodes are not billed when in the stopped state. Free-Tier Nodes ​ Free-Tier Nodes are the nodes running on the free machine plans available on the platform. Each Primary Account gets a fixed number of free hours every month. The free hours available in a month are different for CPU & GPU Machines. Currently, every account gets 2 hours of monthly free usage for GPU Machines. For CPU Machines, there is no time limit. As long as free usage hours are available in the account, any customer (Primary or Secondary) can launch these Free-Tier Nodes. Node Limit ​ At any point in time, only 1 Free-Tier node each for CPU & GPU-type machines is allowed per account, i.e., across projects & teams of primary & secondary customers. If your monthly free hours are consumed, or the node-limit condition is not met, free-tier nodes cannot be launched. Nevertheless, you will always be able to launch nodes on paid machines, without any restrictions. When the monthly free usage limit has been reached, free-tier nodes are either auto-shutdown or converted to paid instances depending on the termination policy chosen by the user at the time of launching the node. If the \"Convert to Paid Version\" option is chosen, billing of nodes will start as soon as the free hours have been consumed. Node Disks (PVC) ​ Every node comes with a default 30 GB of disk space. This disk space can be upgraded to a maximum of 5000 GB based on the user’s choice. Users are not charged anything for the default 30 GB of disk space. However, every additional GB of space beyond the default 30 GB will be charged on a per GB per month basis. Datasets ​ Creation of any dataset leads to the creation of a bucket in the customer’s Object Store on TIR. Datasets are not charged explicitly, but all the corresponding buckets in TIR will be charged as per the pricing of Object Storage. Playground ​ The cost of LAMA-2 and Code Llama models is based on the number of tokens you input and the number of tokens in the output. For Stable Diffusion , the cost is based on the number of inference steps. Nodes Free-Tier Nodes Node Limit Node Disks (PVC) Datasets Playground",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Reserve_IP/",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "Reserve IP | E2E Cloud Skip to main content On this page Reserve IP Reserved IP allows users to reserve a static IP address that remains exclusively assigned to their account. This reserved IP can be attached to any instance or service within their infrastructure, ensuring consistent and reliable network identification. It is particularly useful for applications requiring a fixed endpoint for external access, DNS configuration, or failover scenarios. The Reserved IP remains allocated to the user until it is explicitly released. How to Create a Reserve IP? ​ To initiate the Reserve IP process, first navigate to the sidebar section and select Reserve IP . On the Reserve IP page, locate and click on the RESERVE NEW IP button or the Click Here button to proceed with creating a Manage Reserved IP. Now select the checkbox and then click on Proceed. The List of Reserved IPs provides a comprehensive overview of all Reserved IPs associated with your account. How to Attach the Reserve IP? ​ Select the Node which you want to attach. How to Create a Reserve IP? How to Attach the Reserve IP?",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Pipeline/",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "Pipeline | E2E Cloud Skip to main content On this page Pipeline Introduction ​ In the context of Artificial Intelligence (AI), a pipeline refers to a series of data processing steps or operations that are performed in sequence to achieve a specific AI task or goal. An AI pipeline typically involves several stages, each with a specific function, and it is designed to process and transform input data into meaningful output. Each stage in the pipeline plays a crucial role in the overall AI process, and the effectiveness of the pipeline depends on the quality of data, the choice of algorithms, and the expertise in designing and optimizing each step. AI pipelines are commonly used in various applications, including machine learning, natural language processing, computer vision, and more What is Pipeline ​ TIR Pipelines offer a way to write scalable, serverless and asynchronous training jobs based on docker containers. The supported formats include Argo and Kubeflow Pipelines Templates. You no longer have to worry about the reliability of training of jobs as TIR pipelines offer best-in class retry function. This allows you to restart a job without losing completed work. Additionally, TIR pipelines also support unlimited re-runs, stored results (in EOS buckets) and all resource plans (CPU and GPU). Guide to Create a Pipeline ​ Create Pipeline Step by step guide Run Create Run Scheduled Run Scheduled Run Docker Run Docker Run Introduction What is Pipeline Guide to Create a Pipeline",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/GettingStarted/iam/user_and_access_management/",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "IAM | E2E Cloud Skip to main content On this page Identity and Access management Identity and Access Management is a comprehensive system designed to manage user roles and permissions within the TIR environment. This feature ensures that the right people have access to the right resources, streamlining collaboration and enhancing security across various teams and projects. With Identity and Access Management, organizations can efficiently assign roles such as Owner, Admin, Team Lead, Team Member, Project Lead, and Member, ensuring clear and controlled access to critical functions and information. This structured approach not only simplifies user management but also fosters a more organized and productive working environment. TIR Users ​ 1. User Types ​ Owner: The owner of the main account has the ability to add primary users and contact persons to various teams and projects, assigning them various roles. Users: These are the users who can be added to the owner's account. 2. User Roles ​ Apart from the Owner, there are various other users who can be added with different roles in the TIR Account. Let's explore the different types of users in TIR. Admin: Admins have access to all teams and projects. They also have the ability to add users to teams and projects, assigning them various roles. Admins cannot add users with the Admin role. Like the owner, Admins can also create teams and projects. Team Lead: The Team Lead has full access to their specific team. They can add users to their team and projects exclusively within their team. Team Leads cannot add users with the Admin and Team Lead roles. Team Leads cannot create teams but can create projects within their team. Team Member: These users are part of a specific team. Team Members cannot add any type of user. Team Members cannot create teams or projects. Project Lead: The Project Lead will have full access to their specific project. They will be able to add users to their project only. Project Leads cannot add users with the Admin, Team Lead, and Project Lead roles. Project Leads cannot create teams and projects. Member: These users are part of a specific project with some policy (authorized access to TIR Services) assigned to them. Members cannot add any users. Members cannot create teams or projects. TIR Users 1. User Types 2. User Roles",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/private_cluster/",
    "site_type": "Cloud Computing Platform Documentation",
    "content": "Private Cluster | E2E Cloud Skip to main content On this page Private Cluster Private Cluster enables the creation of a dedicated environment with a predefined allocation of GPU resources. The pricing for the Private Cluster is fixed, unaffected by the actual usage percentage of the allocated resources. Additionally, deploying Nodes, Inference engines, or Vector Databases within the Private Cluster incurs no extra charges. Create Private Cluster ​ To create a new Private Cluster , click the Create Private Cluster button. Select the desired Cluster Configuration by choosing the appropriate machine type with the required GPU and an available plan. Additionally, you can apply filters to the available resources based on CPU , RAM , or GPU Card specifications. On this page, you can view the details of the selected plan. Depending on whether you choose an Hourly-Billed Plan or a Committed Plan , the summary section will display the corresponding details and associated costs. Private Cluster Hourly plan ​ You can select an Hourly-Based Plan based on your requirements, view the estimated cost, and then click Next to proceed. Private Cluster Committed plan ​ In a Private Cluster with a committed plan, users can choose one of the following post-expiry actions: auto-renew the committed plan, auto-start hourly billing, or automatically delete the cluster after expiry. Manage Private Cluster ​ Overview ​ You can view the details of the selected Private Cluster , including the Cluster Name , Number of Nodes , Plan Name , and the Cluster Node Configuration , which displays the count of GPUs , CPUs , and RAM allocated within the cluster. Monitoring ​ You can view the Disk Usage and Memory Usage for the selected Node within the Private Cluster . Additionally, the following metrics are also available: GPU Utilization , GPU Temperature , CPU Utilization , Memory Utilization , Disk Total Read Bytes , and Disk Total Write Bytes . Services ​ You can view the list of Services that have been launched on the cluster. Actions ​ In the Actions section, you can perform two operation which is Update cluster in which you can increase the Node count and Delete cluster . Update Private Cluster ​ In Actions section, click on Update Cluster . To update the node count, click on the Additional Node Count (+) button and increase the nodes as per your requirements. Delete Private Cluster ​ In Actions section, click on Delete Cluster and confirm. Create Private Cluster Manage Private Cluster Overview Monitoring Services Actions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get#Responses",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get#Request",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/setting_up_s3cmd/",
    "site_type": "Documentation",
    "content": "Setting up S3cmd on Linux | E2E Cloud Skip to main content On this page Setting up S3cmd on Linux S3cmd is a popular cross-platform command-line tool for managing S3-compatible object stores. In this tutorial, we will see how to configure and use S3cmd with E2E Object Storage. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer here . Access and Secret keys with permissions for the target bucket. Linux system for installing s3cmd CLI. Step 1: Installing s3cmd on Linux ​ s3cmd is available in default rpm repositories for CentOS, RHEL, and Ubuntu systems. You can install it by simply executing the following commands on your system. On CentOS/RHEL ​ yum install s3cmd On Ubuntu/Debian ​ sudo apt-get install s3cmd Step 2 : (Option 1) Configure s3cmd in Interactive Mode ​ Let us first use interactive mode. Please keep the below information handy as we will need it during the process. Access Key : xxxxxxxxxxxxxxxxxxxx Secret Key : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx S3 Endpoint : objectstore.e2enetworks.net Bucket URL : %(bucket)s.objectstore.e2enetworks.net Default Region: Leave blank (skip) To start configuration in interactive mode, enter the following command: s3cmd --configure Below is the snapshot of installation wizard. Follow the process in similar way to configure EOS with s3cmd CLI. Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region [US]: Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: objectstore.e2enetworks.net Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: % (bucket)s.objectstore.e2enetworks.net Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: New settings: Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region: US S3 Endpoint: objectstore.e2enetworks.net DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.objectstore.e2enetworks.net Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: True HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Configuration saved to '/root/.s3cfg' Note If you test the access with supplied credentials,you will get an error Test failed,Are you sure your keys have s3 :ListallMybuckets permission You can ignore this error since you are using this with EOS bucket Step 2 : (Option 2) Setup s3cmd with Configuration file ​ You can also manually edit the file ~/.s3cfg and credentials in the following format. # Setup endpoint host_base = objectstore.e2enetworks.net host_bucket = %(bucket)s.objectstore.e2enetworks.net # Setup access keys access_key = <<enter your access key here>> secret_key = <<enter your secret key here>> Step 3 : Test access with configured credentials ​ List the contents of target bucket (eg. e2e-test) using a command like below. Please note the access and secret key that you had chosen during interactive/manual setup must have access to this bucket. s3cmd ls s3://e2e-test Note You will not be able to list all the buckets (i.e.,with just s3cmd ls s3://),You need to specify the bucket name You may also test by moving local file to your target bucket (e.g. e2e-test) use below command touch testingfile s3cmd sync testingfile s3://e2e-test/ upload: 'test' -> 's3://e2e-test/testingfile' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done s3cmd ls s3://e2e-test 2019-11-22 12:51 0 s3://e2e-test/testingfile Conclusion ​ We have now successfully configured s3cmd to work with E2E Object Service. The complete user guide on the usage of s3cmd is available here . Prerequisites Step 1: Installing s3cmd on Linux On CentOS/RHEL On Ubuntu/Debian Step 2 : (Option 1) Configure s3cmd in Interactive Mode Step 2 : (Option 2) Setup s3cmd with Configuration file Step 3 : Test access with configured credentials Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/setting_up_s3cmd/#on-centosrhel",
    "site_type": "Documentation",
    "content": "Setting up S3cmd on Linux | E2E Cloud Skip to main content On this page Setting up S3cmd on Linux S3cmd is a popular cross-platform command-line tool for managing S3-compatible object stores. In this tutorial, we will see how to configure and use S3cmd with E2E Object Storage. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer here . Access and Secret keys with permissions for the target bucket. Linux system for installing s3cmd CLI. Step 1: Installing s3cmd on Linux ​ s3cmd is available in default rpm repositories for CentOS, RHEL, and Ubuntu systems. You can install it by simply executing the following commands on your system. On CentOS/RHEL ​ yum install s3cmd On Ubuntu/Debian ​ sudo apt-get install s3cmd Step 2 : (Option 1) Configure s3cmd in Interactive Mode ​ Let us first use interactive mode. Please keep the below information handy as we will need it during the process. Access Key : xxxxxxxxxxxxxxxxxxxx Secret Key : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx S3 Endpoint : objectstore.e2enetworks.net Bucket URL : %(bucket)s.objectstore.e2enetworks.net Default Region: Leave blank (skip) To start configuration in interactive mode, enter the following command: s3cmd --configure Below is the snapshot of installation wizard. Follow the process in similar way to configure EOS with s3cmd CLI. Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region [US]: Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: objectstore.e2enetworks.net Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: % (bucket)s.objectstore.e2enetworks.net Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: New settings: Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region: US S3 Endpoint: objectstore.e2enetworks.net DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.objectstore.e2enetworks.net Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: True HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Configuration saved to '/root/.s3cfg' Note If you test the access with supplied credentials,you will get an error Test failed,Are you sure your keys have s3 :ListallMybuckets permission You can ignore this error since you are using this with EOS bucket Step 2 : (Option 2) Setup s3cmd with Configuration file ​ You can also manually edit the file ~/.s3cfg and credentials in the following format. # Setup endpoint host_base = objectstore.e2enetworks.net host_bucket = %(bucket)s.objectstore.e2enetworks.net # Setup access keys access_key = <<enter your access key here>> secret_key = <<enter your secret key here>> Step 3 : Test access with configured credentials ​ List the contents of target bucket (eg. e2e-test) using a command like below. Please note the access and secret key that you had chosen during interactive/manual setup must have access to this bucket. s3cmd ls s3://e2e-test Note You will not be able to list all the buckets (i.e.,with just s3cmd ls s3://),You need to specify the bucket name You may also test by moving local file to your target bucket (e.g. e2e-test) use below command touch testingfile s3cmd sync testingfile s3://e2e-test/ upload: 'test' -> 's3://e2e-test/testingfile' [1 of 1] 0 of 0 0% in 0s 0.00 B/s done s3cmd ls s3://e2e-test 2019-11-22 12:51 0 s3://e2e-test/testingfile Conclusion ​ We have now successfully configured s3cmd to work with E2E Object Service. The complete user guide on the usage of s3cmd is available here . Prerequisites Step 1: Installing s3cmd on Linux On CentOS/RHEL On Ubuntu/Debian Step 2 : (Option 1) Configure s3cmd in Interactive Mode Step 2 : (Option 2) Setup s3cmd with Configuration file Step 3 : Test access with configured credentials Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/gpu/overview/",
    "site_type": "Documentation",
    "content": "GPU Cloud | E2E Cloud Skip to main content GPU Cloud Welcome to the E2E GPU Cloud documentation! This comprehensive guide is designed to acquaint you with the vast array of GPU computing solutions offered by E2E Networks. From high-performance Nvidia Tesla GPUs to versatile Nvidia Grid solutions, this documentation covers a range of topics to maximize your GPU cloud computing experience. Begin with an Introduction to GPU Cloud Computing , exploring the benefits and applications of GPU-accelerated computing in various fields. Dive deep into specific GPU offerings, such as Nvidia Tesla V100 , Nvidia Tesla T4 , and the NVIDIA A40 and A100 GPUs . These sections provide detailed insights into each GPU's capabilities and use cases. For developers and data scientists, the documentation includes practical guides and tutorials. Learn how to leverage the NVIDIA® GPU Cloud (NGC) with E2E Cloud Compute for optimized machine learning and deep learning workflows. Explore tutorials on running Jupyter Notebooks inside TensorFlow and Pytorch Containers, as well as detailed instructions on CUDA installation and manage gpus with E2E This documentation is an invaluable resource for anyone looking to harness the power of GPU computing in the cloud. Whether you are a seasoned developer, a data scientist, or just starting out, these guides and tutorials provide all the information you need to get started and make the most out of E2E's GPU cloud services. Get Started.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/gpu/nvidia_tesla_v100/",
    "site_type": "Documentation",
    "content": "Nvidia Tesla V100 | E2E Cloud Skip to main content On this page Nvidia Tesla V100 The advent of AI and ML have shaken up the whole technological space by virtue of the potential they hold for each and every industry. According to a report by MIT Sloan Management Review, as many as half of the industry giants with over a hundred thousand employees already had an AI strategy in place by 2018, while the other half were soon expected to have one. When NVIDIA launched its most powerful GPU, Tesla V100 Tensor Core, the substantial acceleration of AI, high-performance computing, data science, and graphics became unstoppable. Powered with the performance of as many as 100 CPUs, a single Tesla V100 GPU can largely cut down the time that data scientists, researchers, and engineers spend on optimizing memory usage, giving them additional time to work on the next revolution in AI, Machine Learning, and more. Why Use a Tesla V100 GPU? ​ When it comes to GPU-accelerated computing, there is no match to NVIDIA Tesla, and it boasts of its reputation as it powers some of the largest datacenters across the world by delivering high throughput at comparably lower costs. Let’s look at some of the reasons why you must consider Tesla V100 GPU: Catalyze AI Training ​ The hype about AI is higher than it ever was. Companies are doing all that is needed to source their data scientists to take up new challenges and create better, more powerful, and reliable solutions, whether it's for speech recognition, training virtual personal assistants, or teaching autonomous cars to drive. Training deep learning models for such use cases is a complex task and requires a tremendous amount of time. Each Tesla V100 GPU comes with 640 Tensor Cores, and with the use of NVIDIA NVLink, these GPUs can be interconnected to render a computing server that holds the power to accelerate up to 300 GB/s. This can pave your path to reducing the training time for AI models from weeks to just a few days. 47x Higher AI Inference ​ With the increasing user demand to connect them to relevant information, services, and products, companies are facing a challenging situation. Even the world’s largest hyperscale company feels the need to double its datacenter capacity in order to smoothly allow each of its users to spend just three minutes each day using their speech recognition services. Tesla V100 is the answer to all such shortcomings that companies are faced with today. It delivers 47 times higher inference performance as compared to a CPU server. This is the much-needed leap that the datacenters and the AI industry had been needing to handle the increasing demand. High-Performance Computing ​ The world needs high-performance computing today more than it ever did. These computing systems have a wide variety of use-cases, from weather forecasting to discovering drugs to searching for new energy sources. With the confluence of AI and HPC, Tesla V100 can facilitate the rapid analysis of large pools of data and help render quick insights. Tesla V100 GPUs On E2E Cloud ​ Now that you’ve started to think about how you could utilize Tesla V100 GPUs, why not go with the best-suited cloud-based GPUs to maximize the performance and minimize the total cost of ownership? Here’s why you should consider using E2E Networks’ Tesla V100 GPU Cloud: All the GPU servers of E2E Networks run in Indian datacenters, reducing latency. Powerful hardware deployed along with cutting-edge engineering that renders increased reliability. Uptime SLAs so that you worry less and do more. Inexpensive pricing plans designed according to the needs of customers. These features not only make E2E GPU Cloud services stand out from others in the market, but they also help you stay ahead of your competition by outperforming them. Make the Most From Tesla V100 GPUs on Cloud ​ E2E Networks is the affordable cloud for companies looking to boost their AI game to the next level. Just when you need it the most, E2E Networks is here to empower your company with the massive performance of Tesla V100 GPUs. Take the giant leap in throughput and efficiency, and give the supercomputing powers to your AI/ML workloads with GPUs on E2E Cloud. Get started, pick and choose your best GPU plan here Why Use a Tesla V100 GPU? Catalyze AI Training 47x Higher AI Inference High-Performance Computing Tesla V100 GPUs On E2E Cloud Make the Most From Tesla V100 GPUs on Cloud",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-without-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Documentation",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/sign_in/#sign-in-with-google-using-trusting-the-device",
    "site_type": "Documentation",
    "content": "Sign In Process | E2E Cloud Skip to main content On this page Sign In Process The customer can sign in with multiple methods in MyAccount of E2E: Sign-In with credentials Sign-In with Google Sign-In with GitHub Sign-In without Trusting the Device ​ To sign in normally, just put in your email and password, and then click the 'Sign-In' button. If you sign in without trusting the device, your session will expire after 15 minutes of inactivity. But if you are actively using it, you won't be logged out. After clicking on sign in, you will be directed to the OTP page. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you have successfully signed in, you will be redirected to the dashboard. Sign-In with Trusting the Device ​ If you sign in with trusting the device, your session will expire after 60 days. However, you can choose to log out manually if you want to end it before that. Sign-In with Google Using Trusting the Device ​ If you want to sign in with Google, you have to click on \"Sign-In with Google\". After clicking, you will be redirected to the \"Choose an account\" page. Enter your password and click on the \"Next\" button. Click on \"Continue\" button. You will be redirected to the page below. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with Google successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In with GitHub Using Trusting the Device ​ If you want to sign in with GitHub, you have to click on \"Sign-In with GitHub\". After clicking, you will be redirected to the \"Sign in to GitHub to continue to E2E Networks Limited - GitHub Integration\" page. After a few seconds, you'll go to the '2-Factor Authentication' page. There, enter the OTP sent to your registered number. You will receive an option of receiving OTP over a voice call if you are unable to receive OTP over SMS in two attempts. Once you enter the OTP , click on Validate OTP . After logging in with GitHub successfully, you will see the dashboard. A popup will appear, asking if you want to trust the device. If you don't click 'Trust the device', you'll be logged out automatically after 15 minutes of inactivity. But if you do click 'Trust the device', you will stay logged in with the account for 60 days. Sign-In without Trusting the Device Sign-In with Trusting the Device Sign-In with Google Using Trusting the Device Sign-In with GitHub Using Trusting the Device",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/customer-resource-limit/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Resource Limit get https://api.e2enetworks.com/myaccount/api/v1 /customer-resource-limit/ Request Security: API Key & Bearer Auth Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/customer-resource-limit/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#__docusaurus_skipToContent_fallback",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/iam-multi-crn/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight CRN details get https://api.e2enetworks.com/myaccount/api/v1 /iam/multi-crn/ Request Security: API Key & Bearer Auth Responses 200 Successful response with CRN data Body application/json application/json code integer Example: 200 data object crn_data array[object] last_used_crn integer Example: 14760 last_used_project integer Example: 17925 errors object Example: {} message string Example: Success Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/iam/multi-crn/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : { 4 \"crn_data\" : [ 5 { 6 \"first_name\" : \"Nipun\" , 7 \"last_name\" : \"\" , 8 \"crn\" : 23827 , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"iam_type\" : \"Owner\" , 11 \"organisation_name\" : \"NIPUN\" , 12 \"is_available_for_switching\" : true 13 } 14 ] , 15 \"last_used_crn\" : 14760 , 16 \"last_used_project\" : 17925 17 } , 18 \"errors\" : { } , 19 \"message\" : \"Success\" 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/#/paths/pbac-projects-header/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight Project details get https://api.e2enetworks.com/myaccount/api/v1 /pbac/projects-header/ Request Security: API Key & Bearer Auth Query Parameters crn integer required CRN ID Find your CRN here >= 0 Auth apikey : Token : Parameters crn* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/pbac/projects-header/?apikey=123' \\ --header 'Authorization: Bearer 123'",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/actions/",
    "site_type": "Documentation",
    "content": "Actions on Object Storage | E2E Cloud Skip to main content On this page Bucket Actions There are six actions in Bucket: Object Versioning Presigned URL Lifecycle Rule Replication Rule Empty Add to CDN Delete Object Versioning ​ E2E provides an Object Versioning feature in Object storage. Using this feature, users can upload duplicate files, which will be stored in Minio with different versions. To enable versioning, click on the Action button and select Object Versioning . Presigned URL ​ E2E provides a Presigned URL feature in Object Storage. This feature allows users to generate presigned URLs for files in their buckets, enabling direct download or upload of files via these URLs. Users can also easily integrate upload presigned URLs into their code for seamless file uploads. After clicking on Generate Presigned URL , you have to enter the required details and select the type of URL, as shown below. Now click on Generate URL to create the Presigned URL. Lifecycle Rule ​ E2E provides a Lifecycle Rule feature in Object storage. Using this feature, users can apply a lifecycle rule to a bucket. After applying this, the object will be deleted as per your set rule. To set it up, click on the Action button, select Lifecycle Rule , enter the details, and click Save . Replication Rule ​ E2E provides a Replication Rule feature in Object Storage. This feature allows users to transfer their objects from one region to another region's bucket. To enable replication, click on Action and select Replication Rule . Enter the required details and click Save . Note For enabling replication rule, versioning must be enabled for the bucket. Users can perform actions on the replication bucket by clicking on Action . Available actions include Delete and Disable . Empty Bucket ​ Using the Empty action, the user can empty the bucket, which will delete all objects from it. Add to CDN ​ EOS integration with CDN improves the performance, scalability, and reliability of the platform by leveraging the capabilities of a Content Delivery Network. Users can perform actions on Add to CDN by clicking on the Action button. Note To add CDN, you need to give public access to your bucket. After clicking on Add to CDN , click on Create CDN . Once created, a new section named Bucket CDN will appear in the Manage Object Storage interface, showing the details of the CDN. You can access comprehensive details about CDN services and view all their actions in the dedicated CDN section. Upload Files ​ Permissions ​ In the Permissions tab, permission details are displayed, and customers can apply permissions to the bucket using the access key and perform actions on it. Access Key ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Customers can create access keys using the Manage Access Keys option in the Permissions tab. Using Manage Access Key ​ To create an access key, click on the Manage Access Keys button. Actions in Manage Access Key ​ Customers can perform two actions on access keys: Lock , Unlock , and Delete . Go to Products > Storage option in the sidebar menu Choose any bucket or create a new one Click the Permissions tab Click the Create Access Key button Enter a name for your access key Choose an access key or create a new one Assign a role: Role Permissions bucket admin can read, write, manage bucket writer can read, write bucket reader can read Public Access Config ​ Using Public Access Config , you can give the permissions for Upload, Download, Upload & Download, or Private for the objects using URL. To enable this, click on Public Access Config and select the desired permission. Bucket Lifecycle ​ In this section, the lifecycle rules you have created are displayed. You can also create and perform actions on these rules. Bucket Details ​ In this section, the details of the bucket are displayed. Bucket Permissions ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Go to Products > Storage option in the sidebar menu Choose any bucket or create a new one Click the Permissions tab Click the Create Access Key button Enter a name for your access key Choose an access key or create a new one Assign a role: Role Permissions bucket admin can read, write, manage bucket writer can read, write bucket reader can read Save the permission. Create Access Key ​ You can create an access key from the Permissions tab on the Bucket details page or the Manage Access page. Enter a name for your access key (application name, project name, or team member name). Click Generate Key . A newly generated access and secret key will be displayed. Keep a note of both keys as you will not see them again after you close the modal window. If you have mc setup, use the given command to configure CLI for this access key. Hint: Choose a short name for the access key, as you will be entering this for each command you type in CLI. Manage Access ​ Sometimes you may need to disable access for certain users or applications. You can lock their access key from the Manage Access page. Go to Products > Storage option in the sidebar menu Click Manage Access Key Identify the access you want to lock by key name Click the Lock icon To unlock, follow the same steps, but click the Unlock icon. Protect Your Bucket Data With Encryption Introduction ​ The procedure on this page configures and enables Server-Side Encryption with Client-Managed Keys (SSE-C). EOS SSE-C supports client-driven encryption of objects before writing the object to the drive. Clients must specify the correct key to decrypt objects for read operations. Prerequisites ​ The mc client is required to encrypt an object ( How to install mc client ). The SSE-C key must be a 256-bit base64-encoded string. The client application is responsible for generating and storing the encryption key. EOS does not store SSE-C encryption keys and cannot decrypt SSE-C encrypted objects without the client-managed key. 1) Generate the Encryption Key ​ First, an encryption key is required. You can generate the encryption key using the following command: cat /dev/urandom | head -c 32 | base64 - It is important to notice that a 256-bit base64-encoded string should be used. Save the encryption key for future reference. 2) Encrypt and Copy Object into Bucket Using Encryption Key ​ To encrypt an object using the mc client, refer to the following command: mc cp ~/source_path/my_object.json ALIAS/BUCKET/my_object.json \\ --encrypt-key \"ALIAS/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with the key_name used while configuring the mc client on which you want to write the SSE-C encrypted object. Replace BUCKET with the full path to the bucket or bucket prefix to which you want to write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. 3) Copy an SSE-C Encrypted Object Between Two Buckets ​ EOS also supports copying an SSE-C encrypted object to another S3-compatible service: mc cp SOURCE/BUCKET/mydata.json TARGET/BUCKET/mydata.json \\ --encrypt-key \\ \"SOURCE/BUCKET/=ENCRYPTION_KEY\",\"TARGET/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with respecting key_name used while configuring the mc client on which you want to read and write the SSE-C encrypted object. Replace source and destination BUCKET with the full path to the bucket or bucket prefix on which you want to read and write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. Considerations: SSE-C encrypted objects are not compatible with the EOS bucket replication feature. User manage a mapping of which encryption key was used to encrypt which object. E2E does not store encryption keys. You are responsible for tracking which encryption key you provided for which object. If your bucket is versioning-enabled, each object version that you upload by using this feature can have its own encryption key. You are responsible for tracking which encryption key was used for which object version. For downloading an encrypted object encryption key is required, if the user loses the key then he can not download the data, and his data will be lost. In this case E2E is not responsible for the loss of your data. References ​ MinIO Server-Side Encryption SSE-C Quickstart E2E Networks MC Client Download Guide Object Versioning Presigned URL Lifecycle Rule Replication Rule Empty Bucket Add to CDN Upload Files Permissions Access Key Using Manage Access Key Actions in Manage Access Key Public Access Config Bucket Lifecycle Bucket Details Bucket Permissions Create Access Key Manage Access Introduction Prerequisites 2) Encrypt and Copy Object into Bucket Using Encryption Key References",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/actions/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Actions on Object Storage | E2E Cloud Skip to main content On this page Bucket Actions There are six actions in Bucket: Object Versioning Presigned URL Lifecycle Rule Replication Rule Empty Add to CDN Delete Object Versioning ​ E2E provides an Object Versioning feature in Object storage. Using this feature, users can upload duplicate files, which will be stored in Minio with different versions. To enable versioning, click on the Action button and select Object Versioning . Presigned URL ​ E2E provides a Presigned URL feature in Object Storage. This feature allows users to generate presigned URLs for files in their buckets, enabling direct download or upload of files via these URLs. Users can also easily integrate upload presigned URLs into their code for seamless file uploads. After clicking on Generate Presigned URL , you have to enter the required details and select the type of URL, as shown below. Now click on Generate URL to create the Presigned URL. Lifecycle Rule ​ E2E provides a Lifecycle Rule feature in Object storage. Using this feature, users can apply a lifecycle rule to a bucket. After applying this, the object will be deleted as per your set rule. To set it up, click on the Action button, select Lifecycle Rule , enter the details, and click Save . Replication Rule ​ E2E provides a Replication Rule feature in Object Storage. This feature allows users to transfer their objects from one region to another region's bucket. To enable replication, click on Action and select Replication Rule . Enter the required details and click Save . Note For enabling replication rule, versioning must be enabled for the bucket. Users can perform actions on the replication bucket by clicking on Action . Available actions include Delete and Disable . Empty Bucket ​ Using the Empty action, the user can empty the bucket, which will delete all objects from it. Add to CDN ​ EOS integration with CDN improves the performance, scalability, and reliability of the platform by leveraging the capabilities of a Content Delivery Network. Users can perform actions on Add to CDN by clicking on the Action button. Note To add CDN, you need to give public access to your bucket. After clicking on Add to CDN , click on Create CDN . Once created, a new section named Bucket CDN will appear in the Manage Object Storage interface, showing the details of the CDN. You can access comprehensive details about CDN services and view all their actions in the dedicated CDN section. Upload Files ​ Permissions ​ In the Permissions tab, permission details are displayed, and customers can apply permissions to the bucket using the access key and perform actions on it. Access Key ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Customers can create access keys using the Manage Access Keys option in the Permissions tab. Using Manage Access Key ​ To create an access key, click on the Manage Access Keys button. Actions in Manage Access Key ​ Customers can perform two actions on access keys: Lock , Unlock , and Delete . Go to Products > Storage option in the sidebar menu Choose any bucket or create a new one Click the Permissions tab Click the Create Access Key button Enter a name for your access key Choose an access key or create a new one Assign a role: Role Permissions bucket admin can read, write, manage bucket writer can read, write bucket reader can read Public Access Config ​ Using Public Access Config , you can give the permissions for Upload, Download, Upload & Download, or Private for the objects using URL. To enable this, click on Public Access Config and select the desired permission. Bucket Lifecycle ​ In this section, the lifecycle rules you have created are displayed. You can also create and perform actions on these rules. Bucket Details ​ In this section, the details of the bucket are displayed. Bucket Permissions ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Go to Products > Storage option in the sidebar menu Choose any bucket or create a new one Click the Permissions tab Click the Create Access Key button Enter a name for your access key Choose an access key or create a new one Assign a role: Role Permissions bucket admin can read, write, manage bucket writer can read, write bucket reader can read Save the permission. Create Access Key ​ You can create an access key from the Permissions tab on the Bucket details page or the Manage Access page. Enter a name for your access key (application name, project name, or team member name). Click Generate Key . A newly generated access and secret key will be displayed. Keep a note of both keys as you will not see them again after you close the modal window. If you have mc setup, use the given command to configure CLI for this access key. Hint: Choose a short name for the access key, as you will be entering this for each command you type in CLI. Manage Access ​ Sometimes you may need to disable access for certain users or applications. You can lock their access key from the Manage Access page. Go to Products > Storage option in the sidebar menu Click Manage Access Key Identify the access you want to lock by key name Click the Lock icon To unlock, follow the same steps, but click the Unlock icon. Protect Your Bucket Data With Encryption Introduction ​ The procedure on this page configures and enables Server-Side Encryption with Client-Managed Keys (SSE-C). EOS SSE-C supports client-driven encryption of objects before writing the object to the drive. Clients must specify the correct key to decrypt objects for read operations. Prerequisites ​ The mc client is required to encrypt an object ( How to install mc client ). The SSE-C key must be a 256-bit base64-encoded string. The client application is responsible for generating and storing the encryption key. EOS does not store SSE-C encryption keys and cannot decrypt SSE-C encrypted objects without the client-managed key. 1) Generate the Encryption Key ​ First, an encryption key is required. You can generate the encryption key using the following command: cat /dev/urandom | head -c 32 | base64 - It is important to notice that a 256-bit base64-encoded string should be used. Save the encryption key for future reference. 2) Encrypt and Copy Object into Bucket Using Encryption Key ​ To encrypt an object using the mc client, refer to the following command: mc cp ~/source_path/my_object.json ALIAS/BUCKET/my_object.json \\ --encrypt-key \"ALIAS/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with the key_name used while configuring the mc client on which you want to write the SSE-C encrypted object. Replace BUCKET with the full path to the bucket or bucket prefix to which you want to write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. 3) Copy an SSE-C Encrypted Object Between Two Buckets ​ EOS also supports copying an SSE-C encrypted object to another S3-compatible service: mc cp SOURCE/BUCKET/mydata.json TARGET/BUCKET/mydata.json \\ --encrypt-key \\ \"SOURCE/BUCKET/=ENCRYPTION_KEY\",\"TARGET/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with respecting key_name used while configuring the mc client on which you want to read and write the SSE-C encrypted object. Replace source and destination BUCKET with the full path to the bucket or bucket prefix on which you want to read and write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. Considerations: SSE-C encrypted objects are not compatible with the EOS bucket replication feature. User manage a mapping of which encryption key was used to encrypt which object. E2E does not store encryption keys. You are responsible for tracking which encryption key you provided for which object. If your bucket is versioning-enabled, each object version that you upload by using this feature can have its own encryption key. You are responsible for tracking which encryption key was used for which object version. For downloading an encrypted object encryption key is required, if the user loses the key then he can not download the data, and his data will be lost. In this case E2E is not responsible for the loss of your data. References ​ MinIO Server-Side Encryption SSE-C Quickstart E2E Networks MC Client Download Guide Object Versioning Presigned URL Lifecycle Rule Replication Rule Empty Bucket Add to CDN Upload Files Permissions Access Key Using Manage Access Key Actions in Manage Access Key Public Access Config Bucket Lifecycle Bucket Details Bucket Permissions Create Access Key Manage Access Introduction Prerequisites 2) Encrypt and Copy Object into Bucket Using Encryption Key References",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/bucket_details/",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "Bucket Details | E2E Cloud Skip to main content On this page Bucket Details In Bucket details, all details of the bucket will be shown. Objects ​ In Objects, the list of objects will be shown. Customers can upload objects from here and perform actions on that. To upload objects, the user can click the Upload button. All uploaded objects are displayed in the Objects section. To view the all versions of an object, click View All Versions. To delete an object, click the Delete button under the Actions. Version Actions ​ Click the “Generate Presigned URL” button under the Actions menu to create a presigned URL for the version. To download the object version, click the Download button under the Actions menu in the Versions section. To delete the object version, click the Delete button under the Actions menu. Bucket Lifecycle ​ In this section, the lifecycle rules that you have created will be shown, and you can also create and perform actions on this. Bucket Details ​ In this section, the details of the bucket will be shown. Permissions ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Go to Products > Storage option in the sidebar menu. Choose any bucket or create a new one. Click the permission tab; it will be opened for the selected bucket. Click the Create access key button. Enter a name for your access key. This can be an application name, project name, or a team member name. Choose an access key or create a new access key. Assign a role: Role Description bucket admin can read, write, manage bucket writer can read, write bucket reader can read Save the permission. Objects Version Actions Bucket Lifecycle Bucket Details Permissions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/bucket_details/#objects",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "Bucket Details | E2E Cloud Skip to main content On this page Bucket Details In Bucket details, all details of the bucket will be shown. Objects ​ In Objects, the list of objects will be shown. Customers can upload objects from here and perform actions on that. To upload objects, the user can click the Upload button. All uploaded objects are displayed in the Objects section. To view the all versions of an object, click View All Versions. To delete an object, click the Delete button under the Actions. Version Actions ​ Click the “Generate Presigned URL” button under the Actions menu to create a presigned URL for the version. To download the object version, click the Download button under the Actions menu in the Versions section. To delete the object version, click the Delete button under the Actions menu. Bucket Lifecycle ​ In this section, the lifecycle rules that you have created will be shown, and you can also create and perform actions on this. Bucket Details ​ In this section, the details of the bucket will be shown. Permissions ​ If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Go to Products > Storage option in the sidebar menu. Choose any bucket or create a new one. Click the permission tab; it will be opened for the selected bucket. Click the Create access key button. Enter a name for your access key. This can be an application name, project name, or a team member name. Choose an access key or create a new access key. Assign a role: Role Description bucket admin can read, write, manage bucket writer can read, write bucket reader can read Save the permission. Objects Version Actions Bucket Lifecycle Bucket Details Permissions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Cloud Storage Management Platform Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/archive_logs/",
    "site_type": "Documentation",
    "content": "Archive Logs | E2E Cloud Skip to main content On this page How To Use Logrotate and S3cmd to Archive Logs to Object Storage Introduction ​ Log files generated on your application and services are sometimes very useful for debugging your application, investigating for security purposes, or general data insights. Storing logs on your server can be a little bit painful. Often, it’s not possible to retain long-term data in these systems due to storage constraints or other server resource issues. A common solution for these long-term storage needs is archiving logs with an object storage service. In this article, we will show you exactly how to use Logrotate and S3cmd to archive logs to Object Storage. Prerequisites ​ An Ubuntu or CentOS server with sudo access. Familiarity with Logrotate and its default configuration and setup. Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Setting up s3cmd on your server. If you haven't set it up, please refer to the tutorial: Setting up s3cmd . Configuring Logrotate ​ Once you have set up a bucket in Object Storage and installed S3cmd on your server, you can easily archive logs to the Object Storage bucket by making a slight modification to your Logrotate config. In this example, we are configuring Logrotate for message logs that are compressed and synced to the EOS bucket when the log file size exceeds 1GB. Create a configuration file in the /etc/logrotate.d/ directory. We are naming it message.conf . vim /etc/logrotate.d/message.conf Assuming the messages logs are stored in the /var/log/message file, Copy paste the below Configuration on the File and Save it /var/log/messages { rotate 3 size 1G missingok notifempty compress copytruncate dateext dateformat -%Y-%m-%d-%s postrotate s3cmd sync /var/log/messages*.gz \"s3://bucketname/\" endscript } Note Replace the message Logs path,Bucket Name and other config as per your requirement in the above configuration Below is the explanation of the configuration file we just used: rotate 3 : Keep three old log files. size 1G : Rotate log files if the size is greater than 1GB. missingok : Don’t write an error message if the log file is missing. notifempty : Don’t rotate the log file if it is empty. compress : Compress the rotated files. This uses gzip by default and results in files ending in .gz . copytruncate : Truncate the original log file in place after creating a copy. dateext : Archive old versions of log files by adding a daily extension like YYYYMMDD instead of simply adding a number. dateformat -%Y-%m-%d-%s : Specify the extension format for dateext using the given notation. The lines between postrotate and endscript (both of which must appear on lines by themselves) are executed (using /bin/sh ) after the log file is rotated. Here, the script we have used is to sync the messages log to the Object Storage bucket. s3cmd sync /var/log/messages*.gz \"s3://yourbucketname/\" You can also include the Logrotate to Run based on timing like Monthly or weekly if you want, which we have not included in the above example. Test and Executing Logrotate Config File ​ After customizing the config to fit your needs and saving it in /etc/logrotate.d, you can test it by doing a dry run, You can test the Logorate config to check if its working as expected. The below command will show you just the Output of the Task and Not execute it. If all looks well, you’re done logrotate -d /etc/logrotate.d/message.conf You can Execute the Logrotate Forceful by below command, Which otherwise would not run until the condition we provided in config is met. This is useful when testing the scripts etc.. which we added in Logrotate config file. logrotate -f /etc/logrotate.d/message.conf Conclusion ​ In this tutorial, we have covered the basic configuration of Logrotate for setting up and archiving logs to EOS buckets. You can also use many other configurations available in Logrotate (refer to all the options by running the command man logrotate in your terminal). If you face any issues while configuring the same and need assistance, you can contact cloud-Platform@e2enetworks.com , where our team can assist you. Introduction Prerequisites Configuring Logrotate Test and Executing Logrotate Config File Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/archive_logs/#introduction",
    "site_type": "Documentation",
    "content": "Archive Logs | E2E Cloud Skip to main content On this page How To Use Logrotate and S3cmd to Archive Logs to Object Storage Introduction ​ Log files generated on your application and services are sometimes very useful for debugging your application, investigating for security purposes, or general data insights. Storing logs on your server can be a little bit painful. Often, it’s not possible to retain long-term data in these systems due to storage constraints or other server resource issues. A common solution for these long-term storage needs is archiving logs with an object storage service. In this article, we will show you exactly how to use Logrotate and S3cmd to archive logs to Object Storage. Prerequisites ​ An Ubuntu or CentOS server with sudo access. Familiarity with Logrotate and its default configuration and setup. Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Setting up s3cmd on your server. If you haven't set it up, please refer to the tutorial: Setting up s3cmd . Configuring Logrotate ​ Once you have set up a bucket in Object Storage and installed S3cmd on your server, you can easily archive logs to the Object Storage bucket by making a slight modification to your Logrotate config. In this example, we are configuring Logrotate for message logs that are compressed and synced to the EOS bucket when the log file size exceeds 1GB. Create a configuration file in the /etc/logrotate.d/ directory. We are naming it message.conf . vim /etc/logrotate.d/message.conf Assuming the messages logs are stored in the /var/log/message file, Copy paste the below Configuration on the File and Save it /var/log/messages { rotate 3 size 1G missingok notifempty compress copytruncate dateext dateformat -%Y-%m-%d-%s postrotate s3cmd sync /var/log/messages*.gz \"s3://bucketname/\" endscript } Note Replace the message Logs path,Bucket Name and other config as per your requirement in the above configuration Below is the explanation of the configuration file we just used: rotate 3 : Keep three old log files. size 1G : Rotate log files if the size is greater than 1GB. missingok : Don’t write an error message if the log file is missing. notifempty : Don’t rotate the log file if it is empty. compress : Compress the rotated files. This uses gzip by default and results in files ending in .gz . copytruncate : Truncate the original log file in place after creating a copy. dateext : Archive old versions of log files by adding a daily extension like YYYYMMDD instead of simply adding a number. dateformat -%Y-%m-%d-%s : Specify the extension format for dateext using the given notation. The lines between postrotate and endscript (both of which must appear on lines by themselves) are executed (using /bin/sh ) after the log file is rotated. Here, the script we have used is to sync the messages log to the Object Storage bucket. s3cmd sync /var/log/messages*.gz \"s3://yourbucketname/\" You can also include the Logrotate to Run based on timing like Monthly or weekly if you want, which we have not included in the above example. Test and Executing Logrotate Config File ​ After customizing the config to fit your needs and saving it in /etc/logrotate.d, you can test it by doing a dry run, You can test the Logorate config to check if its working as expected. The below command will show you just the Output of the Task and Not execute it. If all looks well, you’re done logrotate -d /etc/logrotate.d/message.conf You can Execute the Logrotate Forceful by below command, Which otherwise would not run until the condition we provided in config is met. This is useful when testing the scripts etc.. which we added in Logrotate config file. logrotate -f /etc/logrotate.d/message.conf Conclusion ​ In this tutorial, we have covered the basic configuration of Logrotate for setting up and archiving logs to EOS buckets. You can also use many other configurations available in Logrotate (refer to all the options by running the command man logrotate in your terminal). If you face any issues while configuring the same and need assistance, you can contact cloud-Platform@e2enetworks.com , where our team can assist you. Introduction Prerequisites Configuring Logrotate Test and Executing Logrotate Config File Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/",
    "site_type": "Documentation",
    "content": "Object Storage | E2E Cloud Skip to main content On this page Object Storage Getting Started with E2E Object Store ​ E2E Object Storage Introduction to Object Storage Object Storage Actions Available actions for buckets Bucket Details Learn how to view your buckets details Access Keys Learn about access keys for EOS permissions. Object Lock Enable Object Lock for your bucket Object Versioning Enable Object Versioning for your bucket Object Storage Encryption Enable Object Storage Encryption for your bucket Integrating External Tools and Plugins with E2E Object Store ​ Working with CLI Guide for using S3 compatible CLI with Object Store API Integration REST endpoints for easy integration with external apps and plugins. Set up S3cmd on Linux Configure and use S3cmd with E2E Object Storage Set up S3cmd on Windows Configure and use S3cmd with E2E Object Storage Set up S3FS-Fuse Configure S3FS-Fuse with E2E Object Storage on CentOS Install S3 Browser Install and setup S3 browser for E2E Object store on Windows. Replicate S3-Bucket to EOS-Bucket Live Replication Between S3-Bucket-Folder to EOS-Bucket-Folder E2E Object Storage Use Cases ​ Host a Static Site Tutorial for hosting a static site with E2E Object Storage MySQL Database Backup Guide to Backing Up Your MySQL Database Content to E2E Object Store Archive logs How to use Logrotate and S3cmd to archive logs to Object Storage Copy E2E Object Store How to copy your EOS bucket object to another E2E Account Backup your WordPress How to Backup Your WordPress files and Databases to Object Storage Setup Docker Registry Guide for setting up a Docker registry using E2E Object Store for storing and retrieving images FAQs ​ FAQs Frequently asked Questions regarding E2E Object Storage Getting Started with E2E Object Store Integrating External Tools and Plugins with E2E Object Store E2E Object Storage Use Cases FAQs",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/myaccount/",
    "site_type": "Documentation",
    "content": "E2E Cloud | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Documentation MyAccount Explore All Products ✨ NSE Listed, MeitY Empanelled AI-First Hyperscaler E2E Networks is the leading hyperscaler from India with focus on advanced Cloud GPU infrastructure. The company is popular for providing accelerated cloud computing solutions, including cutting-edge Cloud GPUs like NVIDIA H200/H100/A100 and other GPUs, making it the leading IAAS provider focused on advanced Cloud GPU capabilities in India. Getting Started Compute Storage Database Network Billing Sign Up Process for Indian and International Customers Sign In Sign In Methods IAM Identity and Access Management Explore All Products",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/epfs/",
    "site_type": "Documentation",
    "content": "Introduction to EPFS | E2E Cloud Skip to main content On this page Introduction to EPFS Overview ​ EPFS (E2E Parallel File System) is a highly scalable and reliable parallel file system designed for large-scale High-Performance Computing (HPC) environments. It delivers exceptional performance by supporting parallel data access, making it ideal for handling massive datasets and numerous clients. High throughput : Supports multiple simultaneous clients. Scalability : Can handle petabytes of data and thousands of clients. Reliability : Uses robust mechanisms to ensure data integrity. How EPFS Works ​ Data Distribution : Data is striped across multiple OSSs, enabling parallel read/write operations. The striping pattern can be customized for specific use cases. Metadata Management : The MDS manages metadata, keeping operations like file creation and deletion fast. Parallelism : Clients access data in parallel from OSSs, minimizing bottlenecks. Advantages ​ High Speed : Parallel operations increase performance. Fault Tolerance : Data is replicated across nodes. Scalability : Designed for massive datasets and numerous clients. Note This feature is currently available only on AlmaLinux. Managing EPFS ​ Creating an EPFS ​ Navigate to the Storage > EPFS section in the left sidebar of the dashboard. Click Create . Provide the following details: Name : Enter a name for your EPFS. Plan : Select an appropriate plan. VPC : Choose the desired Virtual Private Cloud. Click Create EPFS . Your newly created EPFS will appear in the list. Accessing EPFS ​ Note Ensure that EPFS and the Virtual Machine (VM) are on the same network. Follow these steps to set up the client and mount EPFS: Download the Client Setup Script : Download the scripts.tar file. Transfer the script to the server : Use the scp command to copy the file into your server. scp <File-Location>/scripts.tar <username>@<server_ip>:/root/ Extract the tar file: Run the following command to extract the script: tar -xvf <file_name> Run the Client Setup Command: Execute the following script to set up the client: ./client_setup.sh tcp1056 10.5.17.... tcp Mount the EPFS: Use the following command to mount EPFS: mount -t lustre 10.20.56.8@tcp:/pfs0 <path_to_your_folder> Upgrading EPFS ​ Enhance your EPFS by increasing its memory capacity through the Upgrade EPFS feature. Click Upgrade under the Action menu. Select the desired upgraded plan and Confirm by clicking the Upgrade button. Your EPFS will be upgraded to the selected configuration. Deleting an EPFS ​ Select Delete from the Action menu. A warning message will notify you of permanent data loss. Confirm and proceed by clicking Delete. The selected EPFS storage will be removed. Overview How EPFS Works Advantages Managing EPFS Creating an EPFS Accessing EPFS Upgrading EPFS Deleting an EPFS",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/sfs-encryption/sfs_encryption/",
    "site_type": "Documentation",
    "content": "Scalable File System Encryption | E2E Cloud Skip to main content Create Encrypted SFS Click on Create Scalable File System , enter a name for your SFS, select the desired plan and VPC, and then check the Enable Encryption checkbox. The Passphrase field is optional . Finally, click on Launch SFS to create the encrypted file system. The SFS will be successfully created, and an encryption shield icon will appear in front of the SFS name to indicate that it is encrypted.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/epfs/#creating-an-epfs",
    "site_type": "Documentation",
    "content": "Introduction to EPFS | E2E Cloud Skip to main content On this page Introduction to EPFS Overview ​ EPFS (E2E Parallel File System) is a highly scalable and reliable parallel file system designed for large-scale High-Performance Computing (HPC) environments. It delivers exceptional performance by supporting parallel data access, making it ideal for handling massive datasets and numerous clients. High throughput : Supports multiple simultaneous clients. Scalability : Can handle petabytes of data and thousands of clients. Reliability : Uses robust mechanisms to ensure data integrity. How EPFS Works ​ Data Distribution : Data is striped across multiple OSSs, enabling parallel read/write operations. The striping pattern can be customized for specific use cases. Metadata Management : The MDS manages metadata, keeping operations like file creation and deletion fast. Parallelism : Clients access data in parallel from OSSs, minimizing bottlenecks. Advantages ​ High Speed : Parallel operations increase performance. Fault Tolerance : Data is replicated across nodes. Scalability : Designed for massive datasets and numerous clients. Note This feature is currently available only on AlmaLinux. Managing EPFS ​ Creating an EPFS ​ Navigate to the Storage > EPFS section in the left sidebar of the dashboard. Click Create . Provide the following details: Name : Enter a name for your EPFS. Plan : Select an appropriate plan. VPC : Choose the desired Virtual Private Cloud. Click Create EPFS . Your newly created EPFS will appear in the list. Accessing EPFS ​ Note Ensure that EPFS and the Virtual Machine (VM) are on the same network. Follow these steps to set up the client and mount EPFS: Download the Client Setup Script : Download the scripts.tar file. Transfer the script to the server : Use the scp command to copy the file into your server. scp <File-Location>/scripts.tar <username>@<server_ip>:/root/ Extract the tar file: Run the following command to extract the script: tar -xvf <file_name> Run the Client Setup Command: Execute the following script to set up the client: ./client_setup.sh tcp1056 10.5.17.... tcp Mount the EPFS: Use the following command to mount EPFS: mount -t lustre 10.20.56.8@tcp:/pfs0 <path_to_your_folder> Upgrading EPFS ​ Enhance your EPFS by increasing its memory capacity through the Upgrade EPFS feature. Click Upgrade under the Action menu. Select the desired upgraded plan and Confirm by clicking the Upgrade button. Your EPFS will be upgraded to the selected configuration. Deleting an EPFS ​ Select Delete from the Action menu. A warning message will notify you of permanent data loss. Confirm and proceed by clicking Delete. The selected EPFS storage will be removed. Overview How EPFS Works Advantages Managing EPFS Creating an EPFS Accessing EPFS Upgrading EPFS Deleting an EPFS",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/monitoring/",
    "site_type": "Software/Service Documentation",
    "content": "Event Monitoring | E2E Cloud Skip to main content Event Monitoring Event Monitoring introduces you to E2E Networks' robust alert monitoring service, designed to help developers and system administrators efficiently manage resource alerts. With Event Monitoring, you can create scalable and reliable alerts tailored to your needs, ensuring timely updates on resource statuses. Event Monitoring Dashboard Create and Manage Alerts User Groups Create your custom user groups.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Software/Service Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Software/Service Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Software/Service Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Software/Service Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Software/Service Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/",
    "site_type": "Cloud Services Platform",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Services Platform",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Services Platform",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Services Platform",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-indian-customers",
    "site_type": "Cloud Services Platform",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Services Platform",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/e2esecrets/",
    "site_type": "Documentation",
    "content": "E2E Secrets Management | E2E Cloud Skip to main content On this page E2E Secrets Management E2E Secrets Management (Vault as a Service) is a secure, end-to-end solution designed to manage, store, and access sensitive secrets such as API keys, passwords, certificates, and encryption keys. It provides a Vault as a Service model, abstracting the complexity of deploying and maintaining your own secret store infrastructure. Creating a Secret ​ Click the Create button to launch a new secret. Upgrading a Secret ​ Click the Upgrade icon next to the secret you wish to upgrade. Choose a desired plan and click the Upgrade Secrets button. Your secret will be successfully upgraded. Deleting a Secret ​ Click the Delete icon for the secret you want to remove. Confirm the action by clicking the Delete button. Logging In to Secret via CLI ​ Use the bao CLI tool to authenticate and interact with Secrets. Begin by exporting the necessary environment variables: # Set Vault environment variables export VAULT_ADDR='https://your-secret-url.com' export VAULT_TOKEN=<your-token> # Replace <your-token> with your actual E2E secret root token # Log in using the bao CLI bao login $Secret_TOKEN Once logged in, you can securely manage secrets, access policies, and other configurations via the CLI. Refer to the official bao CLI documentation for a complete list of available commands and usage examples. Creating a Secret Upgrading a Secret Deleting a Secret Logging In to Secret via CLI",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get#Responses",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams-Team_Id--projects/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Project ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/{Team_Id}/projects/ Request Security: API Key & Bearer Auth Path Parameters Team_Id integer required Team ID >= 0 Responses 200 Successful response with project details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 project_id integer Example: 124 project_name string Example: default-project description string or null Example: null created_by object created_at string<date-time> Example: 2023-03-22T05:27:47.892853Z updated_at string<date-time> Example: 2023-03-22T05:27:47.945762Z errors object Example: {} message string Example: Success Auth apikey : Token : Parameters Team_Id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/{Team_Id}/projects/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"project_id\" : 124 , 7 \"project_name\" : \"default-project\" , 8 \"description\" : null , 9 \"created_by\" : { 10 \"id\" : 19 , 11 \"name\" : \"shubham Chaturvedi\" , 12 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 13 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 14 } , 15 \"created_at\" : \"2023-03-22T05:27:47.892853Z\" , 16 \"updated_at\" : \"2023-03-22T05:27:47.945762Z\" 17 } 18 ] , 19 \"errors\" : { } , 20 \"message\" : \"Success\" 21 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get#Query-Parameters",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/users-iam-accounts/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight IAM Accounts get https://api.e2enetworks.com/myaccount/api/v1/gpu /users/iam-accounts/ Request Security: API Key & Bearer Auth Responses 200 Successful response with user details and roles Body application/json application/json code integer Example: 200 data array[object] id integer Example: 2421 owner object role string Example: Owner Auth apikey : Token : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/users/iam-accounts/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"id\" : 2421 , 6 \"owner\" : { 7 \"id\" : 3573 , 8 \"name\" : \"Nipun\" , 9 \"email\" : \"nipun.arora@e2enetworks.com\" , 10 \"username\" : \"nipun.arora@e2enetworks.com\" , 11 \"phone\" : null , 12 \"is_primary_contact\" : true , 13 \"primary_email\" : \"nipun.arora@e2enetworks.com\" , 14 \"currency\" : \"INR\" , 15 \"is_suspended\" : true 16 } , 17 \"role\" : \"Owner\" 18 } 19 ] 20 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Team ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/ Request Security: API Key & Bearer Auth Query Parameters active_iam integer Active IAM ID (To access contact person account) Find your Active IAM ID here >= 0 Responses 200 Successful response with team details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 team_name string Example: team-1 owner object created_by object description string Example: create a new team is_private boolean Example: false created_at string<date-time> Example: 2023-03-22T05:27:47.872560Z updated_at string<date-time> Example: 2024-07-26T13:58:08.210684Z Auth apikey : Token : Parameters active_iam : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"team_name\" : \"team-1\" , 7 \"owner\" : { 8 \"id\" : 19 , 9 \"name\" : \"shubham Chaturvedi\" , 10 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 11 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 12 } , 13 \"created_by\" : { 14 \"id\" : 19 , 15 \"name\" : \"shubham Chaturvedi\" , 16 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 17 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 18 } , 19 \"description\" : \"create a new team\" , 20 \"is_private\" : false , 21 \"created_at\" : \"2023-03-22T05:27:47.872560Z\" , 22 \"updated_at\" : \"2024-07-26T13:58:08.210684Z\" 23 } 24 ] 25 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/#/paths/teams-Team_Id--projects/get",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight Project ID get https://api.e2enetworks.com/myaccount/api/v1/gpu /teams/{Team_Id}/projects/ Request Security: API Key & Bearer Auth Path Parameters Team_Id integer required Team ID >= 0 Responses 200 Successful response with project details Body application/json application/json responses / 200 code integer Example: 200 data array[object] team_id integer Example: 88 project_id integer Example: 124 project_name string Example: default-project description string or null Example: null created_by object created_at string<date-time> Example: 2023-03-22T05:27:47.892853Z updated_at string<date-time> Example: 2023-03-22T05:27:47.945762Z errors object Example: {} message string Example: Success Auth apikey : Token : Parameters Team_Id* : Send API Request Request Sample: Shell / cURL curl --request GET \\ --url 'https://api.e2enetworks.com/myaccount/api/v1/gpu/teams/{Team_Id}/projects/?apikey=123' \\ --header 'Accept: application/json' \\ --header 'Authorization: Bearer 123' Response Example 1 { 2 \"code\" : 200 , 3 \"data\" : [ 4 { 5 \"team_id\" : 88 , 6 \"project_id\" : 124 , 7 \"project_name\" : \"default-project\" , 8 \"description\" : null , 9 \"created_by\" : { 10 \"id\" : 19 , 11 \"name\" : \"shubham Chaturvedi\" , 12 \"email\" : \"shubham.chaturvedi@e2enetworks.com\" , 13 \"username\" : \"shubham.chaturvedi@e2enetworks.com\" 14 } , 15 \"created_at\" : \"2023-03-22T05:27:47.892853Z\" , 16 \"updated_at\" : \"2023-03-22T05:27:47.945762Z\" 17 } 18 ] , 19 \"errors\" : { } , 20 \"message\" : \"Success\" 21 }",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "API Documentation",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/",
    "site_type": "Documentation",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/e2esecrets/",
    "site_type": "Software Documentation",
    "content": "E2E Secrets Management | E2E Cloud Skip to main content On this page E2E Secrets Management E2E Secrets Management (Vault as a Service) is a secure, end-to-end solution designed to manage, store, and access sensitive secrets such as API keys, passwords, certificates, and encryption keys. It provides a Vault as a Service model, abstracting the complexity of deploying and maintaining your own secret store infrastructure. Creating a Secret ​ Click the Create button to launch a new secret. Upgrading a Secret ​ Click the Upgrade icon next to the secret you wish to upgrade. Choose a desired plan and click the Upgrade Secrets button. Your secret will be successfully upgraded. Deleting a Secret ​ Click the Delete icon for the secret you want to remove. Confirm the action by clicking the Delete button. Logging In to Secret via CLI ​ Use the bao CLI tool to authenticate and interact with Secrets. Begin by exporting the necessary environment variables: # Set Vault environment variables export VAULT_ADDR='https://your-secret-url.com' export VAULT_TOKEN=<your-token> # Replace <your-token> with your actual E2E secret root token # Log in using the bao CLI bao login $Secret_TOKEN Once logged in, you can securely manage secrets, access policies, and other configurations via the CLI. Refer to the official bao CLI documentation for a complete list of available commands and usage examples. Creating a Secret Upgrading a Secret Deleting a Secret Logging In to Secret via CLI",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Software Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Software Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Software Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Software Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Software Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#frequently-asked-questions",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-indian-customers",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Platform Documentation/Support",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/network/overview/",
    "site_type": "documentation",
    "content": "Networking on E2E Cloud | E2E Cloud Skip to main content On this page Networking on E2E Cloud The networking section of the E2E Networks documentation provides detailed guidance on various aspects of network management and configuration. It covers topics such as Content Delivery Network (CDN) setup and management, Virtual Private Cloud (VPC) creation and usage, Reserved IP addresses , DNS settings , and firewall configurations. Additionally, it includes instructions on managing security groups , setting up custom reverse DNS, and utilizing tags for resource management. Key Topics Covered ​ Here's an overview of the key topics covered in the sections below: Content Delivery Network (CDN) Distribute data and static content globally with low latency. Virtual Private Cloud (VPC) Secure, isolated virtual network within a public cloud. Reserve IP Reserve a static IP address for long-term use. Domain Name System (DNS) Map IP addresses to human readable names. Firewall Monitor and control network traffic. Security Group Control inbound and outbound traffic to resources Key Topics Covered",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Nodes Documentation | E2E Cloud Skip to main content Nodes Documentation Welcome to E2E Cloud's Compute Nodes documentation! Here, you'll find everything you need to know about launching nodes through the MyAccount portal, configuring node settings, and managing security with tools like BitNinja. This guide also walks you through essential tasks such as creating and managing snapshots, importing custom images, and resolving common issues. Additionally, you'll learn to set up and manage monitoring alerts, interpret monitoring graphs, and install the Zabbix Agent on your server for effective monitoring. Features Multiple Compute Node Options Choose from Linux Virtual Nodes, Windows Virtual Nodes, Smart Dedicated Nodes, and High-Frequency CPU-Intensive nodes for optimized performance. Easy Node Deployment via MyAccount Portal Deploy, manage, and monitor compute nodes effortlessly through an intuitive web-based interface. API Support for Programmatic Management Automate node creation, scaling, and monitoring using E2E Networks’ API for seamless DevOps integration. Flexible OS Choices Deploy nodes with various operating systems like Ubuntu, CentOS, Debian, Windows Server, cPanel, Plesk, and Webuzo to suit different workloads. Multiple Performance-Tuned Plans Select from high-memory, CPU-intensive, and Smart Dedicated compute plans tailored for AI/ML, big data, and enterprise applications. See All Secure Access with SSH Keys & Password Management Use SSH-based authentication for Linux nodes and secure one-time password login for Windows nodes. Integrated Network & Security Benefit from Virtual Private Cloud (VPC), security groups, reserved IPs, and BitNinja security integration for robust protection. Backup & Snapshot Management Enable automated backups and create snapshots to ensure quick recovery and seamless scaling. Scalable Storage with Volume Attachments Attach additional storage volumes to compute nodes as needed, enabling flexible storage expansion. On-Demand & Committed Billing Pay per hour for flexible usage or opt for 365-day committed plans to save costs on long-term workloads. Real-Time Monitoring & Alerts Track CPU, memory, and network usage via MyAccount’s monitoring dashboard and set up alerts for performance insights. Zabbix Agent Integration Install Zabbix Agent on nodes to access detailed system analytics and proactive resource monitoring. Benefits Performance & Scalability High-speed compute nodes with Intel-based C3 series processors for maximum efficiency. Dedicated Smart Nodes ensure higher performance with reserved network ports. Multiple configurations allow seamless scaling of vCPUs and memory based on workload needs. Cost-Effective Solutions Transparent, predictable pricing with hourly and committed billing models. Optimized cost-performance ratio with specialized compute and memory-intensive node categories. Simplified Deployment & Management Easy-to-use MyAccount portal for managing nodes with a web-based UI. API Access for programmatic control of instances. Quick provisioning with automated setup and pre-configured OS images. Enhanced Security BitNinja Security for proactive protection against threats. SSH key authentication for improved access security. VPC and security group integration to define network access policies. Reliable Backup & Disaster Recovery Automated backup solutions to ensure data protection. Custom snapshots for easy restoration and replication. Volume attachments for flexible data storage expansion. See All Comprehensive Monitoring & Alerts Built-in monitoring graphs for real-time insights into node performance. Zabbix Agent support for detailed monitoring and alert setup. Performance tracking to optimize resource utilization. Virtual Compute Nodes Compute nodes, their deployment and management. Monitoring Set up monitoring alerts, monitoring graphs and Zabbix agent. Active Directory Centralized management of user identities and access permissions.",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3cmdwindows/",
    "site_type": "Documentation",
    "content": "Setting up S3cmd on Windows | E2E Cloud Skip to main content On this page Setting up S3cmd on Windows S3cmd is a popular cross-platform command-line tool for managing S3-compatible object stores. In this tutorial, we will see how to configure and use S3cmd with E2E Object Storage on Windows Server. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer here . Access and Secret keys with permissions for the target bucket. Windows system for installing s3cmd CLI. Step 1: Download and Install Python 2.x ​ S3cmd requires Python 2.7 or a higher version to run. You can install it here . Python 3 is currently not supported. After installation, open the command terminal and add the Python directory to your global PATH variable with the command below. set PATH \"%PATH%;C:\\Python27\\\" Note Here python2.7 was installed, you need to change python version in above command as per your installation version. Re-open the command terminal to utilize the new environment variable added above Verify the installation with below command C:\\>python --version Python 2.7.17 C:\\> Installing S3cmd ​ You can download the latest s3cmd source code from s3cmd official page and extract it to C:\\s3cmd location. After extracting the source code, navigate to the folder to which you downloaded s3cmd and run the command below to set up. python setup.py install Configure s3cmd ​ Please keep the below information handy as we will need it during the process. Access Key : xxxxxxxxxxxxxxxxxxxx Secret Key : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx S3 Endpoint : objectstore.e2enetworks.net Bucket URL : %(bucket)s.objectstore.e2enetworks.net Default Region: Leave blank (skip) Go to the path where s3cmd was downloaded To start configuration in s3cmd, enter the following command: python s3cmd --configure Below is the snapshot of installation wizard. Follow the process in similar way to configure EOS with s3cmd CLI. Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region [US]: Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: objectstore.e2enetworks.net Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: % (bucket)s.objectstore.e2enetworks.net Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: New settings: Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region: US S3 Endpoint: objectstore.e2enetworks.net DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.objectstore.e2enetworks.net Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: True HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Note If you test the access with supplied credentials,you will get an error Test failed,Are you sure your keys have s3 :ListallMybuckets permission You can ignore this error since you are using this with EOS bucket Test access with configured credentials ​ List the contents of target bucket (eg. e2e-test) using a command like below. Please note the access and secret key that you had chosen during interactive/manual setup must have access to this bucket.Make sure you are on the path where s3cmd was downloaded. python s3cmd ls s3://e2e-test You may also test by moving local file to your target bucket (e.g. e2e-test) using below command C:\\s3cmd>python s3cmd sync \"C:\\e2ewindowstest.txt\" s3://e2e-test/ upload: 'C:\\e2ewindowstest.txt' -> 's3://e2e-test/e2ewindowstest.txt' (0 bytes in 0.0 seconds, -1.00 B/s) [1 of 1] Conclusion ​ We have now successfully configured s3cmd to work with E2E Object Service. The complete user guide on the usage of s3cmd is available here . Prerequisites Step 1: Download and Install Python 2.x Installing S3cmd Configure s3cmd Test access with configured credentials Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3cmdwindows/#test-access-with-configured-credentials",
    "site_type": "Documentation",
    "content": "Setting up S3cmd on Windows | E2E Cloud Skip to main content On this page Setting up S3cmd on Windows S3cmd is a popular cross-platform command-line tool for managing S3-compatible object stores. In this tutorial, we will see how to configure and use S3cmd with E2E Object Storage on Windows Server. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer here . Access and Secret keys with permissions for the target bucket. Windows system for installing s3cmd CLI. Step 1: Download and Install Python 2.x ​ S3cmd requires Python 2.7 or a higher version to run. You can install it here . Python 3 is currently not supported. After installation, open the command terminal and add the Python directory to your global PATH variable with the command below. set PATH \"%PATH%;C:\\Python27\\\" Note Here python2.7 was installed, you need to change python version in above command as per your installation version. Re-open the command terminal to utilize the new environment variable added above Verify the installation with below command C:\\>python --version Python 2.7.17 C:\\> Installing S3cmd ​ You can download the latest s3cmd source code from s3cmd official page and extract it to C:\\s3cmd location. After extracting the source code, navigate to the folder to which you downloaded s3cmd and run the command below to set up. python setup.py install Configure s3cmd ​ Please keep the below information handy as we will need it during the process. Access Key : xxxxxxxxxxxxxxxxxxxx Secret Key : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx S3 Endpoint : objectstore.e2enetworks.net Bucket URL : %(bucket)s.objectstore.e2enetworks.net Default Region: Leave blank (skip) Go to the path where s3cmd was downloaded To start configuration in s3cmd, enter the following command: python s3cmd --configure Below is the snapshot of installation wizard. Follow the process in similar way to configure EOS with s3cmd CLI. Enter new values or accept defaults in brackets with Enter. Refer to user manual for detailed description of all options. Access key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables. Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region [US]: Use \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3. S3 Endpoint [s3.amazonaws.com]: objectstore.e2enetworks.net Use \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used if the target S3 system supports dns based buckets. DNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.s3.amazonaws.com]: % (bucket)s.objectstore.e2enetworks.net Encryption password is used to protect your files from reading by unauthorized persons while in transfer to S3 Encryption password: Path to GPG program [/usr/bin/gpg]: When using secure HTTPS protocol all communication with Amazon S3 servers is protected from 3rd party eavesdropping. This method is slower than plain HTTP, and can only be proxied with Python 2.7 or newer Use HTTPS protocol [Yes]: On some networks all internet access must go through a HTTP proxy. Try setting it here if you can't connect to S3 directly HTTP Proxy server name: New settings: Access Key: xxxxxxxxxxxxxxxxxxxxx Secret Key: xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx Default Region: US S3 Endpoint: objectstore.e2enetworks.net DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.objectstore.e2enetworks.net Encryption password: Path to GPG program: /usr/bin/gpg Use HTTPS protocol: True HTTP Proxy server name: HTTP Proxy server port: 0 Test access with supplied credentials? [Y/n] n Save settings? [y/N] y Note If you test the access with supplied credentials,you will get an error Test failed,Are you sure your keys have s3 :ListallMybuckets permission You can ignore this error since you are using this with EOS bucket Test access with configured credentials ​ List the contents of target bucket (eg. e2e-test) using a command like below. Please note the access and secret key that you had chosen during interactive/manual setup must have access to this bucket.Make sure you are on the path where s3cmd was downloaded. python s3cmd ls s3://e2e-test You may also test by moving local file to your target bucket (e.g. e2e-test) using below command C:\\s3cmd>python s3cmd sync \"C:\\e2ewindowstest.txt\" s3://e2e-test/ upload: 'C:\\e2ewindowstest.txt' -> 's3://e2e-test/e2ewindowstest.txt' (0 bytes in 0.0 seconds, -1.00 B/s) [1 of 1] Conclusion ​ We have now successfully configured s3cmd to work with E2E Object Service. The complete user guide on the usage of s3cmd is available here . Prerequisites Step 1: Download and Install Python 2.x Installing S3cmd Configure s3cmd Test access with configured credentials Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/database/",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Database | E2E Cloud Skip to main content On this page Database Database Management ​ This section of our documentation explains database management or our DBaaS (Database as a Service) offering, and has details on creation, configuration, and maintenance of databases. Our service focuses on providing scalable, secure, and efficient database infrastructure, tailored to be highly performant. You'll learn how to manage databases on the MyAccount portal or E2E Cloud. We provide fully-managed database services such as MySQL, PostgreSQL, Kafka, Valkey, MariaDB, and Cassandra, helping you set up, maintain, manage, and administer your databases seamlessly. E2E DBaaS Features Feature MySQL MariaDB PostgreSQL Cassandra Valkey Kafka Fully Managed DBaaS ✓ ✓ ✓ ✓ ✓ ✓ Relational Database ✓ ✓ ✓ ✗ ✗ ✗ NoSQL Database ✗ ✗ ✗ ✓ ✓ ✗ Event Streaming ✗ ✗ ✗ ✗ ✗ ✓ High Scalability ✓ ✓ ✓ ✓ ✓ ✓ Automatic Failover ✓ ✓ ✓ ✓ ✓ ✓ Replication Support ✓ ✓ ✓ ✓ ✓ ✓ In-Memory Storage ✗ ✗ ✗ ✗ ✓ ✗ Supports Complex Queries ✓ ✓ ✓ ✗ ✗ ✗ Data Partitioning ✗ ✗ ✗ ✓ ✗ ✓ Multi-Datacenter Support ✗ ✗ ✗ ✓ ✗ ✓ Read Replica Support ✓ ✓ ✓ ✗ ✗ ✗ Snapshot & Backup Support ✓ ✓ ✓ ✓ ✗ ✗ Key Benefits of using E2E DBaaS MySQL Fully managed database service, eliminating the need for manual installation and maintenance. Supports high performance and scalability, making it ideal for web applications. Secure with firewall restrictions, ensuring that only authorized hosts can connect. Easy administration through the MyAccount portal with quick provisioning. MariaDB Provides a seamless, fully managed experience with automated maintenance and backups. Offers high performance and scalability, making it suitable for WordPress and other CMS applications. Cost-efficient and easy to upgrade based on usage requirements. Reliable with automated failover and replication support. PostgreSQL Highly extensible and supports complex SQL queries for advanced data management. Ensures data integrity and fault tolerance, making it reliable for enterprise applications. Can handle large and small datasets efficiently with built-in scalability. Fully managed DBaaS automates provisioning, patching, and maintenance tasks. Cassandra Designed for high availability with no single point of failure, ensuring reliability. Scales horizontally without downtime, making it ideal for big data and global applications. Supports multi-datacenter replication for disaster recovery and high availability. Optimized for high write and read throughput, handling large volumes of data efficiently. Valkey High-speed in-memory data storage ensures ultra-fast data access. Supports caching, message queues, and real-time analytics for performance optimization. Offers clustering and high availability for scalable applications. Supports various data structures, enhancing flexibility for different use cases. Kafka Enables real-time data streaming and event-driven architectures. Highly scalable with partitioned logs for parallel processing. Fault-tolerant and durable, ensuring reliable data storage and delivery. Supports low-latency, high-throughput messaging, making it ideal for big data applications. DBaaS Overview Learn more about Database Management and its benefits Manage your Database Instance Guide to Managing Your Database on E2E Cloud Parameter Group Learn more about Parameter Group Use WordPress Install and Setup WordPress MySQL Learn more about MySQL MariaDB Learn more about MariaDB PostgreSQL Learn more about PostgreSQL Cassandra Learn more about Cassandra Valkey New Learn more about Valkey Kafka New Learn more about Kafka OpenSearch New Learn more about Opensearch Plans ​ Committed Database Flexible and cost efficient plans Database Management Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/database/#plans",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Database | E2E Cloud Skip to main content On this page Database Database Management ​ This section of our documentation explains database management or our DBaaS (Database as a Service) offering, and has details on creation, configuration, and maintenance of databases. Our service focuses on providing scalable, secure, and efficient database infrastructure, tailored to be highly performant. You'll learn how to manage databases on the MyAccount portal or E2E Cloud. We provide fully-managed database services such as MySQL, PostgreSQL, Kafka, Valkey, MariaDB, and Cassandra, helping you set up, maintain, manage, and administer your databases seamlessly. E2E DBaaS Features Feature MySQL MariaDB PostgreSQL Cassandra Valkey Kafka Fully Managed DBaaS ✓ ✓ ✓ ✓ ✓ ✓ Relational Database ✓ ✓ ✓ ✗ ✗ ✗ NoSQL Database ✗ ✗ ✗ ✓ ✓ ✗ Event Streaming ✗ ✗ ✗ ✗ ✗ ✓ High Scalability ✓ ✓ ✓ ✓ ✓ ✓ Automatic Failover ✓ ✓ ✓ ✓ ✓ ✓ Replication Support ✓ ✓ ✓ ✓ ✓ ✓ In-Memory Storage ✗ ✗ ✗ ✗ ✓ ✗ Supports Complex Queries ✓ ✓ ✓ ✗ ✗ ✗ Data Partitioning ✗ ✗ ✗ ✓ ✗ ✓ Multi-Datacenter Support ✗ ✗ ✗ ✓ ✗ ✓ Read Replica Support ✓ ✓ ✓ ✗ ✗ ✗ Snapshot & Backup Support ✓ ✓ ✓ ✓ ✗ ✗ Key Benefits of using E2E DBaaS MySQL Fully managed database service, eliminating the need for manual installation and maintenance. Supports high performance and scalability, making it ideal for web applications. Secure with firewall restrictions, ensuring that only authorized hosts can connect. Easy administration through the MyAccount portal with quick provisioning. MariaDB Provides a seamless, fully managed experience with automated maintenance and backups. Offers high performance and scalability, making it suitable for WordPress and other CMS applications. Cost-efficient and easy to upgrade based on usage requirements. Reliable with automated failover and replication support. PostgreSQL Highly extensible and supports complex SQL queries for advanced data management. Ensures data integrity and fault tolerance, making it reliable for enterprise applications. Can handle large and small datasets efficiently with built-in scalability. Fully managed DBaaS automates provisioning, patching, and maintenance tasks. Cassandra Designed for high availability with no single point of failure, ensuring reliability. Scales horizontally without downtime, making it ideal for big data and global applications. Supports multi-datacenter replication for disaster recovery and high availability. Optimized for high write and read throughput, handling large volumes of data efficiently. Valkey High-speed in-memory data storage ensures ultra-fast data access. Supports caching, message queues, and real-time analytics for performance optimization. Offers clustering and high availability for scalable applications. Supports various data structures, enhancing flexibility for different use cases. Kafka Enables real-time data streaming and event-driven architectures. Highly scalable with partitioned logs for parallel processing. Fault-tolerant and durable, ensuring reliable data storage and delivery. Supports low-latency, high-throughput messaging, making it ideal for big data applications. DBaaS Overview Learn more about Database Management and its benefits Manage your Database Instance Guide to Managing Your Database on E2E Cloud Parameter Group Learn more about Parameter Group Use WordPress Install and Setup WordPress MySQL Learn more about MySQL MariaDB Learn more about MariaDB PostgreSQL Learn more about PostgreSQL Cassandra Learn more about Cassandra Valkey New Learn more about Valkey Kafka New Learn more about Kafka OpenSearch New Learn more about Opensearch Plans ​ Committed Database Flexible and cost efficient plans Database Management Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/database/valkey/",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Valkey | E2E Cloud Skip to main content On this page Valkey What is Valkey ​ Valkey is a high-performance key/value datastore designed to efficiently handle a range of workloads, including caching, message queues, and primary database functions. It offers flexible deployment options as both a standalone daemon and a clustered system, with robust features for replication and high availability to ensure optimal performance and reliability. It is a versatile data structure store that offers excellent performance, flexibility, and a rich set of features. It's a valuable tool for applications that require efficient handling of various data structures and high-speed access. Key Features ​ Rich Data Structures : Supports a wide range of native data structures, including strings, numbers, hashes, lists, sets, sorted sets, bitmaps, hyperloglogs, and more. In-Memory Performance : Designed for high-speed operations, leveraging in-memory storage for quick data access. Expressive Commands : Provides a comprehensive set of commands for operating on data structures, enabling efficient data manipulation. Native Extensibility : Supports Lua scripting for creating custom commands and data types, enhancing flexibility. Clustering and High Availability : Can be run as either a standalone daemon or in a cluster, with options for replication and high availability. Plugin System : Allows for the creation of custom modules to extend Valkey's functionality with new commands, data types, and more. Use Cases of Valkey ​ Caching : Valkey can be used as a high-performance cache for frequently accessed data, improving application response times. Message Queues : It can serve as a reliable and scalable message queue for asynchronous communication between components. Primary Database : Valkey can be used as a primary database for applications that require high performance and in-memory data storage. Real-time Analytics : It can be used for real-time data processing and analytics due to its high-speed capabilities. How to create Valkey DBaaS ​ To proceed, click the \"Get Started\" button or the \"Add\" icon located in the upper-right corner of the screen, as illustrated in the following images: After that, select the Valkey cluster and click on \"Select Plan\" to continue. Now select the plan according to your requirement. Now fill all the details and click on the \"Launch Cluster\" button. After the cluster is created, you can see its details on the DBaaS listing page. Actions Stop ​ To stop the cluster, click on the three dots and then select the Stop button. Start ​ To start the cluster, click on the three dots and then click on the Start button. Restart ​ To restart the cluster, click on the Restart button. Expand Disk Size ​ To expand disk size, click on the Expand Disk button. Delete ​ To delete the cluster, click on the Delete button. Whitelist IP ​ To whitelist an IP, click on the Add button in the Whitelisted IP tab . Users ​ To add a user to the Valkey database, click on the USERS tab and click on the Add button. Snapshot ​ To take a snapshot, click on the Take Snapshot button after selecting the Snapshots tab . Read Replica ​ To add a Read Replica, go to the Read Replica tab and click on the Add button. Monitoring ​ To see the monitoring details, click on the Monitoring tab . Alerts ​ To check the alerts, click on the Alerts tab . To configure Valkey , kindly click on the following link: Click Here To connect to your database node using Valkey command line ​ Once your database has been provisioned and is in running status, you can get the database connectivity information on the dashboard under the connection details. Public IPv4 Username Password Port Enter the following command at a command prompt on your local or client desktop to connect to a Valkey database: valkey-cli -u \"redis://<'username'>:<'password'>@<Public_IP>:6379/<\"dbaas name\">\" warning When including the password in the connection string, ensure it's properly URL encoded. This means replacing special characters like '@' with their corresponding URL-encoded equivalents. For example, '@' becomes '%40', etc. What is Valkey Key Features Use Cases of Valkey How to create Valkey DBaaS Stop Start Restart Expand Disk Size Delete Whitelist IP Users Snapshot Read Replica Monitoring Alerts To connect to your database node using Valkey command line",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Database as a Service (DBaaS) Provider",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/security/",
    "site_type": "Documentation",
    "content": "Security | E2E Cloud Skip to main content Security The Security section of our documentation addresses critical aspects of network and data security. It covers a range of topics aimed at enhancing the safety and integrity of our users' data and network infrastructure. The topics covered in the sections below show you how to configure firewall, bitninja, ssh key management, setting password policies, and general best practices. Firewall Learn about Firewall Bitninja Learn About Bitninja Best Practice Learn About Best Practices SSH Key Management Learn about SSH Key Management Audit Logs Learn About audit logs Password Policy Learn About Password Policy 2-Factor Authentication 2FA and Why is it mandatory to use? Abuse notification process Learn about Abuse notification process Key Based SSH Why is Key based SSH Secure Maldetect Scan Scanning for malware by using Maldetect Scan Enable Disable Password-based Authentication Learn About Password-based Authentication",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/security/#__docusaurus_skipToContent_fallback",
    "site_type": "Documentation",
    "content": "Security | E2E Cloud Skip to main content Security The Security section of our documentation addresses critical aspects of network and data security. It covers a range of topics aimed at enhancing the safety and integrity of our users' data and network infrastructure. The topics covered in the sections below show you how to configure firewall, bitninja, ssh key management, setting password policies, and general best practices. Firewall Learn about Firewall Bitninja Learn About Bitninja Best Practice Learn About Best Practices SSH Key Management Learn about SSH Key Management Audit Logs Learn About audit logs Password Policy Learn About Password Policy 2-Factor Authentication 2FA and Why is it mandatory to use? Abuse notification process Learn about Abuse notification process Key Based SSH Why is Key based SSH Secure Maldetect Scan Scanning for malware by using Maldetect Scan Enable Disable Password-based Authentication Learn About Password-based Authentication",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/work_cli/",
    "site_type": "documentation",
    "content": "Working with CLI | E2E Cloud Skip to main content On this page Working with CLI This tutorial contains steps for using the S3-compatible CLI with the Object Store. We recommend using MinIO CLI ( mc ) for the best experience. Download MinIO Client (mc) ​ Linux (64-bit Intel) : Download Linux (64-bit PPC) : Download Windows (64-bit) : Download MacOS : brew install minio/stable/mc For other methods, visit MinIO documentation here . Run the Client ​ Check that the client is downloaded correctly by running the following command from the directory where the binary file is saved. macOS : mc --help Windows : mc.exe --help GNU/Linux : chmod +x mc ./mc --help Note Add mc to the environment path You may optionally add mc to your environment path for further convenience. For example: GNU/Linux or macOS : mv mc /usr/local/bin ./mc --help Save Storage Credentials ​ Object Store supports the creation of multiple access credentials (keys) from the storage section in My Account. After generating or creating an access key, you will be provided with an mc config command: mc alias set <ALIAS_NAME> <URL> <ACCESS_KEY> <SECRET_KEY> access_key : You can generate an access key from My Account > Storage > Object Storage > Manage Access . secret_key : Obtain this the same way as the access key. key_name : This can be any meaningful name, something easy to remember as you will use this with every mc command. Note Here is an example: mc alias set test2 https://objectstore.e2enetworks.net FADSF2322FADF23 ADF23FASDFASDF342ASDF The above command will save a storage credential with the name wp_creds in your system. From here on, you can access bucket contents granted to this access key with the use of the string wp_creds. This way, you don't have to pass credentials (access/secret key) each time you run the mc command, instead you refer to wp_creds. Note If you are using mc version earlier than RELEASE.2025-05-21T01-59-54Z then use below command: mc config host add <ACCESS_KEY_NAME> <URL> <ACCESS_KEY> <SECRET_KEY> Here is an example: mc config host add ESTWE https://objectstore.e2enetworks.net 4SG71BPL234234FBTZDQS7L 4F13TOK3PNIMJWR5RMX2323JKULVAX7E4M5PGNC3OI8M List Objects ​ The following command lists the objects in a storage bucket named wp_bucket . Here, the access key wp_creds has been granted permission to wp_bucket from the storage browser in my account. ./mc ls wp_creds/wp_bucket/ Under the hood, the mc uses the saved credentials wp_creds to connect to the E2E Object Store. List Buckets ​ Object store currently does not support listing buckets from CLI. You can view your buckets from storage browser (My account > Storage ). Make Bucket ​ Object store currently does not support creating buckets from CLI. You can create your buckets from storage browser (My account > Storage ). View Object Content ​ Use cat command to view contents of objects in your bucket. You can also use head command to display top few lines of an object. To view terms.txt from customer_terms directory in wp_bucket : mc cat wp_creds/wp_bucket/customer_terms/terms.txt To display first 5 lines from terms.txt : mc head -n 5 wp_creds/wp_bucket/customer_terms/terms.txt Pipe Content ​ You can use pipe command to write contents directly to E2E Object store from command line. To stream MySQL Database dump to Object store directly: mysqldump -u root -p ***** customer_db | mc pipe wp_creds/wp_bucket/customers/backup.sql Copy or Upload content ​ You can copy content from local system to object store using cp command. The copy operations to object store are verified with MD5SUM checksums. Interrupted or failed attempts can be resumed from the point of failure. To copy customer terms.txt to customer_terms path (created if does not exist) in wp_bucket : mc cp terms.txt wp_creds/wp_bucket/customer_terms/terms.txt To copy a folder recursively: mc cp —recursive local_dir wp_creds/wp_bucket/ Remove Content ​ Use rm command to delete file or object. To remove a terms.txt from wp_bucket/customer_terms: mc rm wp_creds/wp_bucket/customer_terms/terms.txt To remove all objects from a bucket : mc rm —recursive —force wp_creds/wp_bucket To remove all incomplete uploaded files for an object: mc rm —incomplete wp_creds/wp_bucket/terms.txt Bucket Status & Object Utilities ​ Check Bucket Status ​ mc ready <bucket-path> mc ping <bucket-path> --count 4 Check Object Size ​ mc du <bucket-path> Search for an Object by Name ​ mc find <bucket-path> | find \"<file-name>\" Generate a Pre-signed URL for Download ​ mc share download <object-path> --expire=<hours> Check Versioning Status of Objects ​ mc ls --recursive --versions <bucket-path> Update mc client ​ To update your mc client to the latest version mc update Note For source based installations of mc client the mc update command does not support update notifications. Share Content ​ Object store does not support sharing configuration from CLI. To enable a bucket for public or anonymous upload and download, you can visit the bucket permissions tab in storage browser (my account). Unsupported Commands ​ Currently we do not support the following commands offered by mc. mirror watch policy admin config Object store is evolving project, so you can expect these in near future. In case any of these commands are limiting your workflow then please write to us at cloud-platform@e2networks.com . Download MinIO Client (mc) Run the Client Save Storage Credentials List Objects List Buckets Make Bucket View Object Content Pipe Content Copy or Upload content Remove Content Bucket Status & Object Utilities Check Bucket Status Check Object Size Search for an Object by Name Generate a Pre-signed URL for Download Check Versioning Status of Objects Update mc client Share Content Unsupported Commands",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/work_cli/#__docusaurus_skipToContent_fallback",
    "site_type": "documentation",
    "content": "Working with CLI | E2E Cloud Skip to main content On this page Working with CLI This tutorial contains steps for using the S3-compatible CLI with the Object Store. We recommend using MinIO CLI ( mc ) for the best experience. Download MinIO Client (mc) ​ Linux (64-bit Intel) : Download Linux (64-bit PPC) : Download Windows (64-bit) : Download MacOS : brew install minio/stable/mc For other methods, visit MinIO documentation here . Run the Client ​ Check that the client is downloaded correctly by running the following command from the directory where the binary file is saved. macOS : mc --help Windows : mc.exe --help GNU/Linux : chmod +x mc ./mc --help Note Add mc to the environment path You may optionally add mc to your environment path for further convenience. For example: GNU/Linux or macOS : mv mc /usr/local/bin ./mc --help Save Storage Credentials ​ Object Store supports the creation of multiple access credentials (keys) from the storage section in My Account. After generating or creating an access key, you will be provided with an mc config command: mc alias set <ALIAS_NAME> <URL> <ACCESS_KEY> <SECRET_KEY> access_key : You can generate an access key from My Account > Storage > Object Storage > Manage Access . secret_key : Obtain this the same way as the access key. key_name : This can be any meaningful name, something easy to remember as you will use this with every mc command. Note Here is an example: mc alias set test2 https://objectstore.e2enetworks.net FADSF2322FADF23 ADF23FASDFASDF342ASDF The above command will save a storage credential with the name wp_creds in your system. From here on, you can access bucket contents granted to this access key with the use of the string wp_creds. This way, you don't have to pass credentials (access/secret key) each time you run the mc command, instead you refer to wp_creds. Note If you are using mc version earlier than RELEASE.2025-05-21T01-59-54Z then use below command: mc config host add <ACCESS_KEY_NAME> <URL> <ACCESS_KEY> <SECRET_KEY> Here is an example: mc config host add ESTWE https://objectstore.e2enetworks.net 4SG71BPL234234FBTZDQS7L 4F13TOK3PNIMJWR5RMX2323JKULVAX7E4M5PGNC3OI8M List Objects ​ The following command lists the objects in a storage bucket named wp_bucket . Here, the access key wp_creds has been granted permission to wp_bucket from the storage browser in my account. ./mc ls wp_creds/wp_bucket/ Under the hood, the mc uses the saved credentials wp_creds to connect to the E2E Object Store. List Buckets ​ Object store currently does not support listing buckets from CLI. You can view your buckets from storage browser (My account > Storage ). Make Bucket ​ Object store currently does not support creating buckets from CLI. You can create your buckets from storage browser (My account > Storage ). View Object Content ​ Use cat command to view contents of objects in your bucket. You can also use head command to display top few lines of an object. To view terms.txt from customer_terms directory in wp_bucket : mc cat wp_creds/wp_bucket/customer_terms/terms.txt To display first 5 lines from terms.txt : mc head -n 5 wp_creds/wp_bucket/customer_terms/terms.txt Pipe Content ​ You can use pipe command to write contents directly to E2E Object store from command line. To stream MySQL Database dump to Object store directly: mysqldump -u root -p ***** customer_db | mc pipe wp_creds/wp_bucket/customers/backup.sql Copy or Upload content ​ You can copy content from local system to object store using cp command. The copy operations to object store are verified with MD5SUM checksums. Interrupted or failed attempts can be resumed from the point of failure. To copy customer terms.txt to customer_terms path (created if does not exist) in wp_bucket : mc cp terms.txt wp_creds/wp_bucket/customer_terms/terms.txt To copy a folder recursively: mc cp —recursive local_dir wp_creds/wp_bucket/ Remove Content ​ Use rm command to delete file or object. To remove a terms.txt from wp_bucket/customer_terms: mc rm wp_creds/wp_bucket/customer_terms/terms.txt To remove all objects from a bucket : mc rm —recursive —force wp_creds/wp_bucket To remove all incomplete uploaded files for an object: mc rm —incomplete wp_creds/wp_bucket/terms.txt Bucket Status & Object Utilities ​ Check Bucket Status ​ mc ready <bucket-path> mc ping <bucket-path> --count 4 Check Object Size ​ mc du <bucket-path> Search for an Object by Name ​ mc find <bucket-path> | find \"<file-name>\" Generate a Pre-signed URL for Download ​ mc share download <object-path> --expire=<hours> Check Versioning Status of Objects ​ mc ls --recursive --versions <bucket-path> Update mc client ​ To update your mc client to the latest version mc update Note For source based installations of mc client the mc update command does not support update notifications. Share Content ​ Object store does not support sharing configuration from CLI. To enable a bucket for public or anonymous upload and download, you can visit the bucket permissions tab in storage browser (my account). Unsupported Commands ​ Currently we do not support the following commands offered by mc. mirror watch policy admin config Object store is evolving project, so you can expect these in near future. In case any of these commands are limiting your workflow then please write to us at cloud-platform@e2networks.com . Download MinIO Client (mc) Run the Client Save Storage Credentials List Objects List Buckets Make Bucket View Object Content Pipe Content Copy or Upload content Remove Content Bucket Status & Object Utilities Check Bucket Status Check Object Size Search for an Object by Name Generate a Pre-signed URL for Download Check Versioning Status of Objects Update mc client Share Content Unsupported Commands",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-international-customers",
    "site_type": "Cloud Services Platform",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Services Platform",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/myaccount_faq/",
    "site_type": "Cloud Services Platform",
    "content": "FAQs | E2E Cloud Skip to main content On this page E2E Networks International Customer Validation Process FAQs Information/Documents Needed from International Customers for Customer Validation ​ In line with the recent CERT-In directions issued by the Indian Computer Emergency Response Team (“CERT-In”) under sub-section (6) of section 70B of the Information Technology Act, 2000 relating to information security practices, procedure, prevention, response and reporting of cyber incidents for Safe & Trusted Internet dated April 28, 2022 (available at link CERT-In Directions ), the Data Centres, Virtual Private Server (VPS) providers, Cloud Service providers and Virtual Private Network Service (VPN Service) providers, shall be required to inter alia maintain the validated contact details, name and address(es) of their subscribers. Accordingly, in order to enable us to complete your customer validation, you are requested to provide the following documents to us: A) If You Have Signed Up as an Individual: ​ Copy of any one identity proof document like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. B) If You Have Signed Up as an Organization: ​ Copy of any one identity proof like Tax ID, Registration Certificate, Incorporation Document for the Organization, etc. Copy of any one address proof like utility bill (not more than 2 months old), bank statement, Registration Certificate containing the address for the organization, etc. Name and contact details (Email and Mobile) of the authorized official of the Organization. Copy of any one identity proof document of the authorized official like Passport, Driving License, Voter’s ID card, Social Security Card, etc. Copy of any one address proof of the authorized official like utility bill (not more than 2 months old), bank statement, Passport, Driving License, Voter’s ID card, etc. Your account activation may take up to 3 business days from the date of receipt of such information to the satisfaction of our risk-assessment team. In case of any queries, you may contact our sales team at 011-4084-4965 from 10.00 AM IST to 8.00 PM IST, Monday to Friday. Information/Documents Needed from International Customers for Customer Validation A) If You Have Signed Up as an Individual: B) If You Have Signed Up as an Organization:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/International_customer_Signup/",
    "site_type": "Cloud Services Platform",
    "content": "For International Customer | E2E Cloud Skip to main content On this page For International Customer Sign Up with Foreign Customer as Organization ​ Navigate to URL https://myaccount.e2enetworks.com/accounts/login For a new user, click on Sign up to begin the registration process. Fill in all the required details and click on the Sign Up button. After filling in all the details, complete OTP verification using the registered phone number and email, then click on the Verify button. After OTP verification, the Billing information page will open, and the user needs to fill in the required fields. Note: We don’t ask for GSTIN and PAN in the case of Foreign customers. We only ask for VAT/TAX ID in the case of an Organization, and that field is not mandatory as of now. After filling in all details, click Validate Payment to proceed further. Skip Validation ​ If the user clicks the skip button, another pop-up will appear, and the customer has to click on Skip validation . A message screen will pop up if the validation is skipped initially. Note After skip verification user will be able to use myaccount but only for 20 days and a warning message will be displayed on their myaccount dashboard the warning message will be like this (Your customer validation process is pending. Please complete validation before the date(like 2023-03-6) to use uninterrupted services. Click here to complete your customer validation). If the user will not complete their customer validation within 20 days then we will suspend his account after 20 days. For suspending we will send a first reminder on the 4th day after SignUp and a second reminder we will send on the 7th day after registration and then 3rd or final reminder will be on the 9th day But still, the customer will not complete his validation after 10 days his account will be suspended. Now after a few days of using services, customer wants to validate his account then he will have to click on the ‘Click here’ link. After clicking on the link a pop-up will appear and show a message like stripe-based validation for the services for E2E networks Ltd. Here customer chooses Trouble complete on mobile verification or Continue on this device. When customer choose mobile verification click on complete on mobile verification. After clicking on verification button then it shows multiple option like using QR Code , SMS , email and using link option. Using QR Code: Using SMS: Using Email: Using Link: When Customer Chooses \"Continue on This Device\": Provide Photo ID Sign Up with Foreign Customer as Organization Skip Validation",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/GettingStarted/#signup-process-for-indian-customers",
    "site_type": "Cloud Services Platform",
    "content": "SignUp Process and Myaccount Dashboard Access | E2E Cloud Skip to main content On this page SignUp Process and Myaccount Dashboard Access Myaccount is the entry point to E2E Networks' E2E Cloud platform, which gives you access to the Myaccount dashboard where you can manage your cloud resources, team, billing and payments, and everything else. The registration and sign up process for a new Indian customer is different from an international one, so please follow the right guidelines below depending on your business geography. SignUp Process for Indian Customers ​ The SignUp process for Indian organizations differs from that of Indian individuals . In the case of Indian organizations, you would need to provide a GSTIN, billing address, organization's PAN, and undergo a simple payment verification process. For Indian individuals, PAN and Aadhaar are required, along with billing address and payment details. SignUp Process for Indian organizations . SignUp Process for Indian individuals . SignUp Process for International Customers ​ The SignUp process for International customers involves filling out the billing address, VAT / TAX ID if available, and payment card validation. Once this is complete, there's a simple customer validation process. Follow the link below for more. SignUp Process for International Customers Frequently Asked Questions ​ To understand why we need to ensure that customers go through a validation process, please read through the FAQs here for Indian customers , and the ones here for International customers . SignUp Process for Indian Customers SignUp Process for International Customers Frequently Asked Questions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Services Platform",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/object_lock/",
    "site_type": "Documentation",
    "content": "Object Lock | E2E Cloud Skip to main content On this page Object Lock Object Lock Configuration ​ EOS supports Object Locking , which helps enforce write-once-read-many (WORM) policies to protect objects from being overwritten or deleted for a fixed retention period. Object Locking supports Governance Mode and Legal Hold . Enable Object Lock ​ Note Object Lock can only be enabled at the time of bucket creation . You will not be able to enable it for an existing bucket. To enable Object Lock: After creating a new bucket with lock enabled, navigate to the Object Lock tab. Toggle the Enable Object Lock option. Set the desired retention period and lock mode (Governance). This ensures all objects uploaded to the bucket are retained according to the defined policy. Governance Lock ​ When the Governance Lock is active: Any object uploaded during this period will automatically inherit the Governance Lock with the configured retention period . Even after disabling Governance Lock for the bucket, the objects uploaded during the active period will retain their lock until explicitly removed. To remove Governance Lock from an object: Go to the Objects tab of the bucket. Click View all versions to display all object versions. Click the three-dot menu next to the version you want to modify. Select Lock Settings and choose the option to remove the Governance Lock . You can legal hold an object by following the same steps as above and selecting the remove lock option for Legal Hold . Legal Hold ​ Legal Hold is a stricter lock that cannot be removed until explicitly cleared, regardless of the bucket or user configuration. To enable Legal Hold for a specific object: Navigate to the Objects tab. Click See all versions . Open the three-dot menu for the specific object version. Click Lock Settings . Toggle the Enable Legal Hold option. Deleting Buckets with Locked Objects ​ If your bucket contains objects that are under a Governance Lock or Legal Hold , the deletion of the bucket will not remove those objects . This may result in the bucket not being completely deleted until all locks are cleared. Reminder : Always verify object lock status before attempting to delete a bucket. Object Lock Configuration Enable Object Lock Governance Lock Legal Hold Deleting Buckets with Locked Objects",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/Release-Notes/?tir=true",
    "site_type": "Software Release Notes",
    "content": "Release Notes | E2E Cloud Skip to main content What's New MyAccount - EOS Encryption Learn More → Release notes Release Notes Filter By: Product All Products Product MyAccount TIR:AI/ML Platform June 13, 2025 TIR Node | FramePack New We're thrilled to announce the launch of FramePack on TIR Nodes! Available as a TIR pre-built image, Framepack is a lightweight Python library that helps organize and manage DataFrames as named frames within a single object. It simplifies handling multiple datasets together, making data analysis more structured and efficient. Unleash your creativity with FramePack on TIR today! June 5, 2025 Parallel File System (PFS) New We're thrilled to announce the launch of Parallel File System (PFS) on TIR! Parallel File System empowers high-performance computing with fast, scalable, and reliable data access. The support for parallel data access makes it ideal for workloads involving massive datasets, demanding extreme throughput and concurrency. Accelerate your compute-intensive tasks with the blazing speed of Parallel File System on TIR today! For More Info Click here June 4, 2025 TIR Node | ComfyUI New We're thrilled to announce the launch of ComfyUI on TIR Nodes! Available as a TIR pre-built image, ComfyUI provides a powerful, node-based interface for visual AI workflows—making it easier than ever to experiment with generative AI models. Unleash your creativity with ComfyUI on TIR today! For More Info Click here May 23, 2025 AI Labs New We’re thrilled to announce the release of AI Labs, a purpose-built platform for end customers to foster structured learning, research innovation, and efficient resource management. Designed for professors, researchers, and students. AI Labs transforms traditional labs into dynamic, cloud-powered AI environments. For More Info Click here May 7, 2025 DeepSeek New Added support for DeepSeek-Coder-V2-Lite-Instruct-FP8, a lightweight FP8-optimized model designed for efficient code understanding and generation. For More Info Click here We’re thrilled to announce DeepSeek-R1-Distill-Llama-70B, trained with RL and excelling in reasoning. For More Info Click here May 6, 2025 Geema, Hermes and BAAI BGE New Say hello to Gemma 3 27B IT, developed using Gemini tech for agile, high-quality performance. For More Info Click here Introducing BGE Multilingual Gemma2, supporting a wide range of multilingual tasks with strong generalization. For More Info Click here Unveiling Hermes 3 Llama 3.1 405B, fine-tuned by Nous Research for top-tier performance. For More Info Click here Show more May 5, 2025 Dolphin, Mistral, OLMo, Phi and QVQ New Dolphin 2.9.2 Mixtral 8x22b runs on SystemChat 2.0 to support consistent long-term prompts. For More Info Click here Now available: Mistral Nemo Instruct 2407, designed to elevate instruction-following and comprehension tasks. For More Info Click here OLMo 7B Instruct advances open science with transparency and reproducibility using the Dolma dataset. For More Info Click here Show more May 4, 2025 QwQ New Announcing QwQ 32B — optimized for complex inference and problem-solving in the Qwen lineup. For More Info Click here QwQ-32B-Preview is an experimental research model developed by the Qwen Team, focused on advancing AI reasoning capabilities. For More Info Click here May 3, 2025 Qwen New Introducing Qwen2.5-32B-Instruct, enhancing coding and mathematics with domain-specific training. For More Info Click here Qwen 2.5 72B Instruct boosts math and programming intelligence via expert domain training. For More Info Click here Qwen 2.5 Coder 7B delivers high-performance code generation as part of the CodeQwen family. For More Info Click here Show more May 2, 2025 Llava New Llava 1.5 13B HF enhances language understanding through advanced autoregressive modeling. For More Info Click here Meet Llava 1.5 7B HF — a faster, cost-efficient variant optimized for transformer-based language modeling. For More Info Click here Results Per Page 10 ​ 1–10 of 67 Previous Next",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/myaccount/",
    "site_type": "Software Release Notes",
    "content": "E2E Cloud Skip to main content E2E MyAccount Overview Endpoints CRN details get Project details get Resource Limit get Resource Details get Nodes Images CDP Backup Load Balancer Auto Scaling Functions Kubernetes SFS Volume Object Storage EPFS Container Registry DBaaS Event Monitoring ParameterGroup CDN Firewall DNS Reserve IP VPC Security Group Security Compliance Billing License Management Settings Tags powered by Stoplight E2E MyAccount Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1 Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/api/tir/",
    "site_type": "Software Release Notes",
    "content": "E2E Cloud Skip to main content TIR : AI/ML Platform Overview Endpoints IAM Accounts get Team ID get Project ID get SKU List get Nodes RAG Dataset SFS Training Cluster Model Repository Model Endpoints Pipeline Run Schedule Run Fine Tune Models GenAI API Vector Database Data Syncer Container Registry External Integration Model Evaluation AI Labs Reserve IP Private Cluster powered by Stoplight TIR : AI/ML Platform Export v1 API Base URL Live Server: https://api.e2enetworks.com/myaccount/api/v1/gpu Security API Key & Bearer Auth API Key  Create a API Key and Auth Token here An API key is a token that you provide when making API calls. Include the token in a query parameter called apikey . Example: ?apikey=123 Bearer Auth Provide your bearer token in the Authorization header when making requests to protected resources. Example: Authorization: Bearer 123",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/pfs/",
    "site_type": "Software Release Notes",
    "content": "Parallel File-System | E2E Cloud Skip to main content On this page Parallel File-System The Parallel File System (PFS) is a high-performance, scalable storage solution optimized for demanding workloads and real-time collaboration. It enables fast, concurrent read and write operations across multiple users and systems—ensuring smooth, efficient data access at scale. Create Parallel File-System ​ To create a new Parallel File-System Click the CREATE FILE-SYSTEM button. Choose the desired Storage Size , then click CREATE . Manage Parallel File-System ​ Mounting to Nodes ​ Before using the PFS, you must mount it to the desired node(s): You can view the details of the selected Parallel File-System attached to nodes by clicking Services . Actions ​ Increase PFS Size Delete File-System Note Before deleting or Resizing a Parallel File System, ensure it is UNMOUNTED from all associated services. Create Parallel File-System Manage Parallel File-System Mounting to Nodes Actions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/tir/Nodes/",
    "site_type": "Software Release Notes",
    "content": "Overview | E2E Cloud Skip to main content On this page Nodes TIR Nodes are fully collaborative environments that make AI development possible. They combine the power of containers, Jupyter Labs, and AI/ML frameworks to create a readily usable workspace for you and your entire team. Getting Started ​ TIR Nodes Guide To TIR Nodes Spot Instance New Spot Instance GPU and Performance ​ Using H100 Optimize workloads using H100 GPUs Configuration and management ​ Committed Nodes Use and manage committed nodes. TIR-Provided Images Pre-built images offered by TIR. Customization and Integrations ​ Node with Your Own Container Deploy nodes with a container of your choice. Access Google Drive in Nodes Integrate Google Drive with your TIR Nodes. TIR Add Ons ​ Gradio Create user interfaces Tensorboard Visualize machine learning training logs TIR Guides ​ LLaMA Factory Fine-tuning with LLaMA Factory on TIR Volume Mount and Data persistence Integration of Datasets (both EOS & Disk) BuildKit Build Docker Images on TIR Nodes Using a Dockerfile Some of the most common use cases are: Run a script or notebook to fine-tune a Large Language Model (LLM) on a single GPU using PyTorch or Hugging Face train. Run a script or notebook to tokenize and fine-tune LLMs or Diffusion models with multiple GPUs (single machine) using DeepSpeed and Accelerate. Open and run a Jupyter notebook (.ipynb) from platforms like GitHub, Kaggle, or Colab. Download and review datasets stored on TIR or other platforms like Hugging Face. Download and test models like Stable Diffusion or any LLM. Note A TIR node is a fully functional coding environment. If you prefer to work with the command line (shell) over Jupyter Labs, you can configure SSH on a notebook (node). This way, you can upload your data using SFTP or sync your code with Git tools and run the scripts as you would on your local system. Getting Started GPU and Performance Configuration and management Customization and Integrations TIR Add Ons TIR Guides",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/",
    "site_type": "Software Release Notes",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/cdp_backups/GettingStarted/",
    "site_type": "Backup and Data Recovery Service",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction CDP Backups can help you manage a node’s backup policy to save files and folders of your E2E Node and also, rolling back to a previous backup recovery point anytime. We recommend you to subscribe for CDP backup service for all your nodes, especially the servers for a production environment. CDP backups secure your data from accidental data loss or modifications along with the option of retaining data for a longer period without consuming the server’s disk space. They are helpful in projects or milestones to back up the complete data or a set of files containing important information. How does CDP Backup work? ​ Backups are created as a replica of your file system which is taken automatically at periodic intervals. Each backup recovery point contains all the data which was backed up to restore from the provisioning till the most recent data block update. This allows point-in-time to restore from any of the recovery points present in the archive. Before you enable CDP backup service, we recommend familiarizing yourself with concepts and terminologies. Completely Secure ​ The backups are created and stored in our backup servers. The connections to these are encrypted using SSL to ensure the security of the data being backed up. Incremental in nature ​ The backup server takes a complete snapshot of the entire filesystem for the first time and from the next run, it only copies over the differential Deltas (data that has changed since the last backup run) thus speeding up the backup process. Database Backups ​ It is always important to backup all your databases stored in your server. The CDP for MySQL Add-On integrates Continuous Data Protection with an online hot backup (snapshot) of MySQL databases to provide fast, efficient, and safe MySQL backups. MySQL add-on ensures that tables are locked and flushed before a backup operation can take place. MySQL Add-On coordinates with the point-in-time file system snapshot. The only requirement for MySQL Add-On is a MySQL account with administrative privileges that is used by the Agent to flush tables with the read lock before the file system snapshot is taken and the lock must be held until the snapshot completes. Click here to check more details. Backup Frequency ​ We do have pre-configured backup plans. You can choose one which matches up your requirement. Backup Recovery Points ​ A recovery point is created as a result of data replication. The first recovery point is called an initial replica because it is performed only one time. In simple words, a Recovery Point appears like a Full backup as each Recovery Point only contains block-level Deltas or changes since the last Synchronization (recovery point creation). In other words, a Recovery Point is a point-in-time backup of the node (or selected files/folders on devices). Each recovery point is all-inclusive i.e it contains all the data and can be used for a restore independently. Backup Recovery Points Retention Policy ​ The Recovery Point Retention policy is default defined and it is applicable for each server for which backup service is enabled. The retention policy will be set as per the backup schedule chosen which will define at which recovery point the backups will be merged and retained. Note After exceeding the defined recovery/archive point number, the old Archive Points will subsequently be replaced by the new ones. Archive Backup Recovery Point ​ Archive backups are considered a best practice to protect your data from natural disasters, malware, and malicious acts. Even enterprises often need to retain long-term backups for business continuity, compliance, customer contracts, and e-Discovery. An Archive Point is a snapshot of a backup recovery point that is stored in another location (object storage-bucket) for long-term data storage to provide further integrity and safe-keeping of data. It will significantly reduce costs while retaining a snapshot of backup recovery point backup for long-term availability. With Archive, you can expand your backup policy to create and manage off-site snapshots of backup recovery points on the E2E Object storage. Archive backup policy can be configured to create a snapshot on a daily, weekly, or monthly schedule in accordance with your retention requirements. According to these configurations, an Archive is created once the policy runs. Daily, the last recovery point of the day is archived. Weekly, the last recovery point of the week is archived. Monthly, the last recovery point of the month is archived. So your backup schedule must be at least daily to archive daily recovery points. You need to adjust the retention policy because the retention policy automatically decides on how many numbers of backup recovery points needed to retain and when to merge old recovery points and archived recovery points. Restore functionality ​ The backup restore rates are inversely proportional to the load on your system. In an ideal environment, Our backup systems can restore at an avg rate of 20 MB/s which translates to 65-70 GB per hour. However, the actual rates may vary and we have seen better speeds than this. The way to request a rollback/restore is to select the files/folders from the recovery points and initiate the restore process. Plans & Prices ​ Please check here for our Backups pricing. How does CDP Backup work? Completely Secure Incremental in nature Database Backups Backup Frequency Backup Recovery Points Backup Recovery Points Retention Policy Archive Backup Recovery Point Restore functionality Plans & Prices",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Backup and Data Recovery Service",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/cdp_backups/GettingStarted/#restore-functionality",
    "site_type": "Backup and Data Recovery Service",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction CDP Backups can help you manage a node’s backup policy to save files and folders of your E2E Node and also, rolling back to a previous backup recovery point anytime. We recommend you to subscribe for CDP backup service for all your nodes, especially the servers for a production environment. CDP backups secure your data from accidental data loss or modifications along with the option of retaining data for a longer period without consuming the server’s disk space. They are helpful in projects or milestones to back up the complete data or a set of files containing important information. How does CDP Backup work? ​ Backups are created as a replica of your file system which is taken automatically at periodic intervals. Each backup recovery point contains all the data which was backed up to restore from the provisioning till the most recent data block update. This allows point-in-time to restore from any of the recovery points present in the archive. Before you enable CDP backup service, we recommend familiarizing yourself with concepts and terminologies. Completely Secure ​ The backups are created and stored in our backup servers. The connections to these are encrypted using SSL to ensure the security of the data being backed up. Incremental in nature ​ The backup server takes a complete snapshot of the entire filesystem for the first time and from the next run, it only copies over the differential Deltas (data that has changed since the last backup run) thus speeding up the backup process. Database Backups ​ It is always important to backup all your databases stored in your server. The CDP for MySQL Add-On integrates Continuous Data Protection with an online hot backup (snapshot) of MySQL databases to provide fast, efficient, and safe MySQL backups. MySQL add-on ensures that tables are locked and flushed before a backup operation can take place. MySQL Add-On coordinates with the point-in-time file system snapshot. The only requirement for MySQL Add-On is a MySQL account with administrative privileges that is used by the Agent to flush tables with the read lock before the file system snapshot is taken and the lock must be held until the snapshot completes. Click here to check more details. Backup Frequency ​ We do have pre-configured backup plans. You can choose one which matches up your requirement. Backup Recovery Points ​ A recovery point is created as a result of data replication. The first recovery point is called an initial replica because it is performed only one time. In simple words, a Recovery Point appears like a Full backup as each Recovery Point only contains block-level Deltas or changes since the last Synchronization (recovery point creation). In other words, a Recovery Point is a point-in-time backup of the node (or selected files/folders on devices). Each recovery point is all-inclusive i.e it contains all the data and can be used for a restore independently. Backup Recovery Points Retention Policy ​ The Recovery Point Retention policy is default defined and it is applicable for each server for which backup service is enabled. The retention policy will be set as per the backup schedule chosen which will define at which recovery point the backups will be merged and retained. Note After exceeding the defined recovery/archive point number, the old Archive Points will subsequently be replaced by the new ones. Archive Backup Recovery Point ​ Archive backups are considered a best practice to protect your data from natural disasters, malware, and malicious acts. Even enterprises often need to retain long-term backups for business continuity, compliance, customer contracts, and e-Discovery. An Archive Point is a snapshot of a backup recovery point that is stored in another location (object storage-bucket) for long-term data storage to provide further integrity and safe-keeping of data. It will significantly reduce costs while retaining a snapshot of backup recovery point backup for long-term availability. With Archive, you can expand your backup policy to create and manage off-site snapshots of backup recovery points on the E2E Object storage. Archive backup policy can be configured to create a snapshot on a daily, weekly, or monthly schedule in accordance with your retention requirements. According to these configurations, an Archive is created once the policy runs. Daily, the last recovery point of the day is archived. Weekly, the last recovery point of the week is archived. Monthly, the last recovery point of the month is archived. So your backup schedule must be at least daily to archive daily recovery points. You need to adjust the retention policy because the retention policy automatically decides on how many numbers of backup recovery points needed to retain and when to merge old recovery points and archived recovery points. Restore functionality ​ The backup restore rates are inversely proportional to the load on your system. In an ideal environment, Our backup systems can restore at an avg rate of 20 MB/s which translates to 65-70 GB per hour. However, the actual rates may vary and we have seen better speeds than this. The way to request a rollback/restore is to select the files/folders from the recovery points and initiate the restore process. Plans & Prices ​ Please check here for our Backups pricing. How does CDP Backup work? Completely Secure Incremental in nature Database Backups Backup Frequency Backup Recovery Points Backup Recovery Points Retention Policy Archive Backup Recovery Point Restore functionality Plans & Prices",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Backup and Data Recovery Service",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Backup and Data Recovery Service",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Backup and Data Recovery Service",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/monitoring/",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Monitoring | E2E Cloud Skip to main content Monitoring E2E Networks node monitoring involves the process of continuously observing and managing cloud-based compute nodes to ensure optimal performance and uptime. E2E Networks provides cloud infrastructure, and their monitoring solutions focus on tracking the health, resource usage (such as CPU, RAM, and disk), and network activity of nodes. This monitoring helps detect anomalies, predict potential issues, and enable proactive management to maintain the stability and security of deployed applications. Automated alerts and detailed metrics facilitate quick response times to potential problems, supporting high availability and efficient resource allocation. Introduction Node Monitoring. Zabbix-agent Steps to Install Zabbix-Agent on your server. Troubleshooting steps Troubleshooting steps for monitoring in Windows",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/node/monitoring/#__docusaurus_skipToContent_fallback",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Monitoring | E2E Cloud Skip to main content Monitoring E2E Networks node monitoring involves the process of continuously observing and managing cloud-based compute nodes to ensure optimal performance and uptime. E2E Networks provides cloud infrastructure, and their monitoring solutions focus on tracking the health, resource usage (such as CPU, RAM, and disk), and network activity of nodes. This monitoring helps detect anomalies, predict potential issues, and enable proactive management to maintain the stability and security of deployed applications. Automated alerts and detailed metrics facilitate quick response times to potential problems, supporting high availability and efficient resource allocation. Introduction Node Monitoring. Zabbix-agent Steps to Install Zabbix-Agent on your server. Troubleshooting steps Troubleshooting steps for monitoring in Windows",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Cloud Monitoring Service/Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/replication-s3-to-eos/",
    "site_type": "Documentation",
    "content": "Replication From S3 to EOS | E2E Cloud Skip to main content On this page Live Replication Between S3-Bucket-Folder to EOS-Bucket-Folder Overview ​ This guide covers setting up live replication between an AWS S3 bucket folder and an EOS (E2E Object Storage) bucket folder using AWS Lambda. Step 1. IAM Role Creation with S3 Full Access ​ Create IAM Role ​ Navigate to AWS IAM Console. Click on Roles → Create Role. Choose AWS Service → Lambda. Attach the following policy: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:ListBucket\" , \"s3:GetObject\" ] , \"Resource\" : [ \"arn:aws:s3:::your-bucket-name\" , \"arn:aws:s3:::your-bucket-name/*\" ] } ] } Name the role LambdaS3FullAccess and create it. Attach this role to your Lambda function. Step2. Create an AWS Lambda Function ​ Open AWS Lambda Console → Create Function. Choose Author from scratch . Set runtime to Python 3.10 . Select the IAM role created earlier. Click Create Function . Step3. Setup a Test Event ​ Open AWS Lambda Console → Select your function. Click Test → Create new test event . Use the following JSON: { \"Records\" : [ { \"eventSource\" : \"aws:s3\" , \"eventName\" : \"ObjectCreated:Put\" , \"s3\" : { \"bucket\" : { \"name\" : \"S3_Bucket-name\" } , \"object\" : { \"key\" : \"Folder-name/Object\" } } } ] } 4. Save the test event. Step4. Lambda Deployment with Dependencies ​ Prepare Lambda Package ​ mkdir -p lambda_package cd lambda_package pip install minio -t lambda_package/ cd lambda_package/ Add Function Code ​ vim lambda_function.py Paste the function code: ​ import os import io import json import boto3 from minio import Minio from minio . error import S3Error # AWS S3 Client s3_client = boto3 . client ( 's3' ) # MinIO Credentials MINIO_ENDPOINT = os . getenv ( \"MINIO_ENDPOINT\" , \"objectstore.e2enetworks.net\" ) MINIO_ACCESS_KEY = os . getenv ( \"MINIO_ACCESS_KEY\" ) MINIO_SECRET_KEY = os . getenv ( \"MINIO_SECRET_KEY\" ) MINIO_BUCKET = os . getenv ( \"MINIO_BUCKET\" ) S3_BUCKET = os . getenv ( \"S3_BUCKET\" ) S3_FOLDER = os . getenv ( \"S3_FOLDER\" ) MINIO_FOLDER = os . getenv ( \"MINIO_FOLDER\" ) # MinIO Client minio_client = Minio ( MINIO_ENDPOINT , access_key = MINIO_ACCESS_KEY , secret_key = MINIO_SECRET_KEY , secure = True ) def list_minio_objects ( ) : \"\"\"Get a list of objects only within the MinIO sync folder.\"\"\" objects = minio_client . list_objects ( MINIO_BUCKET , prefix = f\" { MINIO_FOLDER } /\" , recursive = True ) return { obj . object_name for obj in objects } def sync_folders ( ) : \"\"\"Sync objects from S3 to MinIO and remove deleted objects only within the folder.\"\"\" # Fetch objects in S3 s3_objects = s3_client . list_objects_v2 ( Bucket = S3_BUCKET , Prefix = S3_FOLDER ) s3_keys = set ( ) if 'Contents' in s3_objects : for obj in s3_objects [ 'Contents' ] : relative_path = obj [ 'Key' ] [ len ( S3_FOLDER ) : ] . lstrip ( '/' ) s3_keys . add ( relative_path ) minio_object_path = f\" { MINIO_FOLDER } / { relative_path } \" # Check if the object exists in MinIO try : minio_client . stat_object ( MINIO_BUCKET , minio_object_path ) print ( f\"Skipping { minio_object_path } (Already exists)\" ) continue except S3Error : pass # Proceed with upload if file is missing # Stream S3 object into memory response = s3_client . get_object ( Bucket = S3_BUCKET , Key = obj [ 'Key' ] ) data = io . BytesIO ( response [ 'Body' ] . read ( ) ) # Upload directly to MinIO minio_client . put_object ( MINIO_BUCKET , minio_object_path , data , length = len ( data . getvalue ( ) ) ) print ( f\"Uploaded { obj [ 'Key' ] } to MinIO as { minio_object_path } \" ) # Find objects in MinIO **only within the sync folder** that do not exist in S3 and delete them minio_objects = list_minio_objects ( ) s3_keys_with_prefix = { f\" { MINIO_FOLDER } / { key } \" for key in s3_keys } objects_to_delete = minio_objects - s3_keys_with_prefix for obj in objects_to_delete : minio_client . remove_object ( MINIO_BUCKET , obj ) print ( f\"Deleted { obj } from MinIO (No longer in S3)\" ) def lambda_handler ( event , context ) : try : sync_folders ( ) except Exception as e : print ( f\"Error: { e } \" ) return { 'statusCode' : 500 , 'body' : json . dumps ( 'Replication Failed' ) } return { 'statusCode' : 200 , 'body' : json . dumps ( 'Replication Successful' ) } zip -r ../lambda_function.zip cd .. ls Step5. Upload to AWS Lambda ​ Open AWS Lambda Console . Select your function → Click Upload from → .zip file . Choose lambda_function.zip and click Deploy . Step6. Set Environment Variables in AWS Lambda ​ Open AWS Lambda Console → Select your function. Click Configuration → Environment Variables . Click Edit and add: MINIO_ACCESS_KEY = YOUR_ACCESS_KEY MINIO_SECRET_KEY = YOUR_SECRET_KEY MINIO_ENDPOINT = objectstore.e2enetworks.net MINIO_BUCKET = E2E-BUCKET_NAME S3_BUCKET = YOUR-S3-BUCKET-NAME Click Save . Step7. Configuring S3 Event Notification ​ Navigate to Amazon S3 Console . Select the source bucket. Click Properties → Event Notifications → Create Event Notification . Configure: Name: s3-e2e Event types: Check all (Create, Remove, Restore). Destination: Choose Lambda Function → Select your function. Save changes. Step8. Testing the Lambda Function ​ Click Test → Select the created test event. Click Invoke . The function should display Replication Successful if it works correctly. Limitations & Workaround: ⚠ Existing Data Consideration – If you have any old data or manually uploaded objects in EOS , they will be deleted when the function runs. ⚠ However, this function only synchronizes objects inside the specified S3 folder and will not affect other bucket objects . ✅ Workaround: You can upload the EOS folder's old objects to the S3 folder —this will allow the function to track them as well. Recommendation We strongly advise testing the solution in a test environment first . Once validated, you can proceed with configuration for the production environment . Overview Step 1. IAM Role Creation with S3 Full Access Create IAM Role Step2. Create an AWS Lambda Function Step3. Setup a Test Event Step4. Lambda Deployment with Dependencies Prepare Lambda Package Add Function Code Paste the function code: Step5. Upload to AWS Lambda Step6. Set Environment Variables in AWS Lambda Step7. Configuring S3 Event Notification Step8. Testing the Lambda Function",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/replication-s3-to-eos/#step-1-iam-role-creation-with-s3-full-access",
    "site_type": "Documentation",
    "content": "Replication From S3 to EOS | E2E Cloud Skip to main content On this page Live Replication Between S3-Bucket-Folder to EOS-Bucket-Folder Overview ​ This guide covers setting up live replication between an AWS S3 bucket folder and an EOS (E2E Object Storage) bucket folder using AWS Lambda. Step 1. IAM Role Creation with S3 Full Access ​ Create IAM Role ​ Navigate to AWS IAM Console. Click on Roles → Create Role. Choose AWS Service → Lambda. Attach the following policy: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:ListBucket\" , \"s3:GetObject\" ] , \"Resource\" : [ \"arn:aws:s3:::your-bucket-name\" , \"arn:aws:s3:::your-bucket-name/*\" ] } ] } Name the role LambdaS3FullAccess and create it. Attach this role to your Lambda function. Step2. Create an AWS Lambda Function ​ Open AWS Lambda Console → Create Function. Choose Author from scratch . Set runtime to Python 3.10 . Select the IAM role created earlier. Click Create Function . Step3. Setup a Test Event ​ Open AWS Lambda Console → Select your function. Click Test → Create new test event . Use the following JSON: { \"Records\" : [ { \"eventSource\" : \"aws:s3\" , \"eventName\" : \"ObjectCreated:Put\" , \"s3\" : { \"bucket\" : { \"name\" : \"S3_Bucket-name\" } , \"object\" : { \"key\" : \"Folder-name/Object\" } } } ] } 4. Save the test event. Step4. Lambda Deployment with Dependencies ​ Prepare Lambda Package ​ mkdir -p lambda_package cd lambda_package pip install minio -t lambda_package/ cd lambda_package/ Add Function Code ​ vim lambda_function.py Paste the function code: ​ import os import io import json import boto3 from minio import Minio from minio . error import S3Error # AWS S3 Client s3_client = boto3 . client ( 's3' ) # MinIO Credentials MINIO_ENDPOINT = os . getenv ( \"MINIO_ENDPOINT\" , \"objectstore.e2enetworks.net\" ) MINIO_ACCESS_KEY = os . getenv ( \"MINIO_ACCESS_KEY\" ) MINIO_SECRET_KEY = os . getenv ( \"MINIO_SECRET_KEY\" ) MINIO_BUCKET = os . getenv ( \"MINIO_BUCKET\" ) S3_BUCKET = os . getenv ( \"S3_BUCKET\" ) S3_FOLDER = os . getenv ( \"S3_FOLDER\" ) MINIO_FOLDER = os . getenv ( \"MINIO_FOLDER\" ) # MinIO Client minio_client = Minio ( MINIO_ENDPOINT , access_key = MINIO_ACCESS_KEY , secret_key = MINIO_SECRET_KEY , secure = True ) def list_minio_objects ( ) : \"\"\"Get a list of objects only within the MinIO sync folder.\"\"\" objects = minio_client . list_objects ( MINIO_BUCKET , prefix = f\" { MINIO_FOLDER } /\" , recursive = True ) return { obj . object_name for obj in objects } def sync_folders ( ) : \"\"\"Sync objects from S3 to MinIO and remove deleted objects only within the folder.\"\"\" # Fetch objects in S3 s3_objects = s3_client . list_objects_v2 ( Bucket = S3_BUCKET , Prefix = S3_FOLDER ) s3_keys = set ( ) if 'Contents' in s3_objects : for obj in s3_objects [ 'Contents' ] : relative_path = obj [ 'Key' ] [ len ( S3_FOLDER ) : ] . lstrip ( '/' ) s3_keys . add ( relative_path ) minio_object_path = f\" { MINIO_FOLDER } / { relative_path } \" # Check if the object exists in MinIO try : minio_client . stat_object ( MINIO_BUCKET , minio_object_path ) print ( f\"Skipping { minio_object_path } (Already exists)\" ) continue except S3Error : pass # Proceed with upload if file is missing # Stream S3 object into memory response = s3_client . get_object ( Bucket = S3_BUCKET , Key = obj [ 'Key' ] ) data = io . BytesIO ( response [ 'Body' ] . read ( ) ) # Upload directly to MinIO minio_client . put_object ( MINIO_BUCKET , minio_object_path , data , length = len ( data . getvalue ( ) ) ) print ( f\"Uploaded { obj [ 'Key' ] } to MinIO as { minio_object_path } \" ) # Find objects in MinIO **only within the sync folder** that do not exist in S3 and delete them minio_objects = list_minio_objects ( ) s3_keys_with_prefix = { f\" { MINIO_FOLDER } / { key } \" for key in s3_keys } objects_to_delete = minio_objects - s3_keys_with_prefix for obj in objects_to_delete : minio_client . remove_object ( MINIO_BUCKET , obj ) print ( f\"Deleted { obj } from MinIO (No longer in S3)\" ) def lambda_handler ( event , context ) : try : sync_folders ( ) except Exception as e : print ( f\"Error: { e } \" ) return { 'statusCode' : 500 , 'body' : json . dumps ( 'Replication Failed' ) } return { 'statusCode' : 200 , 'body' : json . dumps ( 'Replication Successful' ) } zip -r ../lambda_function.zip cd .. ls Step5. Upload to AWS Lambda ​ Open AWS Lambda Console . Select your function → Click Upload from → .zip file . Choose lambda_function.zip and click Deploy . Step6. Set Environment Variables in AWS Lambda ​ Open AWS Lambda Console → Select your function. Click Configuration → Environment Variables . Click Edit and add: MINIO_ACCESS_KEY = YOUR_ACCESS_KEY MINIO_SECRET_KEY = YOUR_SECRET_KEY MINIO_ENDPOINT = objectstore.e2enetworks.net MINIO_BUCKET = E2E-BUCKET_NAME S3_BUCKET = YOUR-S3-BUCKET-NAME Click Save . Step7. Configuring S3 Event Notification ​ Navigate to Amazon S3 Console . Select the source bucket. Click Properties → Event Notifications → Create Event Notification . Configure: Name: s3-e2e Event types: Check all (Create, Remove, Restore). Destination: Choose Lambda Function → Select your function. Save changes. Step8. Testing the Lambda Function ​ Click Test → Select the created test event. Click Invoke . The function should display Replication Successful if it works correctly. Limitations & Workaround: ⚠ Existing Data Consideration – If you have any old data or manually uploaded objects in EOS , they will be deleted when the function runs. ⚠ However, this function only synchronizes objects inside the specified S3 folder and will not affect other bucket objects . ✅ Workaround: You can upload the EOS folder's old objects to the S3 folder —this will allow the function to track them as well. Recommendation We strongly advise testing the solution in a test environment first . Once validated, you can proceed with configuration for the production environment . Overview Step 1. IAM Role Creation with S3 Full Access Create IAM Role Step2. Create an AWS Lambda Function Step3. Setup a Test Event Step4. Lambda Deployment with Dependencies Prepare Lambda Package Add Function Code Paste the function code: Step5. Upload to AWS Lambda Step6. Set Environment Variables in AWS Lambda Step7. Configuring S3 Event Notification Step8. Testing the Lambda Function",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/replication-s3-to-eos/#step6-set-environment-variables-in-aws-lambda",
    "site_type": "Documentation",
    "content": "Replication From S3 to EOS | E2E Cloud Skip to main content On this page Live Replication Between S3-Bucket-Folder to EOS-Bucket-Folder Overview ​ This guide covers setting up live replication between an AWS S3 bucket folder and an EOS (E2E Object Storage) bucket folder using AWS Lambda. Step 1. IAM Role Creation with S3 Full Access ​ Create IAM Role ​ Navigate to AWS IAM Console. Click on Roles → Create Role. Choose AWS Service → Lambda. Attach the following policy: { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Action\" : [ \"s3:ListBucket\" , \"s3:GetObject\" ] , \"Resource\" : [ \"arn:aws:s3:::your-bucket-name\" , \"arn:aws:s3:::your-bucket-name/*\" ] } ] } Name the role LambdaS3FullAccess and create it. Attach this role to your Lambda function. Step2. Create an AWS Lambda Function ​ Open AWS Lambda Console → Create Function. Choose Author from scratch . Set runtime to Python 3.10 . Select the IAM role created earlier. Click Create Function . Step3. Setup a Test Event ​ Open AWS Lambda Console → Select your function. Click Test → Create new test event . Use the following JSON: { \"Records\" : [ { \"eventSource\" : \"aws:s3\" , \"eventName\" : \"ObjectCreated:Put\" , \"s3\" : { \"bucket\" : { \"name\" : \"S3_Bucket-name\" } , \"object\" : { \"key\" : \"Folder-name/Object\" } } } ] } 4. Save the test event. Step4. Lambda Deployment with Dependencies ​ Prepare Lambda Package ​ mkdir -p lambda_package cd lambda_package pip install minio -t lambda_package/ cd lambda_package/ Add Function Code ​ vim lambda_function.py Paste the function code: ​ import os import io import json import boto3 from minio import Minio from minio . error import S3Error # AWS S3 Client s3_client = boto3 . client ( 's3' ) # MinIO Credentials MINIO_ENDPOINT = os . getenv ( \"MINIO_ENDPOINT\" , \"objectstore.e2enetworks.net\" ) MINIO_ACCESS_KEY = os . getenv ( \"MINIO_ACCESS_KEY\" ) MINIO_SECRET_KEY = os . getenv ( \"MINIO_SECRET_KEY\" ) MINIO_BUCKET = os . getenv ( \"MINIO_BUCKET\" ) S3_BUCKET = os . getenv ( \"S3_BUCKET\" ) S3_FOLDER = os . getenv ( \"S3_FOLDER\" ) MINIO_FOLDER = os . getenv ( \"MINIO_FOLDER\" ) # MinIO Client minio_client = Minio ( MINIO_ENDPOINT , access_key = MINIO_ACCESS_KEY , secret_key = MINIO_SECRET_KEY , secure = True ) def list_minio_objects ( ) : \"\"\"Get a list of objects only within the MinIO sync folder.\"\"\" objects = minio_client . list_objects ( MINIO_BUCKET , prefix = f\" { MINIO_FOLDER } /\" , recursive = True ) return { obj . object_name for obj in objects } def sync_folders ( ) : \"\"\"Sync objects from S3 to MinIO and remove deleted objects only within the folder.\"\"\" # Fetch objects in S3 s3_objects = s3_client . list_objects_v2 ( Bucket = S3_BUCKET , Prefix = S3_FOLDER ) s3_keys = set ( ) if 'Contents' in s3_objects : for obj in s3_objects [ 'Contents' ] : relative_path = obj [ 'Key' ] [ len ( S3_FOLDER ) : ] . lstrip ( '/' ) s3_keys . add ( relative_path ) minio_object_path = f\" { MINIO_FOLDER } / { relative_path } \" # Check if the object exists in MinIO try : minio_client . stat_object ( MINIO_BUCKET , minio_object_path ) print ( f\"Skipping { minio_object_path } (Already exists)\" ) continue except S3Error : pass # Proceed with upload if file is missing # Stream S3 object into memory response = s3_client . get_object ( Bucket = S3_BUCKET , Key = obj [ 'Key' ] ) data = io . BytesIO ( response [ 'Body' ] . read ( ) ) # Upload directly to MinIO minio_client . put_object ( MINIO_BUCKET , minio_object_path , data , length = len ( data . getvalue ( ) ) ) print ( f\"Uploaded { obj [ 'Key' ] } to MinIO as { minio_object_path } \" ) # Find objects in MinIO **only within the sync folder** that do not exist in S3 and delete them minio_objects = list_minio_objects ( ) s3_keys_with_prefix = { f\" { MINIO_FOLDER } / { key } \" for key in s3_keys } objects_to_delete = minio_objects - s3_keys_with_prefix for obj in objects_to_delete : minio_client . remove_object ( MINIO_BUCKET , obj ) print ( f\"Deleted { obj } from MinIO (No longer in S3)\" ) def lambda_handler ( event , context ) : try : sync_folders ( ) except Exception as e : print ( f\"Error: { e } \" ) return { 'statusCode' : 500 , 'body' : json . dumps ( 'Replication Failed' ) } return { 'statusCode' : 200 , 'body' : json . dumps ( 'Replication Successful' ) } zip -r ../lambda_function.zip cd .. ls Step5. Upload to AWS Lambda ​ Open AWS Lambda Console . Select your function → Click Upload from → .zip file . Choose lambda_function.zip and click Deploy . Step6. Set Environment Variables in AWS Lambda ​ Open AWS Lambda Console → Select your function. Click Configuration → Environment Variables . Click Edit and add: MINIO_ACCESS_KEY = YOUR_ACCESS_KEY MINIO_SECRET_KEY = YOUR_SECRET_KEY MINIO_ENDPOINT = objectstore.e2enetworks.net MINIO_BUCKET = E2E-BUCKET_NAME S3_BUCKET = YOUR-S3-BUCKET-NAME Click Save . Step7. Configuring S3 Event Notification ​ Navigate to Amazon S3 Console . Select the source bucket. Click Properties → Event Notifications → Create Event Notification . Configure: Name: s3-e2e Event types: Check all (Create, Remove, Restore). Destination: Choose Lambda Function → Select your function. Save changes. Step8. Testing the Lambda Function ​ Click Test → Select the created test event. Click Invoke . The function should display Replication Successful if it works correctly. Limitations & Workaround: ⚠ Existing Data Consideration – If you have any old data or manually uploaded objects in EOS , they will be deleted when the function runs. ⚠ However, this function only synchronizes objects inside the specified S3 folder and will not affect other bucket objects . ✅ Workaround: You can upload the EOS folder's old objects to the S3 folder —this will allow the function to track them as well. Recommendation We strongly advise testing the solution in a test environment first . Once validated, you can proceed with configuration for the production environment . Overview Step 1. IAM Role Creation with S3 Full Access Create IAM Role Step2. Create an AWS Lambda Function Step3. Setup a Test Event Step4. Lambda Deployment with Dependencies Prepare Lambda Package Add Function Code Paste the function code: Step5. Upload to AWS Lambda Step6. Set Environment Variables in AWS Lambda Step7. Configuring S3 Event Notification Step8. Testing the Lambda Function",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/using_api/",
    "site_type": "Documentation",
    "content": "Using API | E2E Cloud Skip to main content On this page Using API E2E Object Storage supports a range of REST endpoints for seamless integration with external applications and plugins. Getting Started ​ Object Storage is capable of supporting any API SDK that’s S3 compliant, but we recommend using Minio SDKs for the best experience. In this article, we will use Python to demonstrate API examples, but you may use other languages as per your comfort. Pre-requisites ​ You will need Python 2.7 or higher . You will need a storage bucket and credentials (access/secret key). Install minio python sdk : pip install minio Initialize Client ​ Endpoint URLs Delhi-NCR : objectstore.e2enetworks.net Mumbai : mum-objectstore.e2enetworks.net from minio import Minio eos_client = Minio('<<endpoint_url>>', access_key='<<enter access key here>>', secret_key='<<enter secret key here>>', secure=True) List objects from a bucket ​ # method: list_objects # params: bucket_name, prefix (object path prefix), recursive (set True for directories) objects = eos_client.list_objects('<<bucketname>>', prefix='<<enter path here. e.g. / for root>>', recursive=False) for obj in objects: print(obj.bucket_name, obj.object_name, obj.last_modified, obj.size, obj.content_type) Get Object ​ # method: get_object # params: bucket_name, object name (object full path) from minio.error import ResponseError try: data = eos_client.get_object('bucketname', 'objectname') with open('test-file', 'wb') as file_data: for d in data.stream(32*1024): file_data.write(d) except ResponseError as err: print(err) Put Object ​ # method: get_object # params: bucket_name, object name (object full path), # file pointer, size of file, content type from minio.error import ResponseError try: with open('/local_dir/test-file.csv', 'rb') as file_data: file_stat = os.stat('/local_dir/test-file.csv') eos_client.put_object('bucketname', 'objectname', file_data, file_stat.st_size, content_type='application/csv') except ResponseError as err: print(err) Remove Object ​ # method: remove_objects # params: bucket_name, object prefix (e.g. directory path) from minio.error import ResponseError try: get_name = lambda object: object.object_name names = map(get_name, client.list_objects_v2('bucketname', 'path', recursive=True)) for err in client.remove_objects('bucketname', names): print(\"Deletion Error: {}\".format(err)) except ResponseError as err: print(err) Supported Operations ​ At the moment, the following object-level operations are supported. But we intend to add more bucket and admin-level functions soon. Please feel free to write to us at cloud-platform@e2enetworks.com for feature requests. Operation Operation Operation list_objects get_object remove_object put_object copy_object remove_objects fput_object fget_object get_partial_object select_object_content remove_incomplete_upload presigned_get_object presigned_put_object Getting Started Pre-requisites Initialize Client List objects from a bucket Get Object Put Object Remove Object Supported Operations",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/sfs/",
    "site_type": "Documentation",
    "content": "Scalable File System | E2E Cloud Skip to main content On this page Scalable File System Topics: ​ Scalable File System Introduction to Scalable File Systems SFS Backup Guide for backing up your Scalable File System Topics:",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/kubernetes/GettingStarted/",
    "site_type": "Documentation",
    "content": "Kubernetes | E2E Cloud Skip to main content On this page Kubernetes The Kubernetes section of the E2E Networks documentation offers a comprehensive guide on deploying and managing Kubernetes clusters. It includes topics like getting started with Kubernetes, node pool details, monitoring, alerts, actions, Kubernetes Marketplace, and troubleshooting. Additional topics cover integrating tools like Argo CD, Jenkins, Ansible, and Istio with Kubernetes, as well as connecting to DBaaS. E2E Kubernetes Features Node Pool Management Static Pool : Fixed node allocation for stable workloads. Auto Scale Pool : Dynamically adjusts node count based on workload demand. Elastic Scaling Policies Default Policy : Auto-scales resources based on CPU or memory thresholds. Custom Policy : Allows scaling based on user-defined attributes (e.g., network traffic, disk I/O). Scheduled Auto-Scaling Enables predefined scaling based on time-based traffic patterns. Supports recurring upscale/downscale actions for predictable workload handling. Database-as-a-Service (DBaaS) Integration Ensures reliable and high-availability database connectivity. Separates database storage from Kubernetes pods to maintain data persistence. Ingress and Load Balancing Nginx Ingress Controller enables host-based routing for efficient traffic distribution. Supports SSL termination and load balancing for enhanced security and performance. Cert-Manager for Automated TLS Simplifies SSL certificate provisioning and renewal. Ensures secure communication within Kubernetes clusters. Third-Party Tool Integrations Compatible with DevOps tools like Argo CD, Jenkins, and Ansible for automation. Supports Istio for service mesh implementation and enhanced microservices security. Key Benefits of using E2E Kubernetes Simplified Cluster Management Provides a comprehensive guide for deploying and managing Kubernetes clusters efficiently. Supports automated scaling, monitoring, and troubleshooting to ensure smooth operations. Flexible and Scalable Infrastructure Offers static and auto-scaling node pools with customizable scaling policies. Elastic scaling policies enable dynamic resource allocation based on CPU, memory, or custom parameters. Optimized Resource Utilization Default and custom auto-scaling options ensure efficient resource management. Scheduled auto-scaling policies allow resource adjustments based on traffic patterns. Seamless Database Integration Allows easy connection of Kubernetes clusters to E2E Database-as-a-Service (DBaaS). Ensures high availability, scalability, and data persistence for critical applications. Enhanced Security and Performance Kubernetes Ingress provides a single entry point, reducing the attack surface. Cert-Manager integration enables automated SSL/TLS certificate management for secure communication. Improved DevOps Workflow Supports integration with Argo CD, Jenkins, Ansible, and Istio for streamlined CI/CD processes. Helps teams automate deployments and maintain consistency across environments. Kubernetes Setup and Configuration ​ Getting Started Automating the deployment, scaling, and management of containerized applications.. Persistent Volume using SFS Resilient and fault-tolerant persistent volume Database Connectivity Connecting Cluster to E2E DBaaS. Nginx Ingress Controller Steps for setting up Nginx Ingress controller Security and Management Tools ​ Cert Manager set up an Nginx Ingress with Cert-Manager. Monitoring and Alerts Implementing monitoring systems and setting up alerts. Application Deployment and Integration ​ Kubernetes Marketplace Utilizing the marketplace for various applications. Integration with Tools Implementing monitoring systems and setting up alerts. Kubernetes with Object Storage Instructions on integrating Kubernetes with object storage Plans ​ Committed Kubernetes Flexible and cost efficient plans Troubleshooting ​ Troubleshooting Common issues and their solutions. Ansible Installation Installation and Deployment. Kubernetes Setup and Configuration Security and Management Tools Application Deployment and Integration Plans Troubleshooting",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/appliance/LoadBalancer/",
    "site_type": "Documentation",
    "content": "Introduction | E2E Cloud Skip to main content On this page Introduction Load balancing in simplest terms refers to dynamically distributing application incoming network traffic across a group of backend nodes. It helps to maintain high availability, scalability, fault-tolerance of your application and gives a smooth experience to the application users because applications are serving hundreds of thousands, or millions, of concurrent requests from users or clients and return the correct response as per request. To cost-effectively scale to meet these high volumes, modern computing best practice generally requires adding more servers. A load balancer acts as a single point of contact for the application. It helps to manage your application servers and to route users/client requests across all servers capable of fulfilling those requests in a manner that maximizes speed and capacity utilization and ensures that no one server is overworked, which could degrade performance. If a single server goes down, the load balancer redirects traffic to the remaining online servers. When a new server is added to the server group, the load balancer automatically starts to send requests to it. Load distribution decision is based on the configured process and the traffic that is coming to the application. It checks connection requests from clients, using the protocol and port that you configure for front-end (client to load balancer) connections. It forwards requests to one or more registered backend nodes using the protocol and port number that you set for back-end (load balancer to backend nodes) connections. Essential characteristics of Load balancer ​ You have the flexibility to add and remove backend nodes from your load balancer to handle traffic load based on requirement changes without interrupting the flow of user requests to your application. Registering Nodes adds them to the load balancer, which starts routing requests to them. Deregistering Nodes removes them, and they stop receiving traffic, though they remain running. You can re-register them as needed. When you create a load balancer, you must choose between an internal load balancer (private IP) and an external load balancer (public IP). External load balancers route Internet traffic to backend nodes. Internal load balancers route traffic over private subnets. E2E Load balancers support various load balancing algorithms, each with specific benefits depending on your needs. Monitoring provides real-time health insights and metrics of load balancer operations on the MyAccount portal. Learn more about Monitoring Alerts can be configured to notify you about critical load balancer health changes via email. Learn more about Alerts Reserved IP can be attached as either: An add-on IP associated with the load balancer's primary network interface. A primary public IP for the load balancer interface. Learn more about Reserved IP E2E Load Balancer Features Dynamic Traffic Distribution Effectively distributes incoming network traffic across backend nodes, optimizing speed, capacity utilization, and overall resource management. Automatic Scaling Seamlessly adjusts the number of backend nodes based on fluctuating traffic demands, ensuring optimal load distribution and efficient resource management. Fault Tolerance In the event of a server failure, the load balancer automatically redirects traffic to remaining operational nodes, ensuring uninterrupted availability and minimizing downtime. Flexible Node Management Backend nodes can be registered or deregistered without disrupting ongoing user requests, ensuring continuous service availability. Nodes can be re-registered as needed when scaling or when previously removed nodes are ready to handle traffic again. Protocol and Port Configuration Provides customizable configuration options for both front-end (client to load balancer) and back-end (load balancer to server) connections, offering greater flexibility in traffic management. Internal vs. External Load Balancing External Load Balancer: Routes internet traffic to backend nodes using a public IP address. Internal Load Balancer: Directs traffic over private subnets, ideal for internal network applications requiring no public exposure. Support for Multiple Load Balancing Algorithms Offers a variety of load balancing algorithms, such as Round Robin, Least Connections, and Source IP Hash, to optimize traffic distribution based on specific workload requirements. Monitoring Real-time health insights and metrics of load balancer operations are available via the MyAccount portal. Alerts Alerts can be configured to notify you of critical load balancer health changes via email. Reserved IP Features Add-on IP: A reserved IP can be attached to the load balancer’s primary network interface for enhanced flexibility. Primary Public IP: A reserved IP can be designated as the primary public IP for the load balancer interface, ensuring stable and consistent routing. Health Check The load balancer performs health checks on the specified web application configurations to ensure optimal functionality and performance. BitNinja Protection Integrated BitNinja security modules defend against cyberattacks, providing easy installation, minimal maintenance, and immediate protection for the load balancer. Timeout Configurations Configurable timeout settings, including connection timeout, client timeout, server timeout, and HTTP keep-alive timeout, offer flexibility in traffic management to suit application needs. Key Benefits of using E2E Load Balancer High Availability By distributing traffic across multiple backend nodes, the E2E Load Balancer ensures consistent application availability, even in the event of server failure. Scalability The load balancer dynamically adjusts backend nodes to accommodate varying traffic demands, enabling businesses to scale efficiently without compromising service quality. Resilience With built-in fault tolerance, the system reroutes traffic to healthy nodes if one or more backend servers become unavailable, minimizing service disruptions and enhancing reliability. Customizability E2E Load Balancers allow users to configure load balancing algorithms and traffic routing settings, ensuring tailored performance based on specific application requirements. Proactive Monitoring Continuous health monitoring and real-time performance metrics enable quick identification and resolution of potential issues, ensuring optimal performance. Private and Public Traffic Management With both internal and external load balancing options, E2E Load Balancer ensures traffic is routed according to the application’s specific architecture, whether on public or private networks. Efficient IP Management Reserved IPs offer greater flexibility in managing the load balancer’s network interfaces, contributing to consistent and reliable network performance. Types of Load Balancer ​ Application Load Balancer Routes HTTP/HTTPS traffic at the application layer (Layer 7). Network Load Balancer Routes TCP traffic at the transport layer (Layer 4). Plans ​ Committed LB Longer the commitment more will be the saving Types of Load Balancer Plans",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/auto_scaling/",
    "site_type": "Documentation",
    "content": "Application Scaling on E2E Cloud | E2E Cloud Skip to main content On this page Application Scaling on E2E Cloud The E2E Application Scaling documentation section offers a comprehensive guide on building scalable cloud solutions. It includes an introduction to key concepts around Auto Scaling features, along with detailed information on setting up the Scaler service and managing scale groups . The focus is on various scaling policies and configurations to ensure flexibility and efficiency. Additionally, the documentation provides insights into customizing and scheduling scaling policies for optimal application performance. E2E Auto Scaling Features Dynamic Compute Scaling – Auto Scaling allows for the automatic scaling of compute nodes based on varying workloads. It dynamically adjusts resources to meet infrastructure demands, ensuring cost optimization by adding or removing nodes based on real-time usage. Rule-Based Scaling Policies – With rule-based policies, you can set thresholds (e.g., CPU utilization) to automatically scale the infrastructure. This ensures that your application scales up during peak demand and scales down when demand drops. Integration with Load Balancer – E2E Cloud's Auto Scaling integrates with the Load Balancer to automatically manage backend servers, ensuring traffic is efficiently distributed across the scale group while maintaining consistent performance. Automatic Node Removal – When resource utilization falls below a set threshold, nodes are automatically removed, preventing unnecessary costs during low-demand periods. SSH Access to Nodes – Each node within a scale group allows SSH access for monitoring, debugging, and log viewing, providing flexibility for managing and troubleshooting your infrastructure. Custom and Default Elastic Policies – E2E Cloud allows for both default (e.g., based on CPU or memory usage) and custom elastic scaling policies. This ensures that your infrastructure can scale based on various performance metrics like network traffic, request latency, or custom attributes defined by the user. Cooldown Period – A built-in cooldown period prevents consecutive scaling actions from being triggered too quickly, ensuring that the system has time to assess the impact of previous scaling decisions. Saved Images for Consistent Launch Sequences – The ability to create and use saved images ensures that newly added nodes automatically launch applications at startup, reducing manual effort and ensuring consistency. Scaling Policies for Min, Max, and Desired Nodes – You can define scaling policies with minimum, maximum, and desired node counts to ensure that the system remains within the specified capacity while allowing flexibility to adjust the number of nodes as needed. Custom Policy Management – For advanced users, E2E Cloud provides the option to define custom attributes and policies, offering a fine level of control over the scaling decisions. This flexibility enables you to scale based on metrics like disk I/O, network traffic, or any other custom metric. Key Benefits of using E2E Auto Scaling Cost Efficiency – Auto Scaling ensures that you only pay for the resources you actually use by automatically adding or removing nodes based on demand. This eliminates the need for over-provisioning and minimizes costs during low-usage periods. Improved Performance – By scaling resources in real-time based on demand, Auto Scaling helps maintain optimal application performance, ensuring that users experience consistent speed and reliability even during traffic spikes. Operational Simplicity – Auto Scaling automates many aspects of infrastructure management, such as node addition, removal, and load balancing, reducing the need for manual intervention. This allows teams to focus on other important tasks while ensuring the infrastructure scales seamlessly. Flexibility and Control – With customizable scaling policies, you can fine-tune your scaling strategy to match the specific needs of your application, whether that’s scaling based on CPU, memory, or custom metrics. This provides a high level of control over resource management. Enhanced Availability – The automatic scaling of nodes, combined with load balancing, ensures that your application can handle varying traffic loads, minimizing downtime and improving availability for end-users. Scalable Infrastructure for Growth – E2E Cloud’s Auto Scaling helps your infrastructure grow or shrink in response to changing traffic patterns, ensuring that your system can handle growth without manual intervention, while also providing the agility to reduce resources when demand drops. Streamlined Troubleshooting – With SSH access to each node, teams can easily troubleshoot and debug any issues with individual nodes in a scale group, ensuring rapid identification and resolution of performance problems. Simplicity in Customizing Scaling Triggers - The custom policy feature allows users to define unique scaling triggers based on specific service performance metrics, allowing for a more tailored and precise scaling strategy that aligns with business needs. Support for Dynamic Load Balancing – Integration with the Load Balancer ensures that as nodes are added or removed, traffic is properly distributed across available servers, preventing bottlenecks and ensuring a smooth user experience. Automation for Seasonal or Variable Demand – Auto Scaling is particularly useful for handling seasonal or unpredictable workloads, where demand fluctuates significantly. It ensures that your infrastructure adapts automatically, without requiring manual adjustments. Getting Started ​ To get started: Familiarize yourself with the key concepts of application scaling on E2E Cloud. Try out the application scaling features. Explore the Load Balancer documentation . Click here to get started Getting Started",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/EOSEncryption/#how-e2e-managed-eos-encryption-works-",
    "site_type": "Documentation",
    "content": "EOS Encryption | E2E Cloud Skip to main content On this page EOS Encryption E2E Networks Object Storage (EOS) Encryption enhances data security by encrypting objects within your storage buckets. This ensures that sensitive files and information remain protected from unauthorized access or data breaches, even if the underlying storage infrastructure is compromised. Object storage encryption is applied transparently, allowing users to upload, retrieve, and manage files as usual, while all data remains encrypted behind the scenes. This feature is crucial for organizations handling regulated or confidential information, helping to meet compliance requirements and support cloud data protection strategies. Note Currently E2E Managed Encryption is only available for Delhi region. How E2E Managed EOS Encryption Works ? ​ E2E Managed EOS Encryption is enabled at the bucket level. When creating a new bucket, users can enable encryption by toggling the \"Enable Encryption\" option. EOS uses server-side encryption (SSE), where the system handles key management and encryption operations automatically. Users do not need to manually manage keys or configure encryption mechanisms. All files (objects) uploaded to an encrypted bucket are automatically encrypted. Similarly, when these files are retrieved, they are seamlessly decrypted in transit, ensuring a smooth and secure user experience. Encrypted buckets and their contents can still leverage EOS features like versioning, lifecycle policies, replication, and access control mechanisms without limitations. Note E2E Managed Encryption must be enabled at the time of bucket creation. Once a bucket is created without encryption, it cannot be encrypted. To enable encryption for an existing dataset, a new encrypted bucket must be created and data should be migrated manually. How E2E Managed Encryption Affects Object Uploads and Downloads ? ​ Uploads to an encrypted bucket are automatically encrypted server-side, no extra action is required from user. Downloads from an encrypted bucket are automatically decrypted by EOS backend before delivering to user. Encryption is transparent and does not affect API interactions, access control policies, or object metadata. E2E Managed Encryption and Object Versioning ​ When object versioning is enabled on an encrypted bucket, each version of an object is encrypted independently. Deleting or restoring versions will retain encryption properties—there is no exposure of unencrypted data at any point. Version history maintains the encrypted state, providing full traceability and protection across all object changes. Note Currently, replication rules cannot be applied to encrypted buckets. Support for this will be added in the future. How E2E Managed EOS Encryption Works ? How E2E Managed Encryption Affects Object Uploads and Downloads ? E2E Managed Encryption and Object Versioning",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/functions/",
    "site_type": "Documentation",
    "content": "Functions | E2E Cloud Skip to main content On this page Functions (FaaS) Introduction ​ Function as a Service (FaaS) is a serverless cloud computing paradigm that facilitates the swift development and deployment of functions or services. With FaaS, developers can write and deploy code expeditiously, eliminating the need to handle infrastructure management. This approach can substantially decrease the time required to introduce new features or applications to the market. FaaS operates by allowing developers to focus solely on their code logic, without concerning themselves with the underlying server infrastructure. This serverless model enables automatic scaling and efficient resource utilization, making it an ideal choice for applications with varying workloads. By abstracting away infrastructure concerns, FaaS promotes agility and cost-effectiveness in software development and is particularly advantageous for microservices architectures and event-driven applications. Key Topics ​ Getting Started Learn how to create Functions. Runtime ​ E2E Networks provides several official templates, currently documented as follows: Python 3.11 [FastApi] Python 3.11 [Flask] Node 20 [Express] Node 18 [Express] Python 3.11 [Http] Python 3.9 [Http] Dotnet 7.0 [Http] Php 8.2 [Http] Go 1.21 [Http] Please note that the given code setup should remain unchanged. The handler functions serve as the entry points for your code. You have the flexibility to extend the code as needed, ensuring organizational coherence and seamless integration with the existing codebase. Introduction Key Topics Runtime",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/access_key/",
    "site_type": "Documentation",
    "content": "Access Key | E2E Cloud Skip to main content On this page Access Key If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Customers can create access keys using Manage Access Keys and the Permissions tab. Create Access Key ​ You can create an access key from the Permissions tab on the Bucket details page or the Manage access page. Enter a name for your access key. This can be an application name, project name, or a team member name. Click Generate Key . If all goes well, you will see newly generated access and secret keys. Keep a note of both these keys, as you will not see them again after you close the modal window. If you have mc set up, then use the given command to configure CLI for this access key. tip Choose a short name for the access key as you will be entering this for each command that you type in CLI. Manage Access ​ Sometimes you may need to disable access for certain users or target applications. The way to do that is to lock their access key from the manage access page. Go to Products > Storage Storage option in the sidebar menu. Click Manage Access Key . Identify the access you want to lock using the key name. Click the lock icon as desired. To unlock, follow the same steps above except this time you will see an unlock icon instead of lock. Using Manage Access Key ​ Using the manage access key, you need to click on the Manage Access Keys button. Actions in Manage Access Key ​ Customers can perform two actions in Access key: Lock, Unlock, and Delete. Go to Products > Storage option in the sidebar menu. Choose any bucket or create a new one. Click the permission tab; it will be opened for the selected bucket. Click the Create access key button. Enter a name for your access key. This can be an application name, project name, or a team member name. Choose an access key or create an access key. Assign a role: Role Description bucket admin can read, write, manage bucket writer can read, write bucket reader can read Public Access Config ​ Using Public access config, we give the permissions of Upload, Download, Upload & Download, and Private for the objects using URL. To enable this, you need to click on the Public Access Config button and select the permission you want to give. Protect Your Bucket Data With Encryption Introduction: The procedure on this page configures and enables Server-Side Encryption with Client-Managed Keys (SSE-C). EOS SSE-C supports client-driven encryption of objects before writing the object to the drive. Clients must specify the correct key to decrypt objects for read operations. Prerequisite ​ The mc client is required to encrypt an object ( How to install mc client ). The SSE-C key must be a 256-bit base64-encoded string. The client application is responsible for the generation and storage of the encryption key. EOS does not store SSE-C encryption keys and cannot decrypt SSE-C encrypted objects without the client-managed key. 1) Generate the Encryption Key ​ First of all, an encryption key is required. You can generate the encryption using the following command: cat /dev/urandom | head -c 32 | base64 - It is important to notice that a 256-bit base64-encoded string should be used. Save the encryption key for future reference. 2) Encrypt and Copy Object into Bucket Using Encryption Key ​ To encrypt an object using the mc client, refer to the following command: mc cp ~/source_path/my_object.json ALIAS/BUCKET/my_object.json \\ --encrypt-key \"ALIAS/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with the key_name used while configuring the mc client on which you want to write the SSE-C encrypted object. Replace BUCKET with the full path to the bucket or bucket prefix to which you want to write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. 3) Copy an SSE-C Encrypted Object Between Two Buckets ​ EOS also supports copying an SSE-C encrypted object to another S3-compatible service: mc cp SOURCE/BUCKET/mydata.json TARGET/BUCKET/mydata.json \\ --encrypt-key \\ \"SOURCE/BUCKET/=ENCRYPTION_KEY\",\"TARGET/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with respecting key_name used while configuring the mc client on which you want to read and write the SSE-C encrypted object. Replace source and destination BUCKET with the full path to the bucket or bucket prefix on which you want to read and write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. Considerations: SSE-C encrypted objects are not compatible with the EOS bucket replication feature. User manage a mapping of which encryption key was used to encrypt which object. E2E does not store encryption keys. You are responsible for tracking which encryption key you provided for which object. If your bucket is versioning-enabled, each object version that you upload by using this feature can have its own encryption key. You are responsible for tracking which encryption key was used for which object version. For downloading an encrypted object encryption key is required, if the user loses the key then he can not download the data, and his data will be lost. In this case E2E is not responsible for the loss of your data. References ​ MinIO Server-Side Encryption SSE-C Quickstart E2E Networks MC Client Download Guide Create Access Key Manage Access Using Manage Access Key Actions in Manage Access Key Public Access Config Prerequisite 1) Generate the Encryption Key 2) Encrypt and Copy Object into Bucket Using Encryption Key References",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/",
    "site_type": "Documentation",
    "content": "Storage | E2E Cloud Skip to main content On this page Storage E2E Networks Storage Solutions ​ The Storage section of the E2E Networks documentation offers comprehensive insights into various storage solutions, including Block Storage , Object Storage and Scalable File System . Key Storage Solutions ​ For comprehensive guidelines on each storage solution, refer to their specific sections in our documentation as listed below: Volumes Offers reliable and scalable storage for various data needs. Object Storage Ideal for storing large volumes of unstructured data. Scalable File System Ensures efficient data management with scalability. Head to the right section above, or start here . E2E Networks Storage Solutions Key Storage Solutions",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3fuse/",
    "site_type": "Documentation",
    "content": "Setting up s3fs-fuse | E2E Cloud Skip to main content On this page Setting up s3fs-fuse S3FS-Fuse is an open-source FUSE plugin and an easy-to-use utility for mounting E2E Object Storage Bucket as a File system on E2E Compute Node or your own on-premise server. The plugin supports all major Linux Distributions (eg. Ubuntu). In this tutorial, we will walk through configuration of S3FS-FUSE with EOS on a CentOS. Prerequisites ​ Bucket created in E2E Object Storage with the necessary permissions and its access key pairs. If you have not yet started with bucket creation, you can refer to this article to get started with object storage. Access and Secret keys with permissions for the target bucket A compute node with Linux OS tip Launch Compute Node through E2E My Account or use your own laptop Step 1: Installing s3fs-fuse ​ s3fs is available in default repositories for CentOS, RHEL, and Ubuntu systems. You can simply install it by executing the following commands on your system. Debian 9 and Ubuntu 16.04 or newer: ​ sudo apt install s3fs RHEL and CentOS 7 or newer through via EPEL: ​ sudo yum install epel-release sudo yum install s3fs-fuse macOS via Homebrew: ​ brew cask install osxfuse brew install s3fs Step 2: Creating Access Credentials ​ To access EOS from s3fs, we will need to generate a password file and store EOS access credentials. You can generate EOS credentials (access / secret key) through My Account. touch /etc/eos_creds echo \"<access_key>:<secret_key>\" > /etc/eos_creds Note Replace <access_key> and <secret_key> with your actual Bucket Access credentials. Now, set Owner only permission on the password file to limit access. chmod 600 /etc/eos_creds Step 3: Creating Directory as mount point ​ Create a directory as mount point for the bucket. We will use /eos for this article to keep it simple. mkdir /eos Step 4: Run s3fs command to mount the bucket ​ Run the following command to mount the bucket at directory eos. s3fs <bucket> /eos -o passwd_file=/etc/eos_creds,use_path_request_style,url=https://objectstore.e2enetworks.net Note In the above command replace <bucket> with your actual bucket name Step 5: Test the Mount Point ​ Verify the bucket is mounted using the below command: mount | grep s3fs If all went correctly, then you will see an output like below: s3fs on /eos type fuse.s3fs (rw,nosuid,nodev,relatime,user_id=0,group_id=0) To check file operations to the mounted bucket, you may run these commands from /eos: touch s3fs_file cp s3fs_file /eos/ To see object list from the bucket: s3cmd ls s3://e2e-test # Sample Output # 2019-11-27 02:48 0 s3://e2e-test/s3fs_file Conclusion ​ We have successfully configured s3fs-fuse to work with E2E Object Service. The complete user guide on the usage of s3fs-fuse is available here . Prerequisites Step 1: Installing s3fs-fuse Debian 9 and Ubuntu 16.04 or newer: RHEL and CentOS 7 or newer through via EPEL: macOS via Homebrew: Step 2: Creating Access Credentials Step 3: Creating Directory as mount point Step 4: Run s3fs command to mount the bucket Step 5: Test the Mount Point Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/access_key/#1-generate-the-encryption-key",
    "site_type": "Documentation",
    "content": "Access Key | E2E Cloud Skip to main content On this page Access Key If you intend to use CLI or API for accessing your data on EOS, you will need to define bucket permissions. Customers can create access keys using Manage Access Keys and the Permissions tab. Create Access Key ​ You can create an access key from the Permissions tab on the Bucket details page or the Manage access page. Enter a name for your access key. This can be an application name, project name, or a team member name. Click Generate Key . If all goes well, you will see newly generated access and secret keys. Keep a note of both these keys, as you will not see them again after you close the modal window. If you have mc set up, then use the given command to configure CLI for this access key. tip Choose a short name for the access key as you will be entering this for each command that you type in CLI. Manage Access ​ Sometimes you may need to disable access for certain users or target applications. The way to do that is to lock their access key from the manage access page. Go to Products > Storage Storage option in the sidebar menu. Click Manage Access Key . Identify the access you want to lock using the key name. Click the lock icon as desired. To unlock, follow the same steps above except this time you will see an unlock icon instead of lock. Using Manage Access Key ​ Using the manage access key, you need to click on the Manage Access Keys button. Actions in Manage Access Key ​ Customers can perform two actions in Access key: Lock, Unlock, and Delete. Go to Products > Storage option in the sidebar menu. Choose any bucket or create a new one. Click the permission tab; it will be opened for the selected bucket. Click the Create access key button. Enter a name for your access key. This can be an application name, project name, or a team member name. Choose an access key or create an access key. Assign a role: Role Description bucket admin can read, write, manage bucket writer can read, write bucket reader can read Public Access Config ​ Using Public access config, we give the permissions of Upload, Download, Upload & Download, and Private for the objects using URL. To enable this, you need to click on the Public Access Config button and select the permission you want to give. Protect Your Bucket Data With Encryption Introduction: The procedure on this page configures and enables Server-Side Encryption with Client-Managed Keys (SSE-C). EOS SSE-C supports client-driven encryption of objects before writing the object to the drive. Clients must specify the correct key to decrypt objects for read operations. Prerequisite ​ The mc client is required to encrypt an object ( How to install mc client ). The SSE-C key must be a 256-bit base64-encoded string. The client application is responsible for the generation and storage of the encryption key. EOS does not store SSE-C encryption keys and cannot decrypt SSE-C encrypted objects without the client-managed key. 1) Generate the Encryption Key ​ First of all, an encryption key is required. You can generate the encryption using the following command: cat /dev/urandom | head -c 32 | base64 - It is important to notice that a 256-bit base64-encoded string should be used. Save the encryption key for future reference. 2) Encrypt and Copy Object into Bucket Using Encryption Key ​ To encrypt an object using the mc client, refer to the following command: mc cp ~/source_path/my_object.json ALIAS/BUCKET/my_object.json \\ --encrypt-key \"ALIAS/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with the key_name used while configuring the mc client on which you want to write the SSE-C encrypted object. Replace BUCKET with the full path to the bucket or bucket prefix to which you want to write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. 3) Copy an SSE-C Encrypted Object Between Two Buckets ​ EOS also supports copying an SSE-C encrypted object to another S3-compatible service: mc cp SOURCE/BUCKET/mydata.json TARGET/BUCKET/mydata.json \\ --encrypt-key \\ \"SOURCE/BUCKET/=ENCRYPTION_KEY\",\"TARGET/BUCKET/=ENCRYPTION_KEY\" Replace ALIAS with respecting key_name used while configuring the mc client on which you want to read and write the SSE-C encrypted object. Replace source and destination BUCKET with the full path to the bucket or bucket prefix on which you want to read and write the SSE-C encrypted object. Replace ENCRYPTION_KEY with the key generated in the first step. Considerations: SSE-C encrypted objects are not compatible with the EOS bucket replication feature. User manage a mapping of which encryption key was used to encrypt which object. E2E does not store encryption keys. You are responsible for tracking which encryption key you provided for which object. If your bucket is versioning-enabled, each object version that you upload by using this feature can have its own encryption key. You are responsible for tracking which encryption key was used for which object version. For downloading an encrypted object encryption key is required, if the user loses the key then he can not download the data, and his data will be lost. In this case E2E is not responsible for the loss of your data. References ​ MinIO Server-Side Encryption SSE-C Quickstart E2E Networks MC Client Download Guide Create Access Key Manage Access Using Manage Access Key Actions in Manage Access Key Public Access Config Prerequisite 1) Generate the Encryption Key 2) Encrypt and Copy Object into Bucket Using Encryption Key References",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/s3browser_windows/",
    "site_type": "Documentation",
    "content": "S3 browser For Windows | E2E Cloud Skip to main content On this page S3 browser For Windows Introduction ​ S3 Browser is a freeware Windows client for S3 Compatible storage. It offers a simple web services interface that can be used to store and retrieve any amount of data, at any time, from anywhere on the web. In this tutorial, we will walk through steps to install and setup S3 browser for E2E Object store on your windows system. Prerequisites ​ Bucket in E2E Object Store. If you have not created a bucket yet, please refer to Getting Started section. Access and Secret keys with permissions on the target bucket Administrative access to windows server for Installing and Setting up S3 browser Step 1: Download and Installation ​ Please follow the steps below to download and install S3 Browser. Login to your Windows server with administrative access. Go to https://s3browser.com/download.aspx . Click on the Download link. Once the download is complete, follow the installation wizard to install S3 Browser. Step 2: Configure a New Account in S3 Browser ​ When you launch S3 Browser for the first time, you will be prompted to add a new account. You will need the following details to configure the account: Account Name Account Type Rest End Point Access Key ID Secret Access Key Enter a name of your choice for the account. In the Account Type section, change the type to S3 Compatible Storage . Enter the REST endpoint as https://objectstore.e2enetworks.net . Enter your Access and Secret Key that you obtained from My Account. After entering the above information, click Add New Account . Step 3: Enter Your Bucket Details ​ Once an account is created (i.e., configured), add the details of the external bucket. Click Yes and enter your bucket name. For the purpose of this tutorial, we will enter e2e-test as our sample bucket. Click on Add External Bucket . You will now be able to view the contents of the e2e-test bucket. Conclusion ​ The setup is now complete. Visit here for more details on using S3 Browser. Introduction Prerequisites Step 1: Download and Installation Step 2: Configure a New Account in S3 Browser Step 3: Enter Your Bucket Details Conclusion",
    "errors": null
  },
  {
    "URL": "https://docs.e2enetworks.com/docs/myaccount/storage/object_storage/intro/",
    "site_type": "Documentation",
    "content": "Introduction to E2E Object Storage | E2E Cloud Skip to main content On this page Introduction E2E Object Store (EOS) is a simple, cost-effective, and S3-compatible storage service that enables you to store, backup, and archive large amounts of content for your web apps or data for AI/ML pipelines. Our S3-Compatible REST API enables data access from anywhere on the internet or within your private network. EOS is designed to handle large data volumes, allowing you to scale as per your needs. Under the hood, it is a distributed object storage, a federation of large clusters that ensures high availability. Erasure coding, the standard practice for data storage, is employed for redundancy and fault tolerance. The user interface is simplified so that you can get started in a few clicks. The following diagram shows a typical user workflow when using the Object Store. Create a Bucket ​ In EOS, data files are organized in the form of objects in a bucket. A bucket is a container, just like folders or directories in your OS, and allows separation of concerns. For example, you could create a bucket for a personnel app and another one for an accounts app. This enables you to manage permissions and data separately. To start using EOS for data storage, you must create a bucket. Sign into My Account Go to Products > Storage option in the sidebar menu Click on the + Add bucket button Enter a unique bucket name. You must follow these guidelines when choosing the bucket name- You must enter a bucket name that is unique across all existing buckets in E2E Object Storage. You cannot choose a name that is already in use by another user. Names cannot be changed after creation. So choose wisely. Bucket name must be at least 3 and no more than 63 characters long. Uppercase letters or underscores are not allowed . Do not format bucket names like an IP address (for example, 10.10.10.2). Click Create You will be redirected to the object browser. Note By default, E2E Managed Encryption is enabled for your bucket. You may disable it during bucket creation if desired. For more information about E2E Managed Encryption, Click here . Note If you want to enable Object Lock for your bucket, you can do so by clicking on the Enable Object Lock option while creating the bucket. Note You will not be charged for empty buckets. Now that your bucket is ready, you may choose to ̈ Upload files through the object browser or set bucket permissions to enable CLI access. Create a Bucket",
    "errors": null
  }
]